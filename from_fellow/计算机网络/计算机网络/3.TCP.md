## 一、TCP基本知识

### 1、TCP头部格式

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzYuanBn?x-oss-process=image/format,png" alt="TCP 头格式" style="zoom:50%;" /> 

- **序列号**：建立连接时就生成一个随机数作为初始值，通过SYN传送给接收端住机。每次发送数据，序列号就会累加一个 “数据字节数” 的大小。标识了发送端到接收端的一个**字节**号。**解决网络包乱序问题。**
- **确认应答号**：指下一次期望收到的数据的序列号。发送端接收到确认应答号之后可以认为这之前的数据都已正常接收。**解决丢包问题**。
- 控制位：
  - ACK：为1时，确认应答的字段有效，TCP规定除了最初建立连接时SYN包之外该位必须设置为1。
  - RST：为1时，表示TCP连接出现异常必须强制断开。
  - SYN：为1时，表示希望建立连接，根据序列号字段进行初始化。
  - FIN：为1时，结束标志， 当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位为 1 的 TCP 段。 

### 2、TCP功能

`IP` 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。 如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 `TCP` 协议来负责。因为 TCP 是一个工作在**传输层**的**可靠**数据传输的服务，它能确保接收端接收的网络包是**无损坏、无间隔、非冗余和按序的。**

建立一个 TCP 连接是需要客户端与服务端达成上述三个信息的共识。

- **Socket**：由 IP 地址和端口号组成。
- **序列号**：用来解决乱序问题等。
- **窗口大小**：用来做流量控制。

### 3、TCP特点

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。 

- **面向连接**：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；

- **可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；

- **字节流**：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文。
- 如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。
  
- TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理。
  
- 对「重复」的 TCP 报文会自动丢弃。

### 4、唯一确定一个TCP连接

TCP四元组可以唯一确定一个连接：源地址、源端口、目的地址、目的端口。

源地址和目的地址的字段（32位）是在 **IP 头部** 中，作用是通过 IP 协议发送报文给对方主机。

源端口和目的端口的字段（16位）是在 **TCP 头部** 中，作用是告诉 TCP 协议应该把报文发给哪个进程。

### 5、TCP的最大连接数

最大TCP连接数=客户端的IP数*客户端的端口数。对 IPv4，客户端的 IP 数最多为 `2` 的 `32` 次方，客户端的端口数最多为 `2` 的 `16` 次方，也就是服务端单机最大 TCP 连接数，约为 `2` 的 `48` 次方。 但是，服务端最大并发TCP会受到限制：

- **文件描述符限制**：**每个TCP连接都是一个文件**，如果文件描述符占满了，会发生too many open files。Linux对可打开的文件描述符的数量作了三个方面的限制：系统、用户、进程能打开的最大文件数量都有限制。
- **内存限制**，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。

### 6、多个 TCP 服务进程可以同时绑定同一个端口吗？

如果两个 TCP 服务进程同时绑定的 **IP 地址和端口都相同，那么执行 bind() 时候就会出错**，错误是“Address already in use”。如果两个 TCP 服务进程绑定的端口都相同，而 IP 地址不同，那么执行 bind() 不会出错。

### 7、客户端的端口可以重复使用吗？

客户端在执行 connect 函数的时候，会在内核里随机选择一个端口，然后向服务端发起 SYN 报文，然后与服务端进行三次握手。**端口可以重复使用建立TCP连接**。

**TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的**，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的。所以如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的，因为内核是通过四元祖信息来定位一个 TCP 连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。

### 8、TCP重启时Address in use的问题

**问题描述**：当 TCP 服务进程重启之后，总是碰到“Address in use”的报错信息，TCP 服务进程不能很快地重启，而是要过一会才能重启成功。

**问题原因：**当 TCP 服务进程重启时，服务端会出现 **TIME_WAIT 状态的连接**，TIME_WAIT 状态的连接使用的 IP+PORT 仍然被认为是一个有效的 IP+PORT 组合，相同机器上不能够在该 IP+PORT 组合上进行绑定，那么执行 bind() 函数的时候，就会返回了 Address already in use 的错误。

**解决方法：**调用 bind 前，对 socket 设置 SO_RE USE ADDR 属性，可以解决这个问题。如果当前启动进程绑定的 IP+PORT 与处于TIME_WAIT 状态的连接占用的 IP+PORT 存在冲突，但是新启动的进程使用了 SO_REUSEADDR 选项，那么该进程就可以绑定成功。**会帮助我们在很快时间内重启服务端程序。‍**

### 9、客户端TCP连接TIME_WAIT的端口耗尽问题

**问题描述**：如果客户端都是**与同一个服务器（目标地址和目标端口一样）建立连接**，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就**无法与这个服务器再建立连接**了。但还是可以与**其他服务器**建立连接的，只要客户端连接的服务器不是同一个，那么端口是重复使用的。

**解决方法**：使用**TCP复用功能。打开 net.ipv4.tcp_tw_reuse 这个内核参数**。因为开启了这个内核参数后，客户端调用 connect 函数时，如果选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态。如果**该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒**，那么就会**重用这个连接**，然后就可以正常使用该端口了。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/port/%E7%AB%AF%E5%8F%A3%E9%80%89%E6%8B%A9.jpg" alt="img" style="zoom: 33%;" />

## 二、UDP和TCP的区别

UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。 

### 1、UPD的头部

头部只有 `8` 个字节。 

- **目标和源端口**：主要是告诉 UDP 协议应该把报文发给哪个进程。
- **包长度**：该字段保存了 UDP 首部的长度跟数据的长度之和。
- **校验和**：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP包。

### 2、TCP和UDP的区别

- **连接**：TCP是面向连接的，UDP不需要连接。

- **服务对象**：TCP是一对一的，UDP支持一对一、一对多、多对多。

- **可靠性**：TCP保证可靠交付数据，无差错，不丢失，不重复，按序。UDP是尽最大努力交付，不保证可靠交付。但是也能通过QUIC协议实现可靠传输。

- **拥塞控制、流量控制**：TCP有拥塞控制和流量控制，保证数据传输安全。UDP没有，网络拥堵不影响发送速率。

- **首部开销**：TCP首部更长，没有使用“选项”字段20字节，选用了会更长。UDP首部只有固定的8个字节。

- **传输方式**：TCP是流式传输，没有边界，保证顺序可靠。UDP是一个一个包发送，是有边界的，可能会丢包乱序。

- **分片不同**：TCP中数据大小如果大于MSS大小，就会在传输层进行分片，目标主机收到后就会进行组装。如果只丢失了一个分片，只传输这个分片。

  UDP数据大小如果大于MTU大小，就会在IP层进行分片，目标主机收到后在IP层组装，再传给传输层。

> Q1:为什么TCP头部有  “首部长度” 字段，UDP没有？
>
> 因为**UDP长度固定**，TCP有可选的选项字段，长度可变。
>
> Q2:为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？
>
> TCP的包长度可以直接算出来。其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。
>
> 但其实UDP也是基于IP协议的，也可以用这个公式计算。有两种说法：
>
> - 第一种说法：因为为了网络设备硬件设计和处理方便，首部长度需要是 `4` 字节的整数倍。如果去掉 UDP 的「包长度」字段，那 UDP 首部长度就不是 `4` 字节的整数倍了，所以我觉得这可能是为了补全 UDP 首部长度是 `4` 字节的整数倍，才补充了「包长度」字段。
> - 第二种说法：如今的 UDP 协议是基于 IP 协议发展的，而当年可能并非如此，依赖的可能是别的不提供自身报文长度或首部长度的网络层协议，因此 UDP 报文首部需要有长度字段以供计算。
>

### 3、TCP和UDP的应用场景

- 由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：`FTP` 文件传输；HTTP / HTTPS；


- 由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：包总量较少的通信，如 `DNS` 、`SNMP` 等；视频、音频等多媒体通信；广播通信；


### 4、TCP 和 UDP 可以同时绑定同一个端口吗？

**可以。**传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。

传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。当主机收到数据包后，可以**在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP**，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。

## 三、TCP连接建立

### 1、TCP三次握手

TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而**建立连接是通过三次握手来进行的**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="TCP 三次握手" style="zoom:33%;" />

1. 一开始，客户端和服务端都处于 `CLOSE` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态。

2. **第一次握手**：客户端会随机初始化序号（客户端序列号`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 **`SYN` 标志位置为 `1`**，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后**客户端处于 `SYN-SENT` 状态**。

3. **第二次握手**：服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（服务端序列号`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1` 客户端序列号 + 1, 接着把 **`SYN` 和 `ACK` 标志位置为 `1`**。最后把该报文发给客户端，该报文也不包含应用层数据，之后**服务端处于 `SYN-RCVD` 状态**。

4. **第三次握手**：客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 **`ACK` 标志位置为 `1`** ，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，**这次报文可以携带客户到服务端的数据**，之后**客户端处于 `ESTABLISHED` 状态**。

5. 服务端收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**。一旦完成三次握手，双方都处于 `ESTABLISHED` 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。

### 2、如何在 Linux 系统中查看 TCP 状态？

TCP 的连接状态查看，在 Linux 可以通过 `netstat -napt` 命令查看。

### 3、为什么是三次握手？不是两次、四次？

#### 3.1、主要原因：避免历史连接

客户端先发送了 SYN（seq = 90）报文，然后客户端宕机了，而且这个 SYN 报文还被网络阻塞了，服务端并没有收到，接着客户端重启后，又重新向服务端建立连接，发送了 SYN（seq = 100）报文。

<img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230525514.png" alt="三次握手避免历史连接" style="zoom:50%;" />

客户端连续发送多次 SYN（都是同一个四元组）建立连接的报文，在**网络拥堵**情况下：

- 一个「旧 SYN 报文」比「最新的 SYN」 报文早到达了服务端，那么此时服务端就会回一个 `SYN + ACK` 报文给客户端，此报文中的确认号是 91（90+1）。
- 客户端收到后，发现自己期望收到的确认号应该是 100 + 1，而不是 90 + 1，于是就会回 RST 报文。
- 服务端收到 RST 报文后，就会释放连接。
- 后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了。

上述中的**「旧 SYN 报文」称为历史连接**，TCP 使用三次握手建立连接的**最主要原因就是防止「历史连接」初始化了连接**。

> **Q1：如果服务端在收到 RST 报文之前，先收到了「新 SYN 报文」，也就是服务端收到客户端报文的顺序是：「旧 SYN 报文」->「新 SYN 报文」，此时会发生什么?**
>
> 1.当服务端第一次收到 SYN 报文，也就是收到 「旧 SYN 报文」时，就会回复 `SYN + ACK` 报文给客户端，此报文中的确认号是 91（90+1）。
>
> 2.然后这时再收到「新 SYN 报文」时，就会回 [Challenge Ack (opens new window)](https://xiaolincoding.com/network/3_tcp/challenge_ack.html)报文给客户端，**这个 ack 报文并不是确认收到「新 SYN 报文」的，而是上一次的 ack 确认号**，也就是91（90+1）。所以客户端收到此 ACK 报文时，发现自己期望收到的确认号应该是 101，而不是 91，于是就会回 RST 报文。

##### 3.1.1、两次连接不能解决历史连接

主要是因为**在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费**，最好就是在服务端发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就**需要三次握手**。

#### 3.2、原因2：同步双方初始序列号

TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：

- 接收方可以去除重复的数据；
- 接收方可以根据数据包的序列号**按序接收**；解决包乱序问题
- 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

四次握手其实也能够可靠的同步双方的初始化序号，但由于**第二步和第三步可以优化成一步**，所以就成了「三次握手」。

而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。

#### 3.3、原因3：避免无效连接

如果只有「两次握手」，当客户端发生的 `SYN` 报文在网络中阻塞，客户端没有接收到 `ACK` 报文，就会重新发送 `SYN` ，**由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 `ACK` 报文，所以服务端每收到一个 `SYN` 就只能先主动建立一个连接**。如果客户端发送的 `SYN` 报文在网络中阻塞了，重复发送多次 `SYN` 报文，那么服务端在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**

TCP 建立连接时，通过三次握手**能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号**。序列号能够保证数据包不重复、不丢弃和按序传输。

#### 3.4、不使用「两次握手」和「四次握手」的原因

- 「两次握手」：无法防止历史连接的建立，会建立无效连接，也无法可靠的同步双方序列号；
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

### 4、为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？

#### 4.1、主要原因：防止历史报文被下一个相同的四元组连接接收。

- 客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，然后**超时重传了这个数据包**。

  而此时服务端设备断电重启了，之前与客户端建立的连接就消失了，于是在收到客户端的数据包的时候就会发送 **RST 报文**。

- 紧接着，客户端又与服务端**建立了与上一个连接相同四元组的连接**；

- 在新连接建立完成后，上一个连接中**被网络阻塞的数据包正好抵达了服务端**，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。

可以看到，**如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题**。 

如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了历史报文。并不是完全避免了（因为**序列号会有回绕的问题**，所以需要用**时间戳**的机制来判断历史报文）。

#### 4.2、原因2：安全上防止黑客伪造的相同序列号的TCP报文被对方接收。

### 5、既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

#### 5.1、MTU和MSS

- **MTU：最大传输单元**。是以太网数据链路层中约定的数据载荷部分的最大长度， 一般为 `1500` 字节； 
- **MSS：TCP最大段大小**。 **这个MSS正好是IP中不会被分片处理的最大数据长度**。TCP在传送大量数据时，是以MSS的大小将数据进行分割发送的，重发时也是以MSS为单位。 

 MSS = MTU - IP header头大小 - TCP 头大小。

#### 5.2、主要作用：将超时重传的功能不要交给IP，而是TCP

**当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传，效率很低**。因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。

#### 5.3、IP的重传方法 - 重传整个TCP报文

当某一个 IP 分片丢失后，接收方的 IP 层就无法组装成一个完整的 TCP 报文（头部 + 数据），也就无法将数据报文送到 TCP 层，所以接收方不会响应 ACK 给发送方。因为发送方迟迟收不到 ACK 确认报文，所以会**触发超时重传，就会重发「整个 TCP 报文（头部 + 数据）」。**

为了达到最佳的传输效能 ，TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。  经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率 。

### 6、建立连接握手丢失问题

#### 6.1、第一次握手丢失了，会发生什么？

**客户端会重传SYN报文。**

- 当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 `SYN_SENT` 状态。


- 在这之后，如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「**超时重传**」机制，重传 SYN 报文，而且**重传的 SYN 报文的序列号都是一样的**。


- 通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。**每次超时的时间是上一次的 2 倍**。 当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接。所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。


#### 6.2、第二次握手丢失了，会发生什么？

**客户端和服务端都会重传。**

- 客户端会**重传 SYN 报文**，也就是第一次握手，因为一直没收到服务端的SYN-ACK报文。
- 服务端会**重传 SYN-ACK 报文**，也就是第二次握手，因为服务端一直没收到第三次握手的报文，出发了服务端的重传机制。

这两个重传次数都是可以在内核参数设置的。当服务端客户端的重传次数超过了各自设定的上限后，就会终止重传。

#### 6.3、第三次握手丢失了，会发生什么？

**服务端会重传SYN-ACK报文，ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文。**

- 客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 `ESTABLISH` 状态。


- 因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。


当服务端重传超过设定上限之后，就会断开连接。

### 7、什么是 SYN 攻击？如何避免 SYN 攻击？

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列；
- 全连接队列，也称 accept 队列；

TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务端不能为正常用户服务。 

#### 7.1、正常流程

- 当服务端接收到客户端的 SYN 报文时，会创建一个半连接的对象，然后将其加入到内核的「 SYN 队列」；

  接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；

- 服务端接收到 ACK 报文后，从「 SYN 队列」取出一个半连接对象，然后创建一个新的连接对象放入到「 Accept 队列」；

  应用通过调用 `accpet()` socket 接口，从「 Accept 队列」取出连接对象。

不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，默认情况都会丢弃报文。

**SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。**

#### 7.2、应对方式

- 方式一： 调大 netdev_max_backlog 

  当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值如下参数，默认值是 1000，我们要适当调大该参数的值。这样会避免因为内核队列阻塞导致包都被丢掉，但是还是会承受SYN攻击。

- 方式二：增大 **TCP 半连接队列**，要同时增大下面这三个参数：

  - 增大 net.ipv4.tcp_max_syn_backlog
  - 增大 listen() 函数中的 backlog
  - 增大 net.core.somaxconn
  
- 方式三：开启 **syncookies 功能**

  开启 syncookies 功能就可以在**不使用 SYN 半连接队列的情况下成功建立连接**，相当于绕过了 SYN 半连接来建立连接。 

- 方式四：**减少 SYN+ACK 重传次数** 

  针对 SYN 攻击的场景，我们可以减少 SYN-ACK 的重传次数，以**加快处于 SYN_REVC 状态的 TCP 连接断开。**


### 8、为什么说TCP是面向字节流的协议

#### 8.1、为什么说UDP是面向报文的协议？

当用户消息通过 UDP 协议传输时，**操作系统不会对消息进行拆分**，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是**每个 UDP 报文就是一个用户消息的边界**，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。  

操作系统在收到 UDP 报文后，会将其插入到队列里，**队列里的每一个元素就是一个 UDP 报文** 。

#### 8.2、面向字节流

- 当用户消息通过 TCP 协议传输时，**消息可能会被操作系统分组成多个的 TCP 报文**，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。 **不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议**。 

- 并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理。
- 同时对「重复」的 TCP 报文会自动丢弃。

#### 8.3、粘包问题

 粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。 

- 方式一： 固定长度的消息 。不灵活，不常使用。

- 方式二：**特殊字符作为边界**。  正如**HTTP中通过设置回车、换行作为HTTP报文协议的边界**。可能需要对特殊字符进行转义。

- 自定义消息结构，包头+数据。在包头中说明数据大小。

### 9、TCP传递的数据一定不会丢吗？

#### 9.1、TCP数据传输过程概括

1. 两端首先会通过**三次握手**，建立TCP连接。
2. 一个数据包，从聊天框里发出，消息会从**聊天软件**所在的**用户空间**拷贝到**内核空间**的**发送缓冲区（send buffer）**。
3. 数据包就这样顺着**传输层、网络层，进入到数据链路层，在这里数据包会经过流控（qdisc），再通过RingBuffer发到物理层的网卡**。
4. 数据就这样顺着**网卡**发到了网络中。这里头数据会经过n多个**路由器和交换机**之间的跳转，最后到达**目的机器的网卡**处。
5. 目的机器的网卡会通知**DMA**将数据包信息放到`RingBuffer`中，再触发一个**硬中断**给`CPU`，`CPU`触发**软中断**让`ksoftirqd`去`RingBuffer`收包。
6. 于是一个数据包就这样顺着**物理层，数据链路层，网络层，传输层**，最后从内核空间拷贝到用户空间里的**聊天软件**里。

#### 9.2、丢包情况一：建立连接时丢包

在建立TCP连接三次握手的过程中，服务器会在**第一次握手后**，建立**半连接**，放入**半连接队列**。**第三次握手收到后**，建立**全连接**，放入**全连接队列**。如果队列满导致溢出，新来的包就会被丢弃。

可以通过下面的方式查看是否存在这种丢包行为。

```shell
# 全连接队列溢出次数
# netstat -s | grep overflowed
    4343 times the listen queue of a socket overflowed

# 半连接队列溢出次数
# netstat -s | grep -i "SYNs to LISTEN sockets dropped"
    109 times the listen queue of a socket overflowed 
```

#### 9.3、丢包情况二：流量控制丢包

为了避免数据直接冲入网卡，超出网卡承受能力，让数据按一定的规则排个队依次处理，也就是所谓的**qdisc**(**Q**ueueing **Disc**iplines，排队规则)，**流量控制**机制。

当发送数据过快，流控队列长度`txqueuelen`又不够大时，就容易出现**丢包**现象。当遇到这种情况时，我们可以尝试修改下流控队列的长度。比如像下面这样将eth0网卡的流控队列长度从1000提升为1500.

```shell
# ifconfig eth0 txqueuelen 1500
```

#### 9.4、丢包情况三：网卡丢包

##### 9.4.1、网卡内RingBuffer过小导致丢包

在接收数据时，会将数据暂存到`RingBuffer`接收缓冲区中，然后等着内核触发软中断慢慢收走。如果这个**缓冲区过小**，而这时候发送的数据又过快，就有可能发生溢出，此时也会产生**丢包**。

```shell
# ifconfig
eth0:  RX errors 0  dropped 0  overruns 0  frame 0
```

查看上面的`overruns`指标，它记录了由于`RingBuffer`长度不足导致的溢出次数。

##### 9.4.2、网卡性能不足

网卡作为硬件，**传输速度是有上限的**。当网络传输速度过大，达到网卡上限时，就会发生丢包。这种情况一般常见于压测场景。我们可以通过`ethtool`加网卡名，获得当前网卡支持的最大速度。

```shell
# ethtool eth0
Settings for eth0:
    Speed: 10000Mb/s
```

#### 9.5、丢包情况四：接收缓冲区丢包

我们一般使用`TCP socket`进行网络编程的时候，内核都会分配一个**发送缓冲区**和一个**接收缓冲区**。

当我们想要发一个数据包，会在代码里执行`send(msg)`，这时候数据拷贝到内核**发送缓冲区**就**返回**了，至于**什么时候发数据，发多少数据**，这个后续由内核自己做决定。这两个缓冲区是有大小限制的，可以通过下面的命令去查看。

```shell
# 查看接收缓冲区
# sysctl net.ipv4.tcp_rmem
net.ipv4.tcp_rmem = 4096    87380   6291456

# 查看发送缓冲区
# sysctl net.ipv4.tcp_wmem
net.ipv4.tcp_wmem = 4096    16384   4194304
```

不管是接收缓冲区还是发送缓冲区，都能看到三个数值，分别对应缓冲区的**最小值，默认值和最大值 （min、default、max）。缓冲区会在min和max之间动态调整。**

如果**发送缓冲区**设置过小：

- 执行send的时候如果是**阻塞**调用，就会等待缓冲区有空位时发送。
- **非阻塞**调用会立刻返回一个EAGAIN错误信息，让应用程序下次再发。

如果**接收缓冲区**设置过小：

接收缓冲区满了之后，它的TCP接收窗口会变为0，也就是所谓的**零窗口**，并且会通过数据包里的`win=0`，告诉发送端不要再发送。一般这种情况下，发送端就该停止发消息了，但如果这时候确实还有数据发来，就会发生**丢包**。

#### 9.6、丢包情况五：两端间的网络丢包

丢包情况还可能发生在两端之间的某个中间链路上。

##### 9.6.1、ping命令

只能知道**你的机器和目的机器之间有没有丢包。**

##### 9.6.2、**mtr命令**

mtr命令可以查看到**你的机器和目的机器之间的每个节点的丢包情况**。**mtr默认用的是ICMP包**，有些节点限制了**ICMP包**，导致不能正常展示，可以使用mtr -u 命令使用UDP包，得到比较完整的链路图。

### 10、TCP中的序列号、确认号是如何变化的

#### **10.1、万能公式**

- **公式一：序列号 = 上一次发送的序列号 + len（数据长度）。特殊情况，如果上一次发送的报文是 SYN 报文或者 FIN 报文，则改为 上一次发送的序列号 + 1。**
- **公式二：确认号 = 上一次收到的报文中的序列号 + len（数据长度）。特殊情况，如果收到的是 SYN 报文或者 FIN 报文，则改为上一次收到的报文中的序列号 + 1。**

#### **10.2、序列号、确认号的作用**

- **序列号**：在建立连接时由内核生成的随机数作为其初始值，通过 SYN 报文传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。**用来解决网络包乱序问题。**
- **确认号**：指下一次「期望」收到的数据的序列号，发送端收到接收方发来的 ACK 确认报文以后，就可以认为在这个序号以前的数据都已经被正常接收。**用来解决丢包的问题。**

#### 10.3、三次握手阶段的序列号变化

1. 初始化和第一次握手：假设客户端的初始化序列号为 client_isn，服务端的初始化序列号为 server_isn;
2. 第二次握手：服务端收到客户端的 SYN 报文后，会将 SYN-ACK 报文（第二次握手报文）中序列号和确认号分别设置为：

   - 序列号设置为服务端随机初始化的序列号 server_isn。
   - **确认号设置为 client_isn + 1**，服务端上一次收到的报文是客户端发来的 SYN 报文，该报文的 seq = client_isn，可以得出当前确认号 = client_isn + 1。
3. 第三次握手：客户端收到服务端的 SYN-ACK 报文后，会将 ACK 报文（第三次握手报文）中序列号和确认号分别设置为：

   - 序列号设置为 client_isn + 1。客户端上一次发送报文是 SYN 报文，SYN 的序列号为 client_isn，所以**当前的序列号为 client_isn + 1**。
   - 确认号设置为 server_isn + 1，客户端上一次收到的报文是服务端发来的 SYN-ACK 报文，该报文的 seq = server_isn，可以得出**当前确认号 = server_isn + 1**。

> 为什么第二次和第三次握手报文中的确认号是将对方的序列号 + 1 后作为确认号呢？
>
> SYN 报文是特殊的 TCP 报文，用于建立连接时使用，**虽然 SYN 报文不携带用户数据，但是 TCP 将 SYN 报文视为 1 字节的数据**，当对方收到了 SYN 报文后，在回复 ACK 报文时，就需要将 ACK 报文中的确认号设置为 SYN 的序列号 + 1 ，这样做是有两个目的：
>
> - **告诉对方，我方已经收到 SYN 报文。**
> - **告诉对方，我方下一次「期望」收到的报文的序列号为此确认号，比如客户端与服务端完成三次握手之后，服务端接下来期望收到的是序列号为 client_isn + 1 的 TCP 数据报文。**

#### 10.4、数据传输阶段的变化

假设建立连接后，客户端发出了10字节的数据。

##### 客户端

- **序列号设置为 client_isn + 1**。客户端上一次发送报文是 ACK 报文（第三次握手），该报文的 seq = client_isn + 1，由于是一个单纯的 ACK 报文，没有携带用户数据，所以 len = 0。
- 确认号设置为 server_isn + 1。还是和第三次握手的 ACK 报文的确认号一样，这是因为客户端三次握手之后，发送 TCP 数据报文 之前，如果没有收到服务端的 TCP 数据报文，确认号还是延用上一次的。

可以看到，**客户端与服务端完成 TCP 三次握手后，发送的第一个 「TCP 数据报文的序列号和确认号」都是和「第三次握手的 ACK 报文中序列号和确认号」一样的**。

##### 服务端

- 序列号设置为 server_isn + 1。服务端上一次发送报文是 SYN-ACK 报文，序列号为 server_isn，所以当前的序列号为 server_isn + 1。
- 确认号设置为 client_isn + 11 。服务端上一次收到的报文是客户端发来的 10 字节 TCP 数据报文，该报文的 seq = client_isn + 1，len = 10。也就是将「收到的 TCP 数据报文中的序列号 client_isn + 1，再加上 10（len = 10） 」的值作为了确认号，表示自己收到了该 10 字节的数据报文。

> 如果客户端发送的第三次握手 ACK 报文丢失了，处于 SYN_RCVD 状态服务端收到了客户端第一个 TCP 数据报文会发生什么？
>
> 因为建立连接后，**客户端发送的第一个TCP数据报文的序列号、确认号和第三次握手一样。**并且这个TCP报文也将ACK标志位设置为1，所以可以正常完成握手，并接收数据包。

#### 10.5、四次挥手阶段的变化

数据传输阶段结束后，客户端发起了 FIN 报文，请求服务端端开该 TCP 连接，此时就进入了 TCP 四次挥手阶段：

##### 10.5.1、客户端

**第一次挥手**

- **序列号设置为 client_isn + 11**。客户端上一次发送的报文是 [PSH, ACK] ，该报文的 seq = client_isn + 1, len = 10，可以得出当前的序列号为 client_isn + 11。
- **确认号设置为 server_isn + 1**。客户端上一次收到的报文是服务端发来的 ACK 报文，该报文的 seq = server_isn + 1，是单纯的 ACK 报文，不携带用户数据，所以 len 为 0。

**第四次挥手**

- **序列号设置为 client_isn + 12**。客户端上一次发送的报文是 FIN 报文，该报文的 seq = client_isn + 11，可以得出当前的序列号为 client_isn + 11 + 1，也就是 client_isn + 12。
- **确认号设置为 server_isn + 2**。客户端上一次收到的报文是服务端发来的 FIN 报文，该报文的 seq = server_isn + 1，可以得出当前的确认号为 server_isn + 1 + 1，也就是 server_isn + 2。

##### 10.5.2、服务端

**第二次挥手**

- **序列号设置为 server_isn + 1**。服务端上一次发送的报文是 ACK 报文，该报文的 seq = server_isn + 1，而该报文是单纯的 ACK 报文，不携带用户数据，所以 len 为 0。
- **确认号设置为 client_isn + 12**。服务端上一次收到的报文是客户端发来的 FIN 报文，该报文的 seq = client_isn + 11，可以得出当前的确认号为 client_isn + 11 + 1，也就是 client_isn + 12。

**第三次挥手**

如果后续服务端没有再发送数据的话，序列号、确认号与第二次挥手一样。

- 序列号设置为 server_isn + 1。
- 确认号设置为 client_isn + 12。

### 11、服务端如果没有listen，客户端发起连接，会发生什么？

如果服务端只bind了ip和端口，但是没有调用listen让这个socket监听连接，如果此时客户端朝这个socket发数据：

这属于是**传输层**的问题，不会触发网络层的控制报文ICMP，而是会导致**服务端发回RST报文**。

### 12、没有listen，能建立TCP连接吗？

**可以，客户端是可以自己连自己的形成连接（TCP自连接），也可以两个客户端同时向对方发出请求建立连接（TCP同时打开），这两个情况都有个共同点，就是没有服务端参与，也就是没有listen，就能建立连接**。

#### 12.1、没有listen方法的自连接、两客户端连接如何建立

listen在执行时，会创建半连接和全连接队列，暂存三次握手的连接信息，可以在**握手时根据IP+端口找到对应的socket**。

但是**客户端没有执行listen**，而是**在内核的全局hash表中存放socket信息**。

在 TCP 自连接的情况中，客户端在 connect 方法时，最后会将自己的连接信息放入到这个**全局 hash 表**中，然后将信息发出，消息在经过**回环地址**重新回到 TCP 传输层的时候，就会根据 IP + 端口信息，再一次从这个全局 hash 中取出信息。于是握手包一来一回，最后成功建立连接。

两客户端连接建立时也是同样的方法。

### 13、没有accept，能建立TCP连接吗？

**就算不执行accept()方法，三次握手照常进行，并顺利建立连接。**并且，在服务端执行accept()前，如果客户端发送消息给服务端，服务端是能够**正常回复ack确认包**的。

#### 13.1、建立连接服务端伪代码

```c
int main()
{
    /*Step 1: 创建服务器端监听socket描述符listen_fd*/    
    listen_fd = socket(AF_INET, SOCK_STREAM, 0);
    /*Step 2: bind绑定服务器端的IP和端口，所有客户端都向这个IP和端口发送和请求数据*/    
    bind(listen_fd, xxx);
    /*Step 3: 服务端开启监听*/    
    listen(listen_fd, 128);
    /*Step 4: 服务器等待客户端的链接，返回值cfd为客户端的socket描述符*/    
    cfd = accept(listen_fd, xxx);
    /*Step 5: 读取客户端发来的数据*/
    n = read(cfd, buf, sizeof(buf));
}
```

#### 13.2、建立连接客户端伪代码

```c
int main()
{
    /*Step 1: 创建客户端端socket描述符cfd*/    
    cfd = socket(AF_INET, SOCK_STREAM, 0);
    /*Step 2: connect方法,对服务器端的IP和端口号发起连接*/    
    ret = connect(cfd, xxxx);
    /*Step 4: 向服务器端写数据*/
    write(cfd, buf, strlen(buf));
}
```

#### 13.3、连接建立流程

1.在执行`listen()`方法之后还会执行一个`accept()`方法。**一般情况**下，如果启动服务器，会发现最后程序会**阻塞在**`accept()`里。

2.客户端在创建好socket后，发起connect方法。

3.服务端阻塞的accept方法就会继续执行。

#### 13.4、accept的功能

accept实际上就是从全连接队列中**取出一条连接**，**创建连接过程不需要accept**。如果已经建立的连接呆在全连接队列中，此时客户端发送数据给这个连接，是可以正常回复ACK的。

但是，accep**t仅仅是与连接无关，但是会影响后面的接收信息。**没调用accept会导致**应用程序无法使用TCP连接，即不能接收信息，不能关闭连接。**

#### 13.5、总结

- **每一个**`socket`执行`listen`时，内核都会自动创建一个半连接队列和全连接队列。
- 第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。
- `accept方法`只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎**毫无关系**。
- 出于效率考虑，虽然都叫队列，但半连接队列其实被设计成了**哈希表**，而全连接队列本质是**链表**。
- 全连接队列满了，再来第三次握手也会丢弃，此时如果`tcp_abort_on_overflow=1`，还会直接发`RST`给客户端。
- 半连接队列满了，可能是因为受到了`SYN Flood`攻击，可以设置`tcp_syncookies`，绕开半连接队列。
- 客户端没有半连接队列和全连接队列，但有一个**全局hash**，可以通过它实现自连接或两客户端TCP连接，因此没有listen方法也能建立TCP连接。

## 四、TCP连接断开

### 1、四次挥手过程

 <img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzMwLmpwZw?x-oss-process=image/format,png" alt="客户端主动关闭连接 —— TCP 四次挥手" style="zoom: 33%;" /> 

1. **第一次挥手**：客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
2. **第二次挥手**：服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSE_WAIT` 状态。
3. 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
4. **第三次挥手**：等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
5. **第四次挥手**：客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
6. 服务端收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。
7. 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。这里一点需要注意是：**主动关闭连接的，才有 TIME_WAIT 状态。**

### 2、网络概念区分

1. MSL： **报文最大生存时间** 。它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。 

   2MSL：主动关闭的一方确认被动关闭的一方接收到了自己回复的ACK报文。如果没有接受到，被动一方会要求主动方重传ACK。

2. TTL：**生存时间字段**。在**IP首部中的8位字段**。该字段不是存的具体时间，而是设置了**数据报可以经过的最多路由器数**。  TL的初始值由源主机设置（通常为32或64），一旦经过一个处理它的路由器，它的值就减去1.当该字段值为0时，数据报就被丢弃，并发送ICMP报文通知源主机。 

   MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。**TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了**。

3. RTT：**往返时间**。客户端到服务端往返所花时间。RTT受网络传输拥塞的变化而变化。TCP含有动态估算RTT的算法 。RTT是**TCP超时与重传**中用到的概念。

4. RTO：超时重传时间。

### 3、为什么挥手需要四次

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，因此是需要四次挥手。但是**在特定情况下，四次挥手是可以变成三次挥手的**。

### 4、挥手丢失

以服务端（被动关闭方）、客户端（主动关闭方）为例。

#### 4.1、第一次挥手丢失了，会发生什么

**客户端重传FIN报文。**

客户端迟迟收不到被动方的 ACK 的话，会触发超时重传机制，重传 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制。

当客户端重传 FIN 报文的次数超过 `tcp_orphan_retries` 后，就不再发送 FIN 报文，则会在等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到第二次挥手，那么直接进入到 `close` 状态。

#### 4.2、第二次挥手丢失了，会发生什么？

**客户端重传FIN报文，服务端的ACK报文不会重传。**

当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 **`CLOSE_WAIT` 状态**。 **ACK 报文是不会重传的**，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。 

>  **`FIN_WAIT2` 状态不会持续太久。**
>
> 当客户端收到第二次挥手，也就是收到服务端发送的 ACK 报文后，客户端就会处于 `FIN_WAIT2` 状态，在这个状态需要等服务端发送第三次挥手，也就是服务端的 FIN 报文。
>
> 对于 close 函数关闭的连接，由于无法再发送和接收数据，所以`FIN_WAIT2` 状态不可以持续太久，而 `tcp_fin_timeout` 控制了这个状态下连接的持续时长，默认值是 60 秒。
>
> 这意味着对于**调用 close 关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭**。
>

#### 4.3、第三次挥手丢失了，会发生什么？

**服务端重传FIN报文。**

- 服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 `CLOSE_WAIT` 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。

  此时，**内核是没有权利替代进程关闭连接**，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。

- 服务端处于 **CLOSE_WAIT 状态**时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 **LAST_ACK 状态**，等待客户端返回 ACK 来确认连接关闭。

  如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 `tcp_orphan_retrie`s 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。

- 客户端不会一直等待第三次握手的报文的，因为它已经被close函数关闭了，60秒后还没收到服务端的FIN报文就会直接关闭。

#### 4.4、第四次挥手丢失了，会发生什么？

**服务端会重传FIN报文；客户端进入TIME_WAIT 状态，持续2MSL时间后关闭。**

当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 `TIME_WAIT` 状态。

服务端（被动关闭方）没有收到 ACK 报文前，还是处于 LAST_ACK 状态。

- 当服务端重传第三次挥手报文达到了最大重传次数，如果还是没能收到客户端的第四次挥手（ACK 报文），那么服务端就会断开连接。
- 客户端在收到第三次挥手后，就会进入 TIME_WAIT 状态，开启时长为 2MSL 的定时器，如果途中再次收到第三次挥手（FIN 报文）后，就会**重置定时器，当等待 2MSL 时长后，客户端就会断开连接**。

### 5、TIME_WAIT 问题

#### 5.1、为什么 TIME_WAIT 等待的时间是 2MSL？

**2MSL时长** 这其实是相当于**至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。 `2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。 

为什么不是 4 或者 8 MSL 的时长呢？连续丢包概率实在是太小了，忽略它比解决它更具性价比。 

#### 5.2、为什么需要 TIME_WAIT 状态？

主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。 

##### 5.2.1、原因一：防止历史连接中的数据，被后面相同四元组的连接错误的接收

> - **序列号**，标识了 TCP 发送端到 TCP 接收端的数据流的**一个字节**，因为 TCP 是面向字节流的可靠协议，为了保证消息的顺序性和可靠性，TCP 为每个传输方向上的每个字节都赋予了一个编号，以便于传输成功后确认、丢失后重传以及在接收端保证不会乱序。**序列号是一个 32 位的无符号数，因此在到达 4G 之后再循环回到 0**。
> - **初始序列号**，在 TCP 建立连接的时候，客户端和服务端都会各自生成一个初始序列号，它是基于时钟生成的一个随机数，来保证每个连接都拥有不同的初始序列号。**初始化序列号可被视为一个 32 位的计数器，该计数器的数值每 4 微秒加 1，循环一次需要 4.55 小时**。
>
> 序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据。

如果连接关闭后，马上又以相同四元组建立连接，就会导致错误接收之前的数据。

为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 `2MSL` 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。**

##### 5.2.2、保证「被动关闭连接」的一方，能被正确的关闭 

**等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。** 

假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSE 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会**回 RST 报文**。

**服务端收到这个 RST 并将其解释为一个错误**，这对于一个可靠的协议来说不是一个优雅的终止方式。 

#### 5.3、TIME_WAIT 过多有什么危害？

TIME-WAIT 状态主要的危害有两种：

- 第一是占用**系统资源**，比如文件描述符、内存资源、CPU 资源、线程资源等；
- 第二是占用**端口资源**，端口资源也是有限的，一般可以开启的端口为 `32768～61000`，也可以通过 `net.ipv4.ip_local_port_range`参数指定范围。

客户端和服务端 TIME_WAIT 过多，造成的影响是不同的。 **TIME_WAIT是主动关闭连接方才会有的的状态。**下面说的客户端、服务端都是他们作为主动关闭一方的情况。

- **如果客户端的 TIME_WAIT 状态过多**，**占满了所有端口资源**，那么就无法对「目的 IP+ 目的 PORT」都一样的服务端发起连接了，但是被使用的端口，还是可以继续对另外一个服务端发起连接的。 
-  **如果服务端的 TIME_WAIT 状态过多**，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会**占用系统资源**，比如文件描述符、内存资源、CPU 资源、线程资源等。 

### 6、优化TIME_WAIT

#### 6.1、解决TIME_WAIT

可以打开TCP时间戳和TCP复用机制，这样客户端就会选择一个TIME_WAIT时间超过了1s的连接，建立新连接。因为引入了时间戳，之前TIME_WAIT需要避免的历史连接问题也就解决了。

#### 6.2、避免服务器主动断开连接

其实并不应该强硬的解决TIME_WAIT状态，而是应该巧妙利用。如果服务端出现了大量的TIME_WAIT状态，说明服务端大量主动断开连接。应该让分散各地的客户端断开连接，让客户端承受TIME_WAIT的压力。

##### 6.2.1、HTTP没有使用长连接

关闭 HTTP 长连接机制后，每次请求都要经历这样的过程：建立 TCP -> 请求资源 -> 响应资源 -> 释放连接，那么此方式就是 **HTTP 短连接**。

**当服务端出现大量的 TIME_WAIT 状态连接的时候，可以排查下是否客户端和服务端都开启了 HTTP Keep-Alive**，因为任意一方没有开启 HTTP Keep-Alive，都会导致服务端在处理完一个 HTTP 请求后，就主动关闭连接，此时服务端上就会出现大量的 TIME_WAIT 状态的连接。可以让客户端和服务端都开启 HTTP Keep-Alive 机制。

##### 6.2.2、HTTP长连接超时

服务端建立起长连接后，如果一段时间没有接收到客户端的请求，就会主动断开连接。可以往**网络问题**的方向排查，比如是否是因为网络问题，导致客户端发送的数据一直没有被服务端接收到，以至于 HTTP 长连接超时。

##### 6.2.3、HTTP长连接的请求达到上限

nginx 的 keepalive_requests 参数限制了可以同时建立的HTTP长连接数量，一旦超过**nginx 就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态**。

### 7、CLOSE_WAIT问题

CLOSE_WAIT 状态是「被动关闭方」才会有的状态，而且如果「被动关闭方」没有调用 close 函数关闭连接，那么就无法发出 FIN 报文，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态。

所以，**当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接**。

#### 7.1、TCP服务端的流程

1. 创建服务端 socket，bind 绑定端口、listen 监听端口
2. 将服务端 socket 注册到 epoll
3. epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket
4. 将已连接的 socket 注册到 epoll
5. epoll_wait 等待事件发生
6. 对方连接关闭时，我方调用 close

在close之前的一些流程如果发生异常，**不能正确调用close，就会出现大量CLOSE_WAIT。**

#### 7.2、建立连接后，客户端主机断电

服务端无法察觉到客户端断电的情况，为了避免这种情况，TCP 搞了个**保活机制**。每隔一段时间发送探测报文，连续几次没有回应就断开连接。

> 注意，宕机不是客户端进程崩溃。如果客户端进程崩溃，客户端内核就会检测到，替进程发送FIN报文断开连接，并且回收资源。

开启了 TCP 保活，需要考虑以下几种情况：

- 第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
- 第二种，对端主机宕机并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，**会产生一个 RST 报文**，这样很快就会发现 TCP 连接已经被重置。
- 对端主机宕机，探测报文石沉大海，该TCP连接死亡。

##### 7.2.1、心跳机制

由于TCP保活机制时间非常长，可以在应用层自己实现一个心跳机制。**心跳包**便是在客户端和服务器之间自动通报对方一个结构体，让对方知道自己还活着，以确保连接的有效性的机制。

比如，web 服务软件一般都会提供 `keepalive_timeout` 参数，用来指定 HTTP 长连接的超时时间。如果设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会**启动一个定时器**，如果客户端在完成一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，**定时器的时间一到，就会触发回调函数来释放该连接。**

#### 7.3、建立连接后，服务端进程崩溃

**服务端会发送 FIN 报文，与客户端进行四次挥手**。TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，**后续的挥手过程也都是在内核完成，并不需要进程的参与**，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。

### 8、Socket编程

#### 8.1、TCP的连接流程

<img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230545997.png" alt="基于 TCP 协议的客户端和服务端工作" style="zoom:50%;" />

1. 服务端和客户端**初始化 `socket`，得到文件描述符**；
2. 服务端调用 `bind`，将 **socket 绑定在指定的 IP 地址和端口;**
3. 服务端调用 `listen`，进行**监听**；
4. 服务端调用 `accept`，**等待客户端连接**；
5. 客户端调用 `connect`，向**服务端的地址和端口发起连接请求**；
6. 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。
7. 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。
8. 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。

#### 8.2、listen 时候参数 backlog 的意义

```c
int listen (int socketfd, int backlog)
```

**backlog 是 accept 队列（全连接队列）的长度。**

**但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 = min(backlog, somaxconn)。**

#### 8.3、accept发生在三次握手的哪一步

**第一次握手**：客户端的协议栈向服务端发送了 SYN 包，并告诉服务端当前发送序列号 client_isn，客户端进入 SYN_SENT 状态；

**第二次握手**：服务端的协议栈收到这个包之后，和客户端进行 ACK 应答，应答的值为 client_isn+1，表示对 SYN 包 client_isn 的确认。

同时服务端也发送一个 SYN 包，告诉客户端当前我的发送序列号为 server_isn，服务端进入 SYN_RCVD 状态；

客户端协议栈收到 ACK 之后，使得应用程序从 `connect` 调用返回，表示客户端到服务端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务端的 SYN 包进行应答，应答数据为 server_isn+1；

**第三次握手**：ACK 应答包到达服务端后，服务端的 TCP 连接进入 ESTABLISHED 状态，同时服务端协议栈使得 `accept` 阻塞调用返回，这个时候服务端到客户端的单向连接也建立成功。至此，客户端与服务端两个方向的连接都建立成功。

从上面的描述过程，我们可以得知**客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。**

#### 8.4、客户端调用了close，连接断开的流程

- 客户端调用 `close`，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态；
- 服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 `EOF` 到接收缓冲区中，应用程序可以通过 `read` 调用来感知这个 FIN 包。这个 `EOF` 会被**放在已排队等候的其他已接收的数据之后**，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态；
- 接着，当处理完数据后，自然就会读到 `EOF`，于是也调用 `close` 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态；
- 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；
- 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；
- 客户端经过 `2MSL` 时间之后，也进入 CLOSE 状态；

#### 8.5、没有accept，也能建立连接

accpet 系统调用并不参与 TCP 三次握手过程，它只是负责从 TCP 全连接队列取出一个已经建立连接的 socket，用户层通过 accpet 系统调用拿到了已经建立连接的 socket，就可以对该 socket 进行读写操作了。

#### 8.6、没有 listen，也能建立 TCP 连接

客户端是可以自己连自己的形成连接（**TCP自连接**），也可以两个客户端同时向对方发出请求建立连接（**TCP同时打开**），这两个情况都有个共同点，就是**没有服务端参与，也就是没有 listen，就能 TCP 建立连接。**

### 9、TCP一定需要四次挥手吗？

#### 9.1、需要四次挥手的关键原因

服务器收到客户端的 FIN 报文时，内核会马上回一个 ACK 应答报文，**但是服务端应用程序可能还有数据要发送，所以并不能马上发送 FIN 报文，而是将发送 FIN 报文的控制权交给服务端应用程序**：

- 如果服务端应用程序有数据要发送的话，就发完数据后，才调用关闭连接的函数；
- 如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，

 是否要发送第三次挥手的**控制权不在内核，而是在被动关闭方的应用程序**，因为应用程序可能还有数据要发送，由应用程序决定什么时候调用关闭连接的函数，当调用了关闭连接的函数，内核就会发送 FIN 报文了。所以**服务端的 ACK 和 FIN 一般都会分开发送**。 

> FIN报文一定会在调用关闭连接的函数处才会发送吗？
>
> **不一定。**如果进程退出了，不管是不是正常退出，还是异常退出（如进程崩溃），内核都会发送 FIN 报文，与对方完成四次挥手。

#### 9.2、关闭连接的两种函数

关闭的连接的函数有两种函数：

- **close 函数**，**同时 socket 关闭发送方向和读取方向**，**是粗暴的关闭方式**。也就是 socket 不再有发送和接收数据的能力。

  如果有多进程/多线程共享同一个 socket，如果有一个进程调用了 close 关闭只是让 socket 引用计数 -1，并不会导致 socket 不可用，同时也不会发出 FIN 报文，其他进程还是可以正常读写该 socket，直到引用计数变为 0，才会发出 FIN 报文。

- **shutdown 函数**，可以**指定 socket 只关闭发送方向而不关闭读取方向**，也就是 socket 不再有发送数据的能力，但是还是具有接收数据的能力。

  如果有多进程/多线程共享同一个 socket，shutdown 则不管引用计数，直接使得该 socket 不可用，然后发出 FIN 报文，如果有别的进程企图使用该 socket，将会受到影响。

如果使用粗暴的close函数关闭连接， 如果收到了服务端发送的数据，由于客户端已经不再具有发送和接收数据的能力，所以**客户端的内核会回 RST 报文给服务端，然后内核会释放连接，这时就不会经历完成的 TCP 四次挥手。** 相反的，**使用shutdown就可以完成正常的四次挥手。**

#### 9.3、什么情况下会三次挥手？

当被动关闭方在 TCP 挥手过程中，「**没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。** 

#####  TCP 延迟确认的策略

<img src="https://cdn.xiaolincoding.com//mysql/other/33f3d2d54a924b0a80f565038327e0e4.png" alt="img" style="zoom:50%;" />

- 当有响应数据要发送时，**ACK 会随着响应数据一起立刻发送给对方**；
- 当没有响应数据要发送时，**ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送**；
- 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK。

因为TCP延迟确认默认开启，所以会有大量的三次挥手现象。

### 10、乱序的FIN包比数据包先到达，会发生什么？

问题：四次挥手过程中，第三次挥手的报文，先于被动方的数据包到达，此时会如何处理FIN包？

<img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP5p6XY29kaW5n,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="img" style="zoom:50%;" /> 

可以正常关闭。因为如果 FIN 报文比数据包先抵达客户端，此时 FIN 报文其实是一个**乱序的报文**。

在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「乱序队列」，**并不会进入到 TIME_WAIT 状态**。之后报文到达时，如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。

### 11、TCP连接没有开启keep alive，一端断电和一端进程崩溃的区别

#### 11.1、keep alive机制

是 **TCP 的保活机制** 。

**工作原理**：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，**如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡**，系统内核将错误信息通知给上层应用程序。 

如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。

- 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
- 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。

所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活。

#### 11.2、主机崩溃的情况-无法感知

客户端主机崩溃了，服务端是**无法感知到的**，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，**服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态**，直到服务端重启进程。

在**没有使用 TCP 保活机制**且**双方不传输数据**的情况下，一方的 TCP 连接处在 ESTABLISHED 状态，并不代表另一方的连接还一定正常。

#### 11.3、进程崩溃的情况-内核代劳

TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是**内核会发送第一次挥手 FIN 报文**，**后续的挥手过程也都是在内核完成，并不需要进程的参与**，所以即使服务端的进程退出了，还是能与客户端完成 TCP四次挥手的过程。

**在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手**。

#### 11.4、有数据传输时崩溃

**情景一：客户端主机崩溃，迅速重启。**

客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程：客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会**回复 RST 报文，重置该 TCP 连接**。

所以，**只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接**。

**情景二：客户端主机崩溃，一直没有重启。**

服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。 

### 12、拔掉网线后，原本的TCP连接还存在吗

**网线不会影响传输层。**

#### 12.1、拔掉网线后，有数据传输

服务端由于发出的包无法送达，会触发**重传**机制。

- 如果尽快插回了网线，不影响TCP状态，会继续正常返回ACK报文。

- 如果很久没有插回，超过了重传的阈值，内核会判断这个TCP连接有问题，通过Socket接口告诉应用程序TCP出问题了，断开这个连接。

  等到插回网线后，客户端这边的报文发出时，会发现服务端没有相同四元组的TCP连接，**服务端内核会返回一个RST报文给客户端**，客户端断开连接。

#### 12.2、拔掉后，没有数据传输

- 如果没有开启TCP keep alive机制，客户端拔掉网线后，双发都没有发送数据，这个TCP连接会一直存在。
- 如果开启TCP keep alive机制，拔掉网线后，双方都没有进行数据传输。TCP会发送探测报文：
  - 如果对端工作正常，TCP保活时间会被重置，等到下一次TCP保活时间再检查。
  - 如果对端主机宕机，报文不可达，连续几次后，TCP会报告该TCP连接死亡。

### 13、TCP的保活机制、HTTP长连接

**这两个完全是两样不同东西**，实现的层面也不同：

- HTTP 的 Keep-Alive，是由**应用层（用户态）** 实现的，称为 **HTTP 长连接**；
- TCP 的 Keepalive，是由 **TCP 层（内核态）** 实现的，称为 **TCP 保活机制**；

#### 13.1、HTTP的keep-alive

可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 **HTTP 长连接**。 HTTP 长连接不仅仅减少了 TCP 连接资源的开销，而且这给 **HTTP 流水线**技术提供了可实现的基础。 

##### 13.1.1、HTTP流水线

HTTP 流水线，是**客户端可以先一次性发送多个请求，而在发送过程中不需先等待服务器的回应**，可以减少整体的响应时间。 

**服务器还是按照顺序响应**。**服务器响应完客户端第一批发送的请求后，客户端才能发出下一批的请求**，也就说如果服务器响应的过程发生了阻塞，那么客户端就无法发出下一批的请求，此时就造成了**HTTP应答「队头阻塞」**的问题。 

##### 13.1.2、HTTP定时器

为了避免资源浪费的情况，web 服务软件一般都会提供 `keepalive_timeout` 参数，用来指定 HTTP 长连接的超时时间。

比如设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会**启动一个定时器**，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，**定时器的时间一到，就会触发回调函数来释放该连接。**

## 五、TCP重传、滑动窗口、流量控制、拥塞控制

### 1、重传机制

TCP 实现可靠传输的方式之一，是通过**序列号与确认应答**。当发送端的数据到达接收主机时，接收端主机会返回一个**确认应答消息，表示已收到消息**。TCP 针对数据包丢失的情况，会用**重传机制**解决。 

#### 1.1、超时重传

重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据，也就是**超时重传**。TCP 会在两种情况发生超时重传：**数据包丢失；确认应答丢失**。

##### 1.1.1、超时时间的设置

`RTT` 指的是**数据发送时刻到接收到确认的时刻的差值**，也就是包的往返时间。

`RTO` 指的是超时重传时间。

- 当超时时间 **RTO 较大**时，重发就慢，丢了老半天才重发，没有效率，性能差；
- 当超时时间 **RTO 较小**时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。

**超时重传时间 RTO 的值应该略大于报文往返 RTT 的值**。 

##### 1.1.2、Linux中RTT时间的计算

实际上「报文往返 RTT 的值」是经常变化的，所以「超时重传时间 RTO 的值」应该是一个**动态变化的值**。 估计往返时间，需要**采样RTT、采样 RTT 的波动范围**两个数据。

##### 1.1.3、再次超时的策略

如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。**

这可能导致超时重传周期长，因此可以用**快速重传**。

#### 1.2、快速重传

TCP 还有另外一种**快速重传（Fast Retransmit）机制**，它**不以时间为驱动，而是以数据驱动重传**。  快速重传的工作方式是当**收到三个相同的 ACK 报文**时，会在定时器过期之前，重传丢失的报文段。

##### 1.2.1、**快速重传缺点**

快速重传机制只解决了超时时间的问题，但是它依然面临着另外一个问题：**重传的时候，是重传一个，还是重传所有的问题。** 

- 如果只选择重传一个报文，那么**重传的效率很低**。因为对于后面丢失的报文，还得在后续收到三个重复的 ACK3 才能触发重传。
- 如果选择重传丢失报文之后已发送的所有报文，虽然能同时重传已丢失的报文，但是没有丢失的部分数据相当于做了一次无用功，**浪费资源**。

不管是重传一个报文，还是重传已发送的报文，都存在问题。为了解决不知道该重传哪些 TCP 报文，于是就有 **`SACK` 方法**。

#### 1.3、选择性确认SACK方法

还有一种实现重传机制的方式叫：`SACK`（ Selective Acknowledgment）， **选择性确认**。

这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以**只重传丢失的数据**。

#### 1.4、Duplicate SACK

Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。** 

##### **1.4.1、ACK丢包**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/12.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="ACK 丢包" style="zoom:50%;" /> 

- 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）
- **于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500**，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 `D-SACK`。
- 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。

##### 1.4.2、**网络延时**

 <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/13.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="网络延时" style="zoom:50%;" />

- 数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。
- 而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；
- **所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。**
- 这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。

##### 1.4.3、D-SACK的 好处

1. 可以让「发送方」知道，是**发出去的包丢了，还是接收方回应的 ACK 包**丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;

### 2、滑动窗口

为每个包确认应答，这样的传输方式有一个缺点：数据包的**往返时间越长，通信的效率就越低**。

为解决这个问题，TCP 引入了**窗口**这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。

#### 2.1、窗口的实现、累计应答

窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到**确认应答返回之前，必须在缓冲区中保留已发送的数据。**如果按期收到确认应答，此时数据就可以从缓存区清除。 

> 假设窗口大小为 `3` 个 TCP 段，那么发送方就可以「连续发送」 `3` 个 TCP 段，并且中途若有 ACK 丢失，可以通过「下一个确认应答进行确认」。 
>
> **累计应答：** ACK 600 确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫**累计确认**或者**累计应答**。 

#### 2.2、窗口大小

TCP 头里有一个字段叫 `Window`，也就是窗口大小。窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。 这个字段是**接收端告诉发送端自己还有多少缓冲区可以接收数据**。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。

通常窗口的大小是由接收方的窗口大小来决定的。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。

#### 2.3、发送方的滑动窗口

四个部分，其中深蓝色方框是发送窗口，紫色方框是可用窗口：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/16.jpg?)

- \#1 是已发送并收到 ACK确认的数据：1~31 字节
- \#2 是已发送但未收到 ACK确认的数据：32~45 字节
- \#3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节
- \#4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后

**实现方式**

TCP 滑动窗口方案使用**三个指针**来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。 

- `SND.WND`：表示发送窗口的大小（大小是由接收方指定的）；
- `SND.UNA`：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节。
- `SND.NXT`：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。

**可用窗口大小 = SND.WND -（SND.NXT - SND.UNA）** 

#### 2.4、接收方的滑动窗口

接下来我们看看接收方的窗口，接收窗口相对简单一些，根据处理的情况划分成三个部分：

- \#1 + #2 是已成功接收并确认的数据（等待应用进程读取）；
- \#3 是未收到数据但可以接收的数据；
- \#4 未收到数据并不可以接收的数据；

![接收窗口](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/20.jpg)

其中三个接收部分，**使用两个指针**进行划分:

- `RCV.WND`：表示接收窗口的大小，它会通告给发送方。
- `RCV.NXT`：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。
- 指向 #4 的第一个字节是个相对指针，它需要 `RCV.NXT` 指针加上 `RCV.WND` 大小的偏移量，就可以指向 #4 的第一个字节了。

>  接收窗口和发送窗口的大小并不是完全相等，**接收窗口的大小是约等于发送窗口的大小的。**
>
> 因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。

### 3、流量控制

发送方不能无脑的发数据给接收方，要考虑接收方处理能力。 **TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。** 

#### 3.1、窗口关闭

**如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。** 

**潜在的风险：**接收方向发送方通告窗口大小时，是通过 `ACK` 报文来通告的。当发送窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，**如果这个通告窗口的 ACK 报文在网络中丢失了，那就再也无法继续传输了，导致死锁**。

> 为了解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**如果持续计时器超时，就会发送**窗口探测报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。
>
> - 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；
>- 如果**接收窗口不是 0，那么死锁的局面就可以被打破了。**

#### 3.2、糊涂窗口综合症

如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。到最后，**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**。 `TCP + IP` 头有 `40` 个字节，为了传输那几个字节的数据，要搭上这么大的开销，这太不经济了。 

所以，糊涂窗口综合症的原因是两方面的：**接收方可以通告一个小的窗口；而发送方可以发送小数据。**

##### 3.2.1、让接收方不通告小窗口

接收方通常的策略如下：当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是**小于 MSS 与 1/2 缓存大小中的最小值时**，阻止了发送方再发数据过来。

MSS：最大报文段长度。MTU最大传输单元。MSS = MTU - IP头 - TCP头。

等到接收方处理了一些数据后，**窗口大小 >= MSS，或者接收方缓存空间有一半可以使用**，就可以把窗口打开让发送方发送数据过来。

##### 3.2.2、让发送方不发送小数据

使用 **Nagle 算法**，延时处理，只有**满足下面任意一个条件**，才可以发送数据：

- 条件一：要等到**窗口大小 >= `MSS` 并且 数据大小 >= `MSS`；**
- 条件二：**收到之前发送数据的 `ack` 回包；**

只要上面两个条件都不满足，发送方一直在囤积数据，直到满足上面的发送条件。

如果接收方不能满足「不通告小窗口给发送方」，那么即使开了 Nagle 算法，也无法避免糊涂窗口综合症。因为如果**对端 ACK 回复很快的话**，Nagle 算法就不会拼接太多的数据包，这种情况下依然会有小数据包的传输，网络总体的利用率依然很低。 

**接收方得满足「不通告小窗口给发送方」+ 发送方开启 Nagle 算法，才能避免糊涂窗口综合症**。 

### 4、拥塞控制

**流量控制是避免「发送方」的数据填满「接收方」的缓存**，但是并不知道网络的中发生了什么。

在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大。

所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。于是，就有了**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**

#### 4.1、拥塞窗口

**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

**发送窗口的大小：**是**拥塞窗口和接收窗口中的最小值**。

> **拥塞的判定标准**：其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**

#### 4.2、拥塞控制算法

##### 4.2.1、慢启动和拥塞避免

**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**  慢启动算法，发包的个数是**指数性的增长**。 慢启动门限 `ssthresh` （slow start threshold）是策略的分界线。

- 当 `cwnd` < `ssthresh` 时，使用慢启动算法。
- 当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」。

进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**

- 当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 `MSS` 大小的数据，变成了**线性增长。**

**拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长**。但是总有一个时候会拥塞，发生拥塞就需要拥塞发生算法。

##### 4.2.2、拥塞发生算法

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：**超时重传；快速重传。**

**4.2.2.1、发生超时重传的拥塞发生算法**

当发生了「超时重传」，则就会使用拥塞发生算法。这个时候，ssthresh 和 cwnd 的值会发生变化：

`慢启动门限ssthresh` 设为 `cwnd/2`，`拥塞窗口cwnd` 重置为 `1` （恢复为 cwnd 初始化值，这里假定 cwnd 初始化值 1）；重新开始慢启动 。

这种方法太过于激进。

**4.2.2.2、发生快速重传的拥塞发生算法**：**拥塞避免-快速恢复-拥塞避免**

**快速重传**：接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

`cwnd = cwnd/2` ，也就是设置为原来的一半；`ssthresh = cwnd`；进入**快速恢复算法。**

##### 4.2.3、快速恢复 <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="快速重传和快速恢复" style="zoom:50%;" /> 

- 先用快速重传：`cwnd = cwnd/2` ，也就是设置为原来的一半；`ssthresh = cwnd`;

- 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了，如果是k个重复ACK就+k）；重传丢失的数据包；

  如果再收到重复的 ACK，那么 cwnd 增加 1；

- 如果**收到新数据的 ACK 后**，把 cwnd 设置为第一步中的 ssthresh 的值，也即**解决了重复ACK之后，再次进入拥塞避免状态**；

> 快速恢复算法的解释：
>
> 1.一开始因为网络堵塞，需要减小窗口。**先用拥塞避免算法**，将ssthresh和cwnd都减半；之后由于接收到了K个重复数据包，cwnd再加上K。
>
> 2.随后继续重传，如果收到重复的ACK，cwnd加1。这是为了**保证重复数据包的尽快发送**，因为**这个算法认为网络此时拥塞的主要原因是该包收不到导致的**。
>
> 3.一旦**收到了新的ACK包**，就认为已经解决了之前导致拥塞的重传包的问题，**进入拥塞避免状态。**

## 六、TCP半连接队列和全连接队列(SYN报文何时会被丢弃？)

不管是半连接队列还是全连接队列，都有最大长度限制，**超过限制时，内核会直接丢弃SYN报文，或返回 RST 包。** 

### 1、全连接队列溢出

**当超过了 TCP 最大全连接队列，服务端则会丢掉后续进来的 TCP 连接**，丢掉的 TCP 连接的个数会被统计起来，我们可以使用 `netstat -s `命令来查看。

当服务端并发处理大量请求时，如果 TCP 全连接队列过小，就容易溢出。发生 TCP 全连接队溢出的时候，后续的请求就会被丢弃，这样就会出现服务端请求数量上不去的现象。

#### 1.1、查看全连接队列的长度

可以通过 `ss -ltn` 命令查看。

#### **1.2、Linux可以设置全连接队列溢出后的动作** ：丢弃、回RST

`tcp_abort_on_overflow` 共有两个值分别是 0 和 1，其分别表示：

- 0 ：如果全连接队列满了，那么 server **扔掉** client 发过来的 ack ；一般设置为丢弃，有利于应对**突发流量**。因为丢弃ACK包后，客户端会多次重传，只要服务端解决了短期的突发流量，就依然能顺利建立连接。
- 1 ：如果全连接队列满了，server 发送一个 **`reset` 包**给 client，表示废掉这个握手过程和这个连接；只有非常肯定 TCP 全连接队列会长期溢出时，才能设置为 1 以**尽快通知客户端**。

#### **1.3、验证是否是全连接队列溢出导致的连接问题**

可以把 tcp_abort_on_overflow 设置为 1，这时如果在客户端异常中可以看到很多 `connection reset by peer`**RST报文** 的错误，那么就可以证明是由于服务端 TCP 全连接队列溢出的问题。

#### 1.4、如何增大TCP全连接队列

**TCP 全连接队列的最大值取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)**。 

- `somaxconn` 是 Linux 内核的参数，默认值是 128，可以通过 `/proc/sys/net/core/somaxconn` 来设置其值；
- `backlog` 是 `listen(int sockfd, int backlog)` 函数中的 backlog 大小，Nginx 默认值是 511，可以通过修改配置文件设置其长度；

**如果持续不断地有连接因为 TCP 全连接队列溢出被丢弃，就应该调大 backlog 以及 somaxconn 参数。** 

### 2、半连接队列溢出

半连接队列长度不能用ss命令直接查看，可以通过查询处于 `SYN_RECV` 状态的 TCP 连接，就是 TCP 半连接队列。  

#### 2.1、半连接队列溢出攻击-SYN攻击

对服务端一直发送 TCP SYN 包，但是不回第三次握手 ACK，这样就会使得**服务端有大量的处于 `SYN_RECV` 状态的 TCP 连接**。这其实也就是所谓的 **SYN 洪泛、SYN 攻击、DDos 攻击。**

可以通过**` netstat -s `观察半连接队列溢出**的情况。

#### 2.2、半连接队列的大小

**半**连接队列的最大值是 `max_qlen_log` 变量 。**半连接队列最大值不是单单由 max_syn_backlog 决定，还跟 somaxconn 和 backlog 有关系。** 

- 当 max_syn_backlog > min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = min(somaxconn, backlog) * 2;
- 当 max_syn_backlog < min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = max_syn_backlog * 2;

max_qlen_log  只是一个**理论值**，并不一定等于服务端处于SYN_RECV的最大个数。

### 3、应对SYN攻击的方法

#### 3.1、SYNcookies功能

如果 SYN 半连接队列已满，不一定非要丢弃连接。 **开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接。**  

syncookies 参数主要有以下三个值：

- 0 值，表示关闭该功能；
- 1 值，表示**仅当 SYN 半连接队列放不下时**，再启用它；**应对 SYN 攻击时，只需要设置为 1 即可。**
- 2 值，表示无条件开启功能；

1、当它被设置为1的时候，客户端发来**第一次握手**SYN时，服务端**不会将其放入半连接队列中**，而是直接生成一个`cookies`；

2、这个`cookies`会跟着**第二次握手**，发回客户端。

3、客户端在发**第三次握手**的时候带上这个`cookies`，**服务端验证到它就是当初发出去的那个，就会建立连接并放入到全连接队列中**。整个过程不再需要半连接队列的参与。

> **没有cookies队列**，如果有一个cookies队列，还是会还是会被**SYN Flood 攻击**打满。
>
> 它是通过**通信双方的IP地址端口、时间戳、MSS**等信息进行**实时计算**的，保存在**TCP报头**的`seq`里。当服务端收到客户端发来的第三次握手包时，会通过seq还原出**通信双方的IP地址端口、时间戳、MSS**，验证通过则建立连接。
>

##### 3.1.1、SYNcookies方案不能替代半连接队列

**1、数据丢失，不能重传**

因为服务端并不会保存连接信息，所以如果传输过程中数据包丢了，也不会重发第二次握手的信息。

**2、编码解码，消耗CPU资源-ACK攻击**

编码解码`cookies`，都是比较**耗CPU**的，利用这一点，如果此时攻击者构造大量的**第三次握手包（ACK包）**，同时带上各种瞎编的`cookies`信息，服务端收到`ACK包`后**以为是正经cookies**，憨憨地跑去解码（**耗CPU**），最后发现不是正经数据包后才丢弃。

这种通过构造大量`ACK包`去消耗服务端资源的攻击，叫**ACK攻击**，受到攻击的服务器可能会因为**CPU资源耗尽**导致没能响应正经请求。

#### 3.2、增大半连接队列长度

**想增大半连接队列，我们得知不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大全连接队列**。否则，只单纯增大 tcp_max_syn_backlog 是无效的。增大 tcp_max_syn_backlog 和 somaxconn 的方法是**修改 Linux 内核参数**。

#### 3.3、减少SYN+ACK重传次数

当服务端受到 SYN 攻击时，就会有大量处于 SYN_RECV 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。 

### 4、半连接队列为什么是一个哈希表

**全连接队列（icsk_accept_queue）是个链表**，而**半连接队列（syn_table）是个哈希表**。

- **半连接队列（SYN队列）**，服务端收到**第一次握手**后，会将`sock`加入到这个队列中，队列内的`sock`都处于`SYN_RECV` 状态。
- **全连接队列（ACCEPT队列）**，在服务端收到**第三次握手**后，会将半连接队列的`sock`取出，放到全连接队列中。队列里的`sock`都处于 `ESTABLISHED`状态。这里面的连接，就**等着服务端执行accept()后被取出了。**

全连接队列里是等待被取走的连接，并不关心是哪个连接，只要按顺序取走就好。复杂度是O（1）。

但是半连接队需要等待第三次握手的到来，需要把**对应IP端口的连接从队列中取出。如果半连接队列还是个链表，那我们就需要依次遍历，才能拿到我们想要的那个连接，算法复杂度就是O(n)。**设计成哈希表，复杂度就会是O（1）。

## 七、TCP的性能提升

### 1、三次握手的性能提升

三次握手的过程在一个 HTTP 请求的平均时间占比 10% 以上，在网络状态不佳、高并发或者遭遇 SYN 攻击等场景中，如果不能有效正确的调节三次握手中的参数，就会对性能产生很多的影响。 客户端和服务端都可以针对三次握手优化性能。主动发起连接的客户端优化相对简单些，而服务端需要监听端口，属于被动连接方，其间保持许多的中间状态，优化方法相对复杂一些。 

#### 1.1、客户端优化

客户端在等待服务端回复的 ACK 报文，正常情况下，服务器会在几毫秒内返回 SYN+ACK ，但**如果客户端长时间没有收到 SYN+ACK 报文，则会重发 SYN 包**，重发的次数由 `tcp_syn_retries` 参数控制，默认是 5 次 。

##### 1.1.1、调整**重传时间**

通常，超时重传的间隔时间，是上一次的 2 倍，重传多次后不再重传。 可以根据网络的稳定性和目标服务器的繁忙程度**修改 SYN 的重传次数，调整客户端的三次握手时间上限**。比如内网中通讯时，就可以适当调低重试次数，**尽快把错误暴露给应用程序**。

#### 1.2、服务端优化

**1.2.1、避免SYN攻击**

我们可以通过该 `netstat -s` 命令给出的统计结果中， 可以得到由于半连接队列已满引发的失败次数。上面输出的数值是**累计值**，表示共有多少个 TCP 连接因为半连接队列溢出而被丢弃。**隔几秒执行几次，如果有上升的趋势，说明当前存在半连接队列溢出的现象**。

- **调整SYN半连接队列大小。**不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大 accept 队列。否则，只单纯增大 tcp_max_syn_backlog 是无效的。
- **开启 syncookies 功能。**以在不使用 SYN 半连接队列的情况下成功建立连接。 （SYN半连接队列已满时，不一定非要丢弃连接）
- **向客户端发送RST复位报文**，让客户端及时知道拥堵的情况（全连接队列已满时，不一定非要丢弃连接）
- **增大服务器SYN+ACK的重发次数**，可以在网络繁忙，报文丢失严重的时候，尽快建立起三次连接。
- **修改全连接队列长度**：accept 队列的长度取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)，其中：
  - somaxconn 是 Linux 内核的参数，默认值是 128，可以通过 `net.core.somaxconn` 来设置其值；
  - backlog 是 `listen(int sockfd, int backlog)` 函数中的 backlog 大小；

#### 1.3、如何绕过三次握手？

三次握手建立连接造成的后果就是，HTTP 请求必须在一个 RTT（从客户端到服务器一个往返的时间）后才能发送。

 <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/21.jpg" alt="常规 HTTP 请求" style="zoom:50%;" /><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/22.jpg" alt="开启 TCP Fast Open 功能" style="zoom:50%;" /> 

##### 1.3.1、使用TCP Fast Open功能减少TCP连接建立的时延

**首次建立连接**

1. 客户端发送 SYN 报文，该报文包含 **Fast Open 选项**，且该选项的 Cookie 为空，这表明客户端请求 Fast Open Cookie；
2. 支持 TCP Fast Open 的**服务器生成 Cookie**，并将其置于 SYN-ACK 数据包中的 Fast Open 选项以发回客户端；
3. 客户端收到 SYN-ACK 后，**本地缓存 Fast Open 选项中的 Cookie**。

所以，**第一次发起 HTTP GET 请求的时候，还是需要正常的三次握手流程**。

**客户端再次向服务器建立连接**

1. 客户端发送 SYN 报文，该报文包含**「数据」**（对于非 TFO 的普通 TCP 握手过程，SYN 报文中不包含「数据」）以及此前记录的 **Cookie**；

2. 支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验。

   - 如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「数据」递送至相应的应用程序；

   - 如果 Cookie 无效，服务器将丢弃 SYN 报文中包含的「数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；

3. 如果服务器接受了 SYN 报文中的「数据」，服务器可在握手完成之前发送「数据」，**这就减少了握手带来的 1 个 RTT 的时间消耗**；

4. 客户端将发送 ACK 确认服务器发回的 SYN 以及「数据」，但如果客户端在初始的 SYN 报文中发送的「数据」没有被确认，则客户端将重新发送「数据」；

5. 此后的 TCP 连接的数据传输过程和非 TFO 的正常情况一致。

所以，**之后发起 HTTP GET 请求的时候，可以绕过三次握手，这就减少了握手带来的 1 个 RTT 的时间消耗**。开启了 TFO 功能，cookie 的值是存放到 **TCP option 字段**里的。

##### 1.3.2、打开Fast Open 功能

在 Linux 系统中，可以通过**设置 tcp_fastopn 内核参数，来打开 Fast Open 功能**： tcp_fastopn 各个值的意义:

- 0 关闭
- 1 作为客户端使用 Fast Open 功能
- 2 作为服务端使用 Fast Open 功能
- 3 无论作为客户端还是服务器，都可以使用 Fast Open 功能。**TCP Fast Open 功能需要客户端和服务端同时支持，才有效果。**

 <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/24.jpg" alt="三次握手优化策略" style="zoom:50%;" /> 

###   2、四次挥手的性能提升

客户端和服务端双方都可以主动断开连接，**通常先关闭连接的一方称为主动方，后关闭连接的一方称为被动方。**四次挥手过程只涉及了两种报文，分别是 **FIN 和 ACK**。

#### 2.1、主动方的优化

关闭连接的方式通常有两种，分别是 **RST 报文关闭**和 **FIN 报文关闭**。

如果进程**收到 RST 报文，就直接关闭连接**了，不需要走四次挥手流程，是一个**暴力关闭连接**的方式。

安全关闭连接的方式必须通过四次挥手，它由进程调用 `close` 和 `shutdown` 函数发起 FIN 报文。

> 调用 close 函数和 shutdown 函数有什么区别？
>
> 调用了 close 函数意味着完全断开连接，**完全断开不仅指无法传输数据，而且也不能发送数据。 此时，调用了 close 函数的一方的连接叫做「孤儿连接」，如果你用 netstat -p 命令，会发现连接对应的进程名为空。**
>
> 使用 close 函数关闭连接是不优雅的。于是，就出现了一种优雅关闭连接的 `shutdown` 函数，**它可以控制只关闭一个方向的连接**。

##### 2.1.1、FIN_WAIT 1状态优化

收不到对方的ACK报文时，调整FIN的重传次数。

##### 2.1.2、FIN_WAIT 2状态优化

FIN_WAIT 2状态等待对方发送 FIN 报文，关闭对方的发送通道。

这时，**如果连接是用 shutdown 函数关闭的，连接可以一直处于 FIN_WAIT2 状态，因为它可能还可以发送或接收数据。但对于 close 函数关闭的孤儿连接，由于无法再发送和接收数据，所以这个状态不可以持续太久，而 tcp_fin_timeout 控制了这个状态下连接的持续时长**，默认值是 60 秒。

它意味着对于孤儿连接（调用 close 关闭的连接），如果在 60 秒后还没有收到 FIN 报文，连接就会直接关闭。这个 60 秒不是随便决定的，**它与 TIME_WAIT 状态持续的时间是相同的，都是2MSL（报文在网络中的最长生存时间）**。

**因为这两个状态都需要保持 2MSL 时长。MSL 定义了一个报文在网络中的最长生存时间**（报文每经过一次路由器的转发，IP 头部的 TTL 字段就会减 1，减到 0 时报文就被丢弃，这就限制了报文的最长存活时间）。相当于**至少允许报文丢失一次** 。因此，**TIME_WAIT 和 FIN_WAIT2 状态**的最大时长都是 2 MSL，由于**在 Linux 系统中，MSL 的值固定为 30 秒，所以它们都是 60 秒。**

##### 2.1.3、TIME_WAIT状态的优化

TIME-WAIT 的状态尤其重要，主要是两个原因： 

**原因一：防止历史连接中的数据，被后面相同四元组的连接错误的接收**

**原因二：保证「被动关闭连接」的一方，能被正确的关闭**

##### 1、TIME_WAIT优化方式一：超过上限，直接关闭

Linux 提供了 tcp_max_tw_buckets 参数，当 **TIME_WAIT 的连接数量超过该参数**时，新关闭的连接就不再经历 TIME_WAIT 而**直接关闭**。 

当服务器的并发连接增多时，相应地，同时处于 TIME_WAIT 状态的连接数量也会变多，此时就应当调大 `tcp_max_tw_buckets` 参数，**减少不同连接间数据错乱的概率**。tcp_max_tw_buckets 也不是越大越好，毕竟系统资源是有限的。 

##### 2、TIME_WAIT优化方式二：复用TCP

在建立新连接时，复用处于 TIME_WAIT 状态的连接，那就是打开 tcp_tw_reuse 参数。**tcp_tw_reuse 只作用在 connect 函数，也就是客户端，跟服务端一毛关系的没有**。并且需要打开TCP时间戳才能使用。由于引入了时间戳，好处有：

-  2MSL（TIME_WAIT状态的持续时间） 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃；
- 同时，它还可以防止序列号绕回，也是因为重复的数据包会由于时间戳过期被自然丢弃；

##### 3、TIME_WAIT优化方式三：跳过挥手，直接关闭

设置socket选项，设置调用 close 关闭连接行为。**那么调用 close 后，会立该发送一个 RST 标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了 TIME_WAIT 状态，直接关闭。**

这种方式只推荐在客户端使用，服务端千万不要使用。因为服务端一调用 close，就发送 RST 报文的话，客户端就总是看到 TCP 连接错误 “connnection reset by peer”。

#### 2.2、被动方的优化

##### 2.2.1、**优化1：CLOSE_WAIT状态太多时检查是否正常关闭**

被动方收到 FIN 报文时，内核会自动回复 ACK，同时**连接处于 CLOSE_WAIT 状态**，它表示等待应用进程调用 close 函数关闭连接。 因为**内核不能替线程决定何时关闭连接**。

用 netstat 命令发现大量 CLOSE_WAIT 状态。就排查应用程序，因为可能因为应用程序出现了 Bug，没有调用 close 函数。

##### 2.2.2、**优化2：LAST_ACK状态调整重发次数**

处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文关闭发送通道，同时连接进入 LAST_ACK 状态，等待主动方返回 ACK 来确认连接关闭。 

如果迟迟收不到这个 ACK，内核就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与主动方重发 FIN 报文的优化策略一致。 

#### 2.3、连接双方同时关闭连接

由于TCP是全双工协议，可能会发生这种双方同时关闭的情况。

如果在发送出FIN之后，收到的不是对方的ACK，而是对方的FIN，就会认为是同时关闭。跳过原来的FIN_WAIT_1和FIN_WAIT_2阶段，进入一个新的Closing阶段。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/38.jpg" alt="同时关闭" style="zoom:50%;" /> 

Closing阶段只要接收到对方的确认自己FIN的ACK，就可以进入TIME_WAIT阶段，即将关闭连接。

上面都是TCP握手、挥手的优化，下面是TCP连接传输速度的优化。

#### 2.4、调整滑动窗口

TCP为了解决为每个数据包确认应答的速度受限的缺点， **并行批量发送报文，再批量确认报文即可。** **但是还得考虑接收方的处理能力。**当接收方硬件不如发送方，或者系统繁忙、资源紧张时，是无法瞬间处理这么多报文的。于是，这些报文只能被丢掉，使得网络效率非常低。**为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是滑动窗口的由来。**

##### 2.4.1、窗口扩大字段

接收窗口并不是恒定不变的，接收方会把当前可接收的大小放在 TCP 报文头部中的**窗口字段**，这样就可以起到窗口大小通知的作用。 

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/42.jpg" alt="TCP 头部" style="zoom: 50%;" />

从上图中可以看到，窗口字段只有 2 个字节，因此它最多能表达 65535 字节大小的窗口，也就是 64KB 大小。这个窗口大小最大值，在当今高速网络下，很明显是不够用的。

**扩充窗口的方法**：在 **TCP 选项字段定义了窗口扩大因子**，用于扩大 TCP 通告窗口，其值大小是 2^14，这样就使 TCP 的窗口大小从 16 位扩大为 30 位（2^16 \* 2^ 14 = 2^30），所以此时窗口的最大值可以达到 1GB。

但是并不是窗口越大越好：**因为网络的传输能力是有限的，当发送方依据发送窗口，发送超过网络处理能力的报文时，路由器会直接丢弃这些报文。因此，缓冲区的内存并不是越大越好。** 

##### 2.4.2、如何确定最大传输速度？

带宽是单位时间内的流量，表达是「速度」，比如常见的带宽 100 MB/s；缓冲区单位是字节，当网络速度乘以时间才能得到字节数；

**带宽时延积**：它决定**网络中飞行报文的大小**，它的计算方式：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/44.jpg" alt="img" style="zoom:50%;" />

如果飞行报文超过了带宽时延积，就会导致网络过载，容易丢包。**由于发送缓冲区大小决定了发送窗口的上限，而发送窗口又决定了「已发送未确认」的飞行报文的上限。因此，发送缓冲区不能超过「带宽时延积」。**

- 如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的网络传输，同时导致网络过载，容易丢包；
- 如果发送缓冲区「小于」带宽时延积，就不能很好的发挥出网络的传输效率。

所以，**发送缓冲区的大小最好是往带宽时延积靠近。**

#### 2.5、调整发送缓冲区范围

在 Linux 中发送缓冲区和接收缓冲都是可以用参数调节的。设置完后，Linux 会根据你设置的缓冲区进行**动态调节**。 它的范围通过` tcp_wmem `参数配置，共有三个参数控制（单位是字节），它们分别表示：

- 第一个数值是动态范围的最小值，4096 byte = 4K；
- 第二个数值是初始默认值，16384 byte ≈ 16K；
- 第三个数值是动态范围的最大值，4194304 byte = 4096K（4M）；

**发送缓冲区是自行调节的**，当发送方发送的数据被确认后，并且没有新的数据要发送，就会把发送缓冲区的内存释放掉。

#### 2.6、调整接收缓冲区范围

设置接收缓冲区范围的 tcp_rmem 参数，一样是三个参数控制（单位是字节）：

- 第一个数值是动态范围的最小值，表示即使在内存压力下也可以保证的最小接收缓冲区大小，4096 byte = 4K；
- 第二个数值是初始默认值，87380 byte ≈ 86K；
- 第三个数值是动态范围的最大值，6291456 byte = 6144K（6M）；

#### 2.7、Linux自动调整接收缓存区

接收缓冲区可以根据系统空闲内存的大小来调节接收窗口：

- 如果系统的空闲内存很多，就可以自动把缓冲区增大一些，这样传给对方的接收窗口也会变大，因而提升发送方发送的传输数据数量；
- 反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常工作；

发送缓冲区的调节功能是自动开启的，**而接收缓冲区则需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能**。

#### 2.8、调整TCP内存范围

接收缓冲区调节时，怎么知道当前内存是否紧张或充分呢？这是通过 tcp_mem 配置完成的：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/48.jpg" alt="img" style="zoom:50%;" />

上面三个数字单位不是字节，而是「页面大小」，1 页表示 4KB，它们分别表示：

- 当 TCP 内存小于第 1 个值时，不需要进行自动调节；
- 在第 1 和第 2 个值之间时，内核开始调节接收缓冲区的大小；
- 大于第 3 个值时，内核不再为 TCP 分配新内存，此时新连接是无法建立的；

一般情况下这些值是在系统启动时根据系统内存数量计算得到的。根据当前 tcp_mem 最大内存页面数是 177120，当内存为 (177120 * 4) / 1024K ≈ 692M 时，系统将无法为新的 TCP 连接分配内存，即 TCP 连接将被拒绝。

## 八、TCP的缺陷

### 1、升级TCP的工作比较困难

TCP 协议是诞生在 1973 年，至今 TCP 协议依然还在实现更多的新特性。

但是 **TCP 协议是在内核中实现的，应用程序只能使用不能修改**，如果要**想升级 TCP 协议，那么只能升级内核**。而升级内核这个工作是很麻烦的事情，服务程序就需要回归测试是否兼容新的内核版本，所以服务器的内核升级也比较保守和缓慢。**很多 TCP 协议的新特性，都是需要客户端和服务端同时支持才能生效的**，比如 **TCP Fast Open** 这个特性，虽然在2013 年就被提出了，但是 Windows 很多系统版本依然不支持它，这是因为 PC 端的系统升级滞后很严重，Windows Xp 现在还有大量用户在使用，尽管它已经存在快 20 年。

所以，即使 TCP 有比较好的特性更新，也很难快速推广，用户往往要几年或者十年才能体验到。

### 2、TCP建立连接的延迟

基于 TCP 实现的应用协议，都是**需要先建立三次握手才能进行数据传输**，比如 HTTP 1.0/1.1、HTTP/2、HTTPS。现在大多数网站都是使用 HTTPS 的，这意味着在 TCP 三次握手之后，**还需要经过 TLS 四次握手后**，才能进行 HTTP 数据的传输，这在一定程序上增加了数据传输的延迟。

TCP 三次握手的延迟被 **TCP Fast Open （快速打开）**这个特性解决了，这个特性可以在「第二次建立连接」时减少 TCP 连接建立的时延。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/45.jpg" alt="常规 HTTP 请求 与 Fast  Open HTTP 请求" style="zoom:50%;" />

过程如下：

- 在第一次建立连接的时候，服务端在**第二次握手产生一个 `Cookie` （已加密）**并通过 SYN、ACK 包一起发给客户端，于是**客户端就会缓存这个 `Cookie`**，所以**第一次发起 HTTP Get 请求的时候，还是需要 2 个 RTT 的时延；**
- 在下次请求的时候，**客户端在 SYN 包带上 `Cookie` 发给服务端**，就提前可以跳过三次握手的过程，因为 `Cookie` 中维护了一些信息，服务端可以从 `Cookie` 获取 TCP 相关的信息，这时**发起的 HTTP GET 请求就只需要 1 个 RTT 的时延；**

### 3、TCP中存在的安全问题

针对 HTTPS 来说，**TLS 是在应用层实现的握手，而 TCP 是在内核实现的握手**，这两个握手过程是无法结合在一起的，总是得先完成 TCP 握手，才能进行 TLS 握手。因为**TCP 是在内核实现的，所以 TLS 是无法对 TCP 头部加密的**，这意味着 **TCP 的序列号都是明文传输**，所以就存安全的问题。

#### 攻击方式

<img src="https://cdn.xiaolincoding.com//mysql/other/A*po6LQIBU7zIAAAAAAAAAAAAAARQnAQ.png" alt="img" style="zoom:50%;" />

攻击者**伪造一个的 RST 报文强制关闭一条 TCP 连接**，而攻击成功的关键则是 **TCP 字段里的序列号位于接收方的滑动窗口内，该报文就是合法的。**

为此 TCP 也不得不进行三次握手来同步各自的序列号，而且初始化序列号时是采用随机的方式（不完全随机，而是随着时间流逝而线性增长，到了 2^32 尽头再回滚）来提升攻击者猜测序列号的难度，以增加安全性。这种方式**只能避免攻击者预测出合法的 RST 报文**，而无法避免攻击者截获客户端的报文，然后中途伪造出合法 RST 报文的攻击的方式。

### 4、TCP存在队头阻塞问题

TCP 是字节流协议，**TCP 层必须保证收到的字节数据是完整且有序的**，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据。只有这样做才能保证数据的有序性，但是带来了**队头阻塞**问题。

### 5、网络迁移需要重新建立TCP连接

基于 TCP 传输协议的 HTTP 协议，由于是通过**四元组（源 IP、源端口、目的 IP、目的端口）**确定一条 TCP 连接。

那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接**。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

## 九、如何基于UDP实现可靠传输？

基于 UDP 协议实现的可靠传输协议的成熟方案了，那就是 **QUIC 协议**。

### 1、QUIC实现可靠传输

要基于 UDP 实现的可靠传输协议，那么就要在应用层下功夫，也就是要**设计好协议的头部字段**。拿 HTTP/3 举例子，在 UDP 报文头部与 HTTP 消息之间，共有 3 层头部：

<img src="https://cdn.xiaolincoding.com//mysql/other/ab3283383013b707d1420b6b4cb8517c.png" alt="img" style="zoom:50%;" />

#### 1.1、Packet Header

Packet Header 首次建立连接时和日常传输数据时使用的 Header 是不同的。

<img src="https://cdn.xiaolincoding.com//mysql/other/bcf3ccb6a15c4cdebe1cd0527fdd9a5e.png" alt="Packet Header" style="zoom: 33%;" />

- Long Packet Header 用于首次建立连接。
- Short Packet Header 用于日常传输数据。

**QUIC 也是需要三次握手来建立连接的**，主要目的是为了协商连接 ID。协商出连接 ID 后，后续传输时，双方只需要固定住连接 ID，从而实现连接迁移功能。所以**日常传输数据的 Short Packet Header 不需要在传输 Source Connection ID 字段了，只需要传输 Destination Connection ID**。

#### 1.2、QUIC严格递增的编号的好处

Short Packet Header 中的 `Packet Number` 是每个报文独一无二的编号，它是**严格递增**的，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。

##### **1.2.1、优点1：解决了TCP计算RTT时重传的歧义性问题。**

在TCP连接中，发生超时重传后，**重传的报文和原始报文都是一样的序号**，这会导致**采样RTT（往返时延）的计算不准确。**重传时间RTO是根据RTT计算的，如果RTT计算的不准确，RTO也会计算的不准确，这可能会导致重传的概率事件增大。

而**QUIC的报文的Packet Number是严格递增的**，即便是重传报文也是递增的，这样RTT的计算就会很准确。 

##### 1.2.2、优点2：支持乱序确认，解决了队头阻塞问题，但是需要Stream配合

QUIC 使用的 Packet Number 单调递增的设计，可以让数据包不再像 TCP 那样必须有序确认，QUIC 支持**乱序确认**，当数据包Packet N 丢失后，**只要有新的已接收数据包确认，当前窗口就会继续向右滑动。**

QUIC会将重传的数据包放到发送队列，**重新编号**比如数据包Packet N+M 后重新发送给接收端。

#### 1.3、QUIC Frame Header

一个 Packet 报文中可以存放多个 QUIC Frame。<img src="https://cdn.xiaolincoding.com//mysql/other/6a94d41ef3d14cb6b7846e73da6c3104.png" alt="img" style="zoom:33%;" />

每一个 Frame 都有明确的类型，针对类型的不同，功能也不同，自然格式也不同。

##### 1.3.1、Stream类型的Frame格式

只关注Stream类型的Frame格式，这一形式来自于HTTP/2。Stream 可以认为就是一条 HTTP 请求，它长这样：

<img src="https://cdn.xiaolincoding.com//mysql/other/536298d2c54a43b699026bffe0f85010.png" alt="img" style="zoom:33%;" />

- Stream ID 作用：多个并发传输的 HTTP 消息，通过不同的 Stream ID 加以区别，类似于 HTTP2 的 Stream ID；
- Offset 作用：类似于 TCP 协议中的 Seq 序号，**保证数据的顺序性和可靠性**；
- Length 作用：指明了 Frame 数据的长度。

##### 1.3.2、Stream作用一：实现可靠传输

同一个Stream内的数据必须是有序的，从而实现可靠传输。通过Offset实现。

##### 1.3.3、Stream作用二：确认报文

重传的 Packet N+M 与丢失数据包的 Packet N 编号不一致，但是其中的Frame Header这一层中，**丢失的数据包和重传的数据包 Stream ID 与 Offset 都一致，说明这两个数据包的内容一致**。

##### 1.3.4、Stream作用三：配合Packet Number解决了队头阻塞问题，支持乱序确认

**QUIC 通过单向递增的 Packet Number，配合 Stream ID 与 Offset 字段信息，可以支持乱序确认而不影响数据包的正确组装**，摆脱了TCP 必须按顺序确认应答 ACK 的限制，解决了 TCP 因某个数据包重传而阻塞后续所有待发送数据包的问题。

同时，在QUCI的具体实现中，每个Stream都使用自己的滑动窗口，避免传输过程中发生了数据丢失，而滑动窗口又无法往前移动，导致阻塞住了所有的HTTP请求。

### 2、QUIC解决队头阻塞

#### 2.1、TCP的队头阻塞问题

因为**TCP设计的目的就是为了保证数据的有序性**。TCP 队头阻塞的问题，其实就是**接收窗口的队头阻塞问题**。

只有当接收窗口收到窗口内数据，并且收到有序数据时，接收窗口才能往前滑动，这之后那些已经被接收并且被确认的数据才能被读取。当接收窗口收到的数据不是有序的，比如收到第 33～40 字节的数据，由于第 32 字节数据没有收到， **接收窗口无法向前滑动**，那么即使先收到第 33～40 字节的数据，**这些数据也无法被应用层读取的**。

导致接收窗口的队头阻塞问题，是因为 **TCP 必须按序处理数据，也就是 TCP 层为了保证数据的有序性，只有在处理完有序的数据后，滑动窗口才能往前滑动，否则就停留**，停留「接收窗口」会使得应用层无法读取新的数据。

#### 2.2、HTTP中的队头阻塞问题

##### 2.2.1、HTTP1.1的队头阻塞问题-应用层的队头阻塞问题

HTTP1.1在浏览器中的同一域名的并发连接数有限，**如果连接数超过上限，排在后面的连接就需要等待前面的资源加载完成**。 过去常常出现的浏览器空白并且一直“转圈”就是因为这个问题。  

##### 2.2.2、HTTP2的队头阻塞问题-TCP的队头阻塞问题

HTTP/2中抽象出了**Stream**，通过流的多路复用，实现了**并发传输**。每个Stream都有一个自己的Stream ID，可以并行跑在一个TCP连接上面。****

- 不同Stream的帧可以乱序发送，因为每个帧的头部都有Stream ID信息，接收端可以通过Stream ID有序组装成HTTP消息。
- 同一Stream内部的帧必须严格有序。

**解决了应用层的队头阻塞，但是没有解决TCP的队头阻塞问题。**

但是 HTTP/2 多个 Stream 请求都是在一条 TCP 连接上传输，**共用同一个 TCP 滑动窗口**，那么当滑动窗口有一个位置的报文缺失，滑动窗口是无法往前移动的，此时就会阻塞住所有的 HTTP 请求，这属于 **TCP 层队头阻塞。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/quic/http2%E9%98%BB%E5%A1%9E.jpeg" alt="img" style="zoom:50%;" />

#### 2.3、没有队头阻塞的QUIC

QUIC 也借鉴 HTTP/2 里的 Stream 的概念，在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (Stream)。但是 **QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口**。

假如 Stream2 丢了一个 UDP 包，也只会影响 Stream2 的处理，不会影响其他 Stream，与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/quic/quic%E6%97%A0%E9%98%BB%E5%A1%9E.jpeg" alt="img" style="zoom:50%;" />

### 3、QUIC的流量控制

QUIC 是基于 UDP 传输的，**而 UDP 没有流量控制，因此 QUIC 实现了自己的流量控制机制**，QUIC 的滑动窗口滑动的条件跟 TCP 有一点差别，但是同一个 Stream 的数据也是要保证顺序的，不然无法实现可靠传输，因此同一个 Stream 的数据包丢失了，也会造成窗口无法滑动。

#### **3.1、TCP实现流量控制的方式**

让「接收方」告诉「发送方」，它（接收方）的接收窗口有多大，从而让「发送方」根据「接收方」的实际接收能力控制发送的数据量。

TCP 的接收窗口在收到有序的数据后，接收窗口才能往前滑动，否则停止滑动。

#### 3.2、QUIC 实现流量控制的方式

- 通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。
- 发送端通过 STREAM_DATA_BLOCKED帧告诉对端由于流量控制被阻塞了，无法发送数据。

**QUIC 的 每个 Stream 都有各自的滑动窗口，不同 Stream 互相独立，队头的 Stream A 被阻塞后，不妨碍 StreamB、C的读取**。

##### **3.2.1、Stream 级别的流量控制**

Stream 可以认为就是一条 HTTP 请求，每个 Stream 都有独立的滑动窗口，所以每个 Stream 都可以做流量控制，防止单个 Stream 消耗连接（Connection）的全部接收缓冲。

##### 3.2.2、**Connection 流量控制**

限制连接中所有 Stream 相加起来的总字节数，防止发送方超过连接的缓冲容量

### 4、QUIC的拥塞控制-在应用层，灵活性高

QUIC 协议当前默认使用了 TCP 的 Cubic 拥塞控制算法（我们熟知的慢开始、拥塞避免、快重传、快恢复策略），也支持使用其他拥塞控制算法。

QUIC 是处于**应用层**的，应用程序层面就能实现不同的拥塞控制算法，**不需要操作系统，不需要内核支持**。TCP 拥塞控制算法迭代速度很慢。而 **QUIC 可以随浏览器更新，QUIC 的拥塞控制算法就可以有较快的迭代速度**。**可以针对不同的应用设置不同的拥塞控制算法**，这样灵活性就很高。

### 5、QUIC更快的连接建立

#### 5.1、**HTTP/1、2的连接建立：**

对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，**先 TCP 握手（1RTT），再 TLS 握手（2RTT），所以需要 3RTT 的延迟才能传输数据**，就算 Session 会话服用，也需要至少 2 个 RTT。

#### 5.2、QUCI连接建立

HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。

但是 **HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS**，它**在自己的帧会携带 TLS 里的“记录”**，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。

如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT（下图的右下角）：

<img src="https://cdn.xiaolincoding.com//mysql/other/4cad213f5125432693e0e2a512c2d1a1.png" alt="img" style="zoom: 67%;" />

### 6、QUIC迁移连接

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接**。而建立连接的过程包含 **TCP 三次握手**和 **TLS 四次握手**的时延，以及 **TCP 慢启动**的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。