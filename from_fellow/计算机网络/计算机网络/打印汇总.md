## 一、TCP/IP网络模型

**分层的网络模型目的**：在不同的设备上通信需要一套**通用的网络协议**。

### 1、四层网络每一层的封装样式

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/%E5%B0%81%E8%A3%85.png" alt="img" style="zoom:50%;" /> 

## 二、网页显示过程

从键入网址，到网页信息显示的过程。

### 1、HTTP

#### 1.1、URL(Uniform resource locator，统一资源定位系统)

在键入网址后，浏览器的**第一步工作是对URL进行解析**，从而生成发送给web服务器的请求信息。

##### 1.1.1、URL元素组成

- URL开头表示访问数据的协议：HTTP、HTTPS。
- //后面的字符串表示服务器的名称。
- 之后输入web服务器名。
- 最后是数据源的路径名：/ + 目录名 + / … + 文件名。

URL实际上是在**请求服务器里的文件资源**。如果**没有路径名时，访问根目录下设置的默认文件** `/index.html` 或者 `/default.html` 这些文件，这样就不会发生混乱了。  

#### 1.2、HTTP请求

对URL进行解析后，浏览器确定了Web服务器和文件名，**第二步是生成HTTP请求信息**。

### 2、真实地址查询DNS

通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 `Web` 服务器。这要**查询服务器域名对应的 IP 地址**。

#### 2.1、DNS(Domain Name System)域名系统

用于**查询服务器域名对应的 IP 地址** ，DNS表中保存了Web服务器域名和IP之间的对应关系，**DNS的特点是只指路，不带路。**

#### 2.2、域名的层级关系

DNS中的域名都是用句点分割的，**越靠右表示层级越高。**这里的句点代表了不同层次之间的**界限**。**域名的层级关系类似一个树状结构：**

- 根 DNS 服务器（.）

- 顶级域 DNS 服务器（.com）

- 权威 DNS 服务器（server.com）

  <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/5.jpg" alt="DNS 树状结构" style="zoom:33%;" />

**根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中**。这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。客户端只要能够找到任意一台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器。

#### 2.3、DNS解析域名的工作流程

1. 客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给**本地 DNS 服务器**。
2. 本地域名服务器收到客户端的请求后：
   - 如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。
   - 如果没有，本地 DNS 会去问它的**根域名服务器**： 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。
3. 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，给出了**.com 顶级域名服务器**的地址。
4. 本地 DNS 收到顶级域名服务器的地址后，就问.com 顶级域名服务器： www.server.com 的 IP 地址。
5. 顶级域名服务器给出了 www.server.com 区域的**权威 DNS 服务器****的地址。
6. 本地 DNS 于是转向问权威 DNS 服务器，它是域名解析结果的原出处，所以称之为权威。
7. 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
8. 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。 


#### 2.4、DNS缓存

实际解析过程中，**浏览器会先查看自己的缓存**，如果没有再去访问**操作系统缓存**，如果还是没有，才会最终访问**本地DNS服务器**。

### 3、指南帮手-协议栈

通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的**协议栈**。浏览器通过**调用Socket库，委托协议栈工作。**协议栈上一半是负责收发数据的TCP和UDP协议，下面一半是IP协议控制网络包收发过程。

协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，**上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/7.jpg" alt="img" style="zoom:50%;" />

#### 3.1、IP协议

**IP中包含ICMP协议和ARP协议**：

- ICMP协议（Internet Control Message Protocol）：用于告知网络包传送过程中产生的**错误**以及各种**控制信息**。
- ARP协议（Address Resolution Protocol）：用于根据**IP地址**查询相应的以太网**MAC地址**。

IP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。 

### 4、可靠传输：TCP

HTTP 是基于 TCP 协议传输的。

#### 4.1、TCP报文头部

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/8.jpg" alt="TCP 包头格式" style="zoom: 50%;" />

- **源端口号和目标端口号**是必不可少的，标注应发给哪个应用。
- **包序号**：解决了**包乱序**问题。
- **确认号**：确认发出去对方有收到，否则应该重新发送，解决了**丢包**问题。
- **状态位**： 例如 `SYN` 是发起一个连接，`ACK` 是回复，`RST` 是重新连接，`FIN` 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。 
- **窗口大小**：实现了TCP的**流量控制**。通信双发标识自己能处理的能力，避免发送太快或者太慢。
- **拥塞控制**：控制自己发送的速度，避免网络堵塞。

#### 4.2、TCP三次握手

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="TCP 三次握手" style="zoom:33%;" /> 

- 一开始，客户端和服务端都处于 `CLOSED` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态。
- 然后客户端主动发起连接 `SYN`（同步序列编号），之后处于 **`SYN-SENT` 状态。**
- 服务端收到发起的连接，返回 `SYN`，并且 `ACK` 客户端的 `SYN`，之后处于 **`SYN-RCVD` 状态**（表示接受到了SYN报文）。
- 客户端收到服务端发送的 `SYN` 和 `ACK` 之后，发送对 `SYN` 确认的 `ACK`，之后**处于 `ESTABLISHED` 状态**，因为它一发一收成功了。
- 服务端收到 `ACK` 的 `ACK` 之后，处于 `ESTABLISHED` 状态，因为它也一发一收了。

所以三次握手目的是**保证双方都有发送和接收的能力**。

> ##### 查看TCP的连接状态
>
> 在Linux中可以通过 `netstat -napt` 命令查看TCP的连接状态。
>

#### 4.3、TCP分割数据

如果 HTTP 请求消息比较长，超过了**最大报文段长度`MSS`** 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。 

- `MTU`最大传输单元：一个网络包的最大长度，以太网中一般为 `1500` 字节。

- `MSS`最大报文段长度：**除去 IP 和 TCP 头部**之后，一个网络包所能容纳的 TCP 数据的最大长度。

  <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/11.jpg" alt="MTU 与 MSS" style="zoom: 33%;" />

- 在TCP协议中，数据会被以 `MSS` 的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。  


#### 4.4、TCP报文生成

TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 `80`， HTTPS 默认端口号是 `443`）。

在双方建立了连接后，**TCP 报文中的数据部分就是存放 HTTP 头部 + 数据**，组装好 TCP 报文之后，就需交给下面的网络层处理。

### 5、远程定位-IP

TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成**网络包**发送给通信对象。

#### 5.1、IP报头格式

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/14.jpg" alt="IP 包头格式" style="zoom: 33%;" />

- 源地址IP，即是客户端输出的 IP 地址；
- 目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。

-  **协议号：**因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的**协议号**，要填写为 `06`（十六进制），表示协议为 TCP。 
-  **TTL：生存时间值。**单位是路由器**跳数**。每次路由器转发都会-1，保证报文不会无休止发送。

#### 5.2、路由表规则

在存在多块网卡时，这个时候就需要根据**路由表**规则，来判断哪一个网卡作为源地址 IP。

1. 遍历路由表，首先用**目标地址**和**第一条目的子网掩码**进行 **与运算**，得到结果与这一条目的Destination进行比对，如果不一致匹配失败。

2. 接下来继续匹配，直到成功。

3. 比较特殊的是，目标地址和子网掩码都是 `0.0.0.0`，这表示**默认网关**。如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器，**`Gateway` 即是转发给的路由器的 IP 地址**。

### 6、两点传输MAC

生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 **MAC 头部**。

#### 6.1、MAC 头部

MAC头部是以太网使用的头部，只有三个信息：**发送方 MAC 地址**、**接收方目标 MAC 地址**和**协议类型**，用于**两点之间的传输。**一般在 TCP/IP 通信里，MAC 包头的**协议类型**只使用：

- `0800` ： IP 协议
- `0806` ： ARP 协议

**发送方**的 MAC 地址：MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。

**接收方**的 MAC 地址：通过路由表获取接收方的IP地址后，**通过ARP协议获取MAC地址**。

#### 6.2、ARP协议

ARP协议将IP地址转换为MAC地址：ARP 协议会在以太网中以**广播**的形式，对以太网所有的设备进行询问，对应IP的设备就会回应自己的MAC地址。 

#### 6.3、ARP缓存

每次**操作系统**会将本次查询结果放入缓存，在查询时先查询缓存，不存在的话就发送ARP广播。在发包时：

- 先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。
- 而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。 

### 7、网卡-出口

网卡将**数字信息转换为电信号**，才能在网线上传输。

控制网卡靠**网卡驱动程序**。网卡驱动获取网络包之后，会将其**复制**到网卡内的缓存区中，接着会在其**开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/%E6%95%B0%E6%8D%AE%E5%8C%85.drawio.png" alt="数据包" style="zoom: 67%;" /> 

- 起始帧分界符是一个用来表示包起始位置的标记；
- 末尾的 `FCS`（帧校验序列）用来检查包传输过程是否有损坏；

### 8、交换机-送别者

交换机的设计是将网络包**原样**转发到目的地。交换机工作在 MAC 层，也称为**二层网络设备**。 

#### 8.1、交换机工作流程

1. 电信号到达网线接口，交换机里的模块进行接收，并将**电信号转换为数字信号**。

2. 然后通过包末尾的 **`FCS` 校验错误**，如果没问题则**放到缓冲区**。

3. 与网卡不同的是，**交换机的端口不具有MAC地址**，因此还需要检查这个包的接收方MAC地址是否在自己的MAC地址表中有记录。如果有就发送到对应的端口。


#### 8.2、找不到指定的MAC地址

**交换机的 MAC 地址表**主要包含两个信息：**设备的 MAC 地址**；这个设备连接的**交换机端口号**。

**原因：**地址表中找不到指定的 MAC 地址。这可能是因为**具有该地址的设备还没有向交换机发送过包**，或者这个设备**一段时间没有工作**导致地址被从地址表中删除了。 

**处理方式：**将这个包转发给所有除了源端口之外的其他端口，**只有相应的接收者才接收包，而其他设备则会忽略这个包。**如果得到响应之后，就会把这个MAC地址写入MAC表，下一次就不用广播了。

**以太网的设计本来就是将包发送到整个网络的**，这样做很合适。 

> **以太网：**电脑上的以太网接口，Wi-Fi接口，以太网交换机、路由器上的千兆，万兆以太网口，还有网线，它们都是以太网的组成部分。

#### 8.3、广播地址

如果接收方 MAC 地址是一个**广播地址**，那么交换机会将包发送到除源端口之外的所有端口。以下两个属于广播地址：

- MAC 地址中的 `FF:FF:FF:FF:FF:FF`
- IP 地址中的 `255.255.255.255`

### 9、路由器-出境大门

网络包经过交换机之后，现在到达了**路由器**，并在此被转发到下一个路由器或目标设备。现在的路由器大多也具有了交换机的功能。

#### 9.1、路由器和交换机的区别

- 因为**路由器**是基于 IP 设计的，俗称**三层**网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；
- 而**交换机**是基于以太网设计的，俗称**二层**网络设备，交换机的端口不具有 MAC 地址。

#### 9.2、路由器的基本原理

- 路由器的**端口具有 MAC 地址**，因此它就**能够成为以太网的发送方和接收方**；

- 同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。

当转发包时，首先路由器端口会接收发给自己的以太网包，然后**路由表**查询转发目标，再由相应的端口作为发送方将以太网包发送出去。

#### 9.3、路由器接收包

1. 首先，电信号到达网线接口部分，路由器中的模块会**将电信号转成数字信号**，然后**通过包末尾的 `FCS` 进行错误校验。**

2. 如果没问题则**检查 MAC 头部中的接收方 MAC 地址**，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。


总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。

#### 9.4、查询路由表确定输出端口

1、完成包接收操作之后，路由器就会**去掉**包开头的 MAC 头部。**MAC 头部的作用就是将包送达路由器**，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会**被丢弃**。

2、接下来，路由器会根据 MAC 头部后方的 `IP` 头部中的内容进行包的转发操作。 转发操作分为几个阶段：

  - 首先是查询**路由表**判断转发目标。 根据包的接收方 IP 地址**查询路由表中的目标地址栏，以找到相匹配的记录**。 路由表：

    <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/24.jpg" alt="路由器转发" style="zoom:50%;" /> 

  - 每个条目的子网掩码和 `192.168.1.100` IP 做 **& 与运算**后，得到的结果与对应条目的目标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续与下个条目进行路由匹配。

  - 实在找不到匹配路由时，就会选择**默认路由**，路由表中子网掩码为 `0.0.0.0` 的记录表示「默认路由」。 

#### 9.5、路由器的发送操作

1. 根据**路由表的网关列**判断对方的地址。

   - 如果**网关是一个 IP 地址**，则这个IP 地址就是我们要转发到的目标地址，**还未抵达终点**，还需继续需要路由器转发。

   - 如果**网关为空**，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明**已抵达终点**。

2. 知道对方的 IP 地址之后，**接下来需要通过 `ARP` 协议根据 IP 地址查询 MAC 地址**，并将查询的结果作为接收方 MAC 地址。路由器也有 ARP 缓存，因此**首先会在 ARP 缓存中查询**，如果找不到则发送 ARP 查询请求。

3. 网络包完成后，接下来会将其**转换成电信号并通过端口发送出去**。发送出去的网络包会**通过交换机到达下一个路由器**。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。

4. 接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。

在网络包传输的过程中，**源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址**，因为需要 MAC 地址在以太网内进行**两个设备**之间的包传输。 

### 10、服务端与客户端-互相扒皮

1. 数据包抵达服务器后，服务器会先扒开数据包的 **MAC 头部**，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。 

2. 接着继续扒开数据包的 **IP 头**，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 **TCP 协议**。 

3. 于是，扒开 **TCP 的头**，里面有**序列号**，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。**TCP头部里面还有端口号**， **HTTP 的服务器正在监听这个端口号。** 

4. 于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 **HTTP 进程**。

   服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 **HTTP 响应报文**里。

5. **HTTP 响应报文**也需要**穿上 TCP、IP、MAC 头部**，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。 

6. 客户端同样的接收这个报文，获取数据。

7. 最后，客户端要离开了，向服务器发起了 **TCP 四次挥手**，至此双方的连接就断开了。 

### 11、其他网络问题

#### 1、如果发送的包不是本地局域网中的，怎样填写MAC地址？

如果目标主机不是本地局域网，**填入的MAC地址是路由器**，也就是把数据包转发给路由器，路由器一直转发下一个路由器。直到转发到目标主机的路由器，**发现 IP 地址是自己局域网内的主机**，就会 arp 请求获取目标主机的 MAC 地址，从而转发到这个服务器主机。 

转发的过程中，**源IP地址和目标IP地址是不会变**的（前提：没有使用 NAT 网络的），**源 MAC 地址和目标 MAC 地址是会变化**的。 

## 三、Linux网络

### 1、OSI网络模型

国际标准化组织制定了开放式系统互联通信参考模型（*Open System Interconnection Reference Model*），也就是 **OSI 网络模型**，该模型主要有 7 层，分别是**应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层。** 

每一层负责的职能不同：

- 应用层：负责给应用程序提供统一的接口。
- 表示层：负责把数据转换成兼容另一个系统能识别的格式。
- 会话层：负责建立、管理和中止表示层实体之间的通信会话。
- 传输层：负责端到端的数据传输，
- 网络层：负责数据的路由、转发、分片。
- 数据链路层：负责数据的封帧和差错检测，以及MAC寻址。
- 物理层：负责在物理网络中传输数据帧。

### 2、TCP/IP模型

但是OSI模型太复杂，难以具体实现，**更常用的是TCP/IP网络模型：**

- 应用层：负责向用户提供一组应用程序，比如HTTP、DNS、FTP等。

- 传输层：负责**端到端**的通信，比如TCP、UDP。

- 网络层：负责**网络包的封装、分片、路由、转发**，比如IP、ICMP。

- 网络接口层：负责网络包**在物理网络中的传输**，比如网络包的封帧、MAC寻址，差错检测，以及网卡传输网络帧等。

  <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/OSI%E4%B8%8ETCP.png" alt="img" style="zoom: 50%;" /> 

### 3、Linux网络协议栈

#### 3.1、各层增加的部分

- 传输层：给应用数据前面增加了TCP头。

- 网络层：给TCP数据包增加了IP头。

- 网络接口层：给IP数据包前后分别增加了帧头和帧尾。

  <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/%E5%B0%81%E8%A3%85.png" alt="img" style="zoom:50%;" />

在增加了报头后，需要注意不能超过**最大传输单元MTU**的限制（是物理链路层的限制，以太网中是1500字节，也就规定了单次传输的最大 IP 包大小）如果超过了就会对报文进行切片。如果 MTU 越小，需要的分包就越多，那么网络吞吐能力就越差，相反的，如果 MTU 越大，需要的分包就越少，那么网络吞吐能力就越好。

#### 3.2、网络协议栈

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/%E5%8D%8F%E8%AE%AE%E6%A0%88.png" alt="img" style="zoom: 50%;" /> 

- 应用程序通过系统调用，和Socket层进行数据交互。
- Socket下是传输层，网络层，网络接口层。
- 最下面的一层是网卡驱动程序和硬件网卡设备。

#### 3.3、Linux网络技术

##### 3.3.1、DMA技术

网卡接受到一个网络包：通过DMA技术（Direct Memory Access，**DMA是直接存储器访问**的缩写。可以让**外设直接访问内存，数据传输交给DMA控制器完成，减少了CPU的负担**），将网络包写入到**Ring Buffer环形缓冲区**，告知操作系统这个网络包已经到达，告知方式就是NAPI机制。

##### 3.3.2、NAPI 机制

告知网络包到达的一种方式是触发中断。但是**频繁中断要求CPU处理每个传入的数据包，导致CPU使用率高**。

所以为了解决频繁中断带来的性能开销，Linux 内核在 2.6 版本中引入了 **NAPI 机制**，它是**混合「中断和轮询」**的方式来接收网络包，**不采用中断的方式读取数据**，而是首先**采用中断唤醒数据接收的服务程序，然后 `poll` 的方法来轮询数据。** 

NAPI能够**延迟处理**传入的数据包，使得驱动程序可以在单个中断处理多个数据包。

因此，当有网络包到达时，会通过 DMA 技术，将网络包写入到指定的内存地址，接着**网卡向 CPU 发起硬件中断**，当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数。

##### 3.3.3、硬件中断处理函数

硬件中断处理函数会做如下的事情：

- 需要先**「暂时屏蔽中断」**，表示已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，**避免 CPU 不停的被中断**。
- 接着，发起**「软中断」**，然后**恢复刚才屏蔽的中断。**

至此，硬件中断处理函数的工作就已经完成。硬件中断处理函数做的事情很少，主要耗时的工作都交给软中断处理函数了。

##### 3.3.4、软中断的处理

内核中的 ksoftirqd 线程专门负责软中断的处理，当 ksoftirqd 内核线程收到软中断后，就会来**轮询处理数据**。

ksoftirqd 线程会从 **Ring Buffer 中获取一个数据帧**，用 sk_buff 表示，从而可以作为一个网络包交给网络协议栈进行逐层处理。

#### 3.4、Linux接收网络包

1. **网络接口层**：在这一层会**检查报文的合法性**，如果不合法则丢弃，合法则会找出该网络包的上层协议的类型，比如是 IPv4，还是 IPv6，接着再**去掉帧头和帧尾，然后交给网络层**。

2. **网络层**：则取出 IP 包，判断网络包下一步的走向，比如是**交给上层处理还是转发出去**。当确认这个网络包要发送给本机后，就会从 IP 头里看看上一层协议的类型是 TCP 还是 UDP，接着**去掉 IP 头，然后交给传输层**。

3. **传输层：**取出 TCP 头或 UDP 头，根据四元组「源 IP、源端口、目的 IP、目的端口」 作为标识，找出对应的 Socket，并把**数据放到 Socket 的接收缓冲区**。

4. **应用层：**程序调用 Socket 接口，**将内核的 Socket 接收缓冲区的数据「拷贝」到应用层的缓冲区**，然后唤醒用户进程。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/%E6%94%B6%E5%8F%91%E6%B5%81%E7%A8%8B.png" alt="img" style="zoom:50%;" /> 

#### 3.5、Linux发送网络包

1. **应用层**：应用程序会**调用 Socket 发送数据包的接口**，由于这个是**系统调用**，所以会**从用户态陷入到内核态中的 Socket 层**，内核会申请一个内核态的 sk_buff 内存，**将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区**。 接下来，网络协议栈从 Socket 发送缓冲区中取出 sk_buff，并按照 TCP/IP 协议栈从上到下逐层处理。 

2. **传输层**：如果使用的是 TCP 传输协议发送数据，那么**先拷贝一个新的 sk_buff 副本** ，这是因为 sk_buff 后续在调用网络层，最后到达网卡发送完成的时候，这个 sk_buff 会被释放掉。而 TCP 协议是支持**丢失重传**的，在收到对方的 ACK 之前，这个 sk_buff 不能被删除。所以内核的做法就是每次调用网卡发送的时候，实际上传递出去的是 sk_buff 的一个拷贝，等收到 ACK 再真正删除。接着，**对 sk_buff 填充 TCP 头**。

   > 为什么每一层都用 sk_buff 这**同一个数据结构**？
   >
   > 在每一层传递时，都是用sk_buff这一个统一的结构体，避免了各层在增加和删去报头时的重复拷贝。
   >
   > 在各层之间切换sk_buff的使用时，是**通过调整 sk_buff 中 `data` 的指针**：
   >
   > - 当接收报文时，从网卡驱动开始，通过协议栈层层往上传送数据报，通过增加 skb->data 的值，来逐步剥离协议首部。
   >
   > - 当要发送报文时，创建 sk_buff 结构体，数据缓存区的头部预留足够的空间，用来填充各层首部，在经过各下层协议时，通过减少 skb->data 的值来增加协议首部。 

3. **网络层**：**选取路由、填充IP头、对超过MTU大小的数据包进行分片**。 处理完这些工作后会交给网络接口层处理。

4. **网络接口层**：通过 ARP 协议获得下一跳的 MAC 地址，然后**对 sk_buff 填充帧头和帧尾**，接着将 sk_buff 放到**网卡的发送队列**中。  

5. 接下来会触发**「软中断」**告诉网卡驱动程序，这里有新的网络包需要发送，驱动程序会**从发送队列中读取 sk_buff**，将这个 sk_buff **挂到 RingBuffer 中**，接着**将 sk_buff 数据映射到网卡可访问的内存 DMA 区域**，最后触发真实的发送。 

6. 在发送完成后，网卡设备触发一个**硬中断**释放内存，**释放sk_buff内存和清理Ring Buffer内存**。

7. 最终，收到TCP报文的**ACK应答**后，传输层**释放原始的sk_buff**。

##### 3.5.1、发送网络数据时发生的内存拷贝

1. 第一次拷贝，调用发送数据的系统调用时，内核会申请一个内核态的sk_buff内存，将**用户待发送的数据拷贝到sk_buff内存**，并将其发送到缓冲区。
2. 第二次拷贝，在使用TCP传输协议时，从传输层进入网络层，每一个**sk_buff都会被克隆成一个新的副本**送往网络层。为了实现TCP的可靠传输，TCP的原始sk_buff还在保存。
3. 第三次拷贝，当**IP层发现sk_buff大于MTU**时才需要进行，会再**申请额外的sk_buff，并将原来的sk_buff拷贝为多个sk_buff。**

## 四、HTTP基本概念

### 1、HTTP

HTTP：HyperText Transfer Protocol，超文本传输协议。

**HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。** 

### 2、HTTP状态码

### <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" alt=" 五大类 HTTP 状态码 " style="zoom:50%;" /> 

2.1、`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

2.2、`2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

- 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
- 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
- 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

2.3、`3xx` 类状态码表示客户端请求的资源发生了变动，需要**客户端用新的 URL 重新发送请求获取资源**，也就是**重定向**。

- 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
- 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。
- **「304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称**缓存重定向**，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

2.4、`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

- 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
- 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
- 「**404 Not Found**」表示**请求的资源在服务器上不存在或未找到**，所以无法提供给客户端。

2.5、`5xx` 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于**服务器端的错误码**。

- 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
- 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
- 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
- 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。

### 3、HTTP常见字段

3.1、Host字段：用于在客户端发送请求时，**指定服务器的域名**，实现将请求发往同一台服务器上的不同网站。

Host：www.A.com

3.2、Content-Length字段：表明本次回应的数据长度。 **HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题**（因为HTTP是基于TCP传输的，所以会有粘包问题）。 

3.3、Connection字段：Connection字段最常用于客户端要求服务器使用“**HTTP长连接**”机制，以便其他请求复用。

HTTP长连接指的是只要其中一方没有要求中断连接，便保持连接。

3.4、Content-Type字段：Content-Type字段用于服务器回应时，告诉客户端，本次数据是什么格式。

```text
Content-Type: text/html; charset=utf-8
```

上面的类型表明，发送的是网页，而且编码是UTF-8。 

客户端请求的时候，可以使用 `Accept` 字段声明自己可以接受哪些数据格式。 

3.5、Content-Encoding字段：Content-Encoding字段说明**数据的压缩方法**，表示服务器返回的数据使用了什么压缩格式。

```text
Content-Encoding: gzip
```

上面表示服务器返回的数据采用了 gzip 方式压缩，告知客户端需要用此方式解压。

客户端在请求时，用 `Accept-Encoding` 字段说明自己可以接受哪些压缩方法。

### 4、Get和Post

#### 4.1、GET和POST的区别

- **GET的语义是从服务器获取指定的资源**。**GET 方法是安全、幂等、可被缓存的。** GET 请求的参数位置一般是**写在 URL 中**，URL 规定只能支持 ASCII，所以 GET 请求的参数**只允许 ASCII 字符** ，而且浏览器会对 URL 的**长度有限制**（HTTP协议本身对 URL长度并没有做任何规定）。 
- **POST的语义是请求负荷（报文body）对指定的资源做出处理**。**POST 不安全，不幂等，（大部分实现）不可缓存**。  POST 请求携带数据的位置一般是**写在报文 body 中**， body 中的数据可以是**任意格式**的数据，只要客户端与服务端协商好即可，而且浏览器**不会对 body 大小做限制**。 

#### 4.2、安全和幂等

安全：在HTTP协议里，安全指的是请求方法不会破坏服务器的资源。

幂等：多次执行相同的操作，结果都是相同的。

**GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，**可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签**。

**POST** 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。所以，**浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签**。

但是实际在使用中，可以用GET方法实现新增和删除，GET方法会变得不安全，不幂等。POST方法也可以用于查询，就是安全且幂等的。

## 五、HTTP缓存技术

对于一些重复的HTTP请求，如果每次得到的数据都是一样的，可以把“请求-响应”的数据缓存在本地。两种实现方式：

### 1、强制缓存

**强制缓存**：**只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。** 

强制缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的：

利用Cache-Control表示相对时间；Expires表示绝对时间。这两者同时出现时，Cache-Control优先级高于Expires。

具体流程如下：

- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；
- 浏览器再次请求访问服务器中的该资源时，会先**通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期**，如果没有，则使用该缓存，否则重新请求服务器；
- 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。

### 2、**协商缓存**

**协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存**。某些请求的响应码是 `304`（缓存重定向），这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。协商缓存有两种实现方式：

2.1、可以通过请求头部中的 `If-Modified-Since` 字段与响应头部中的 `Last-Modified` 字段实现 。**是基于时间实现的 。**

  - 响应头部中的 `Last-Modified`：标示这个响应资源的最后修改时间；
  - 请求头部中的 `If-Modified-Since`：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。

2.2、请求头部中的 `If-None-Match` 字段与响应头部中的 `ETag` 字段。 **是基于一个唯一标识实现的。**

  - 响应头部中 `Etag`：**唯一标识响应资源**；
  - 请求头部中的 `If-None-Match`：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。

2.3、带上了 ETag 和 Last-Modified 字段信息给服务端，**这时 Etag 的优先级更高**。因为ETag 主要能解决 Last-Modified 几个比较难以解决的问题：

1. 在**没有修改文件内容情况下文件的最后修改时间可能也会改变**，这会导致客户端认为这文件被改动了，从而重新请求；
2. 可能有些文件是在**秒级以内修改**的，`If-Modified-Since` 能检查到的粒度是秒级的，使用 Etag就能够保证这种需求下客户端在 1 秒内能刷新多次；
3. 有些服务器不能精确获取文件的最后修改时间。

### 3、强制缓存和协商缓存的工作流程

**只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求**。  

当使用 ETag 字段实现的协商缓存的过程：

- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，**在 Response 头部加上 ETag 唯一标识**，这个唯一标识的值是根据当前请求的资源生成的；

- 当浏览器再次请求访问服务器中的该资源时，首先会**先检查强制缓存是否过期**：

  - 如果没有过期，则直接使用本地缓存；
  - 如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 **ETag 唯一标识**；

- 服务器再次收到请求后，会根**据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较：**

  - **如果值相等，则返回 304 Not Modified，不会返回资源**；
  - 如果不相等，则**返回 200 状态码和返回资源**，并在 Response 头部加上**新的 ETag 唯一标识；**

- 如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。

## 六、HTTP特性

### 1、HTTP/1.1的优点

- **简单**

  HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，**易于理解**，降低了学习和使用的门槛。 

- **灵活、易于扩展**

  HTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**。 同时 HTTP 由于是工作在应用层（ `OSI` 第七层），则它**下层可以随意变化**，比如：

  - **HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层**；
  - HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。

- **应用广泛，跨平台**


### 2、HTTP/1.1的缺点

- 无状态双刃剑：

  好处是服务器不会记忆HTTP的状态，减少了服务器负担。坏处是完成有关联性的操作都非常的麻烦。例如购物过程中每一环节都需要用户信息，询问次数会特别多，因此使用了**Cookie技术**来弥补。

  `Cookie` 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。 

- 明文传输双刃剑：

  优点是传输的信息**方便阅读，便于调试**。缺点是带来了**安全问题**。

- 不安全：

  - 通信使用明文（不加密），**内容可能会被窃听**。比如，账号信息容易泄漏。
  - 不验证通信方的身份，因此有可能**遭遇伪装**。比如，访问假的淘宝、拼多多。
  - 无法证明报文的完整性，所以**有可能已遭篡改**。比如，网页上植入垃圾广告。

  **HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层**，使得在安全上达到了极致。 

### 3、HTTP/1.1的性能

HTTP 协议是基于 **TCP/IP**，并且使用了「**请求 - 应答**」的通信模式，所以性能的关键就在这**两点**里。 

- **长连接**：

  HTTP/1.1提出了长连接的通信方式。 只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。减少了过多的TCP连接次数。

- **管道网络传输**：

  HTTP/1.1 采用了长连接的方式，这使得管道（pipeline）网络传输成为了可能。

  即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以**减少整体的响应时间。**但是**服务器必须按照接收请求的顺序发送对这些管道化请求的响应**。

  如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住，这称为「队头堵塞」。所以，**HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞**。

- **响应的队头阻塞**：

  因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「**队头阻塞**」。


## 七、HTTP与HTTPS

### 1、HTTP和HTTPS的区别

- HTTP是**明文传输**。HTTPS在TCP和HTTP网络层之间加入了**SSL/TLS安全协议**，使得报文能够**加密传输**。
- HTTP只需要TCP三次握手，HTTPS在此基础上**还进行SSL/TLS握手过程**。
- HTTP**默认端口80**，HTTPS**默认端口是443**。
- HTTPS协议需要向CA（证书权威机构）**申请数字证书**，保证服务器的身份是可信的。

### 2、HTTP存在的风险

- **窃听风险**：通信链路可以获取通信内容。HTTPS通过**信息加密**解决。使用**混合加密**。
- **篡改风险**：强制植入垃圾信息。HTTPS通过**校验机制**解决。使用**摘要算法**。
- **冒充风险**：冒充假网站。HTTPS通过**身份证书**解决。将服务器公钥放入**数字证书**。HTTP**S** 在 HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议，可以很好的解决了上述的风险。

### 3、HTTPS如何解决三个风险

#### 3.1、混合加密（保证消息的完整性）

##### 3.1.1、对称加密

**加密和解密使用相同的密钥**，在通信时还需将传输密钥给对方用来解密，密钥传输过程中同样可能被截获。

##### 3.1.2、非对称加密

使用**一对非对称的密钥**，一把叫做**公开密钥**，一把叫做**私有密钥**，其中公开密钥可以随意发送，私有密钥必须保密。发送密文的一方要使用对方的公开密钥进行加密，对方收到信息之后，使用自己的私有密钥进行解密，这种方式不需要传输用来解密的私钥了，也就不必担心私钥被截获。

- HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式： 
  - 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。
  - 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。
- 采用「混合加密」的方式的原因：
  - **对称加密**只使用一个密钥，**运算速度快**，密钥必须保密，**无法做到安全的密钥交换**。
  - **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

#### 3.2、摘要算法+数字签名（解决消息来源的可靠性）

- 在计算机里会**用摘要算法（哈希函数）来计算出内容的哈希值**，这个**哈希值是唯一的，且无法通过哈希值推导出内容**。

  但存在一个问题：只能保证消息准确，但不能保证消息来源：通过哈希算法可以确保内容不会被篡改，**但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明**。 

- 用**非对称加密算法（私钥加密、公钥解密）**来解决，共有两个密钥：

  - 一个是公钥，这个是可以公开给所有人的；
  - 一个是私钥，这个必须由本人管理，不可泄露。

  这两个密钥可以**双向加解密**的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容。 流程的不同，意味着目的也不相同：

  - **公钥加密，私钥解密**。这个目的是为了**保证内容传输的安全**，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；
  - **私钥加密，公钥解密**。这个目的是为了**保证消息不会被冒充**，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。

  **数字签名算法**就是通过私钥加密、公钥解密的方式，确认消息的身份。主要是对内容的哈希值加密。

#### 3.3、数字证书（防止地址伪造）

- 服务器必须把自己的公钥注册到**CA（数字证书认证机构）**。CA用自己的私钥将服务器的公钥数字签名，将**服务器的个人信息+公钥+数字签名打包成一个数字证书**。
- 客户端拿到服务器的数字证书之后，需要**使用CA的公钥进行确认服务器数字证书是否真实**。
- 最后，客户端在获取到服务器公钥后，使用它对报文进行加密后发送。

 <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/22-%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="数子证书工作流程" style="zoom:67%;" /> 

### 4、HTTPS是如何建立连接的

#### 4.1、SSL/TLS协议基本流程

- 客户端向服务端**索要并验证服务器的公钥**。
- 双方使用**非对称加密**协商生产”**会话密钥**“。
- 双方采用**”会话密钥“对称加密**进行加密通信。

前两步就是TLS握手阶段，涉及四次通信。常用的密钥交换算法有：RSA算法和ECDHE算法。

#### 4.2、基于 RSA 算法的TLS协议建立的详细流程

1. Client Hello请求： 由**客户端向服务器发起加密通信请求**。

   - 客户端向服务器发送客户端支持的TLS协议版本；

   - 客户端生产的随机数Client Random；

   - 客户端支持的密码套件列表（如RSA加密算法）。

2. SeverHello：**服务器收到客户端请求后，向客户端发出响应。**确认TLS协议版本，如果浏览器不支持，关闭加密通信。

   - 服务其生产的随机数Server Random；


      - 确认密码套件列表。


      - 服务器的数字证书。

3. 客户端回应。客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 **CA 公钥，确认服务器的数字证书的真实性。**

   如果证书没有问题，客户端会**从数字证书中取出服务器的公钥**，然后使用它加密报文，向服务器发送如下信息：

   - 一个随机数pre-master key，该随机数会被服务器公钥加密。

   - 加密通信算法改变通知，表示随后的信息都将用”会话密钥“加密通信。

   - 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。 

   **服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」**。 

4. 服务器最后响应。服务器收到客户端的第三个随机数（`pre-master key`）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发送最后的信息：

   - 加密通信算法改变通知。随后的信息都将用”会话密钥“加密通信。

   - 服务器握手结束通知，表示服务器的握手阶段已经结束。

至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。 

#### 4.3、客户端校验数字证书的流程 - 私钥加密，公钥解密

##### 4.3.1、CA签发证书的过程

- 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 **Hash 值**；
- 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 **CA 对证书做了签名**；
- 最后将 **Certificate Signature 添加在文件证书上，形成数字证书**；

##### 4.3.2、客户端校验证书流程：

- 首先客户端会使用**同样的 Hash 算法**获取该证书的 Hash 值 H1；
- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以**使用 CA 的公钥解密** Certificate Signature 内容，得到一个 Hash 值 H2 ；
- 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。

### 5、HTTPS保证数据完整性

TLS在实现上分为 **握手协议**和**记录协议**两层： 

- **TLS 握手协议**就是我们前面说的 TLS 四次握手的过程，负责**协商加密算法和生成对称密钥**，后续用此密钥来保护应用程序数据（即 HTTP 数据）；
- **TLS 记录协议**负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议；TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证。

压缩过程：

- 首先，消息被分割成多个较短的片段,然后分别对每个片段进行压缩。

- 接下来，经过压缩的片段会加上**消息认证码（MAC 值**，这个是通过哈希算法生成的），这是为了**保证完整性，并进行数据的认证**。通过附加消息认证码的 MAC 值，可以**识别出篡改**。

  与此同时，为了**防止重放攻击**（攻击者发送一个目的主机已经接收过的包，因为是已经接收过的，片段，所以会直接通过认证，会破坏认证的正确性），在计算消息认证码时，还加上了片段的编码。

- 再接下来，经过压缩的片段再加上消息认证码会**一起通过对称密码进行加密**。

- 最后，上述经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。

 记录协议完成后，最终的报文数据将传递到传输控制协议 (TCP) 层进行传输。

## 八、HTTP/1.1、HTTP/2、HTTP/3演变与优化

### 1、HTTP/1.1相比HTTP/1.0改进

- 使用**长连接**的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持**管道**网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。解决了**请求的队头堵塞问题**，但是还有应答的队头阻塞问题。

### 2、HTTP/1.1的性能瓶颈

- **请求 / 响应头部（Header）未经压缩**就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
- **首部冗余**：每次互相发送相同的首部造成的浪费较多；
- **应答的队头阻塞：**服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据。
- 没有请求优先级控制；
- 请求**只能从客户端开始**，服务器只能被动响应。

### 3、HTTP1.1的优化思路

#### 3.1、尽量避免发送 HTTP 请求

使用**缓存技术**。将具有重复性的HTTP请求，将“请求-响应”的数据缓存在本地，下次访问时直接读取本地的数据。

##### 3.1.1、缓存形成方式

-  客户端会把第一次请求以及响应的数据保存在本地磁盘上，其中将请求的 **URL 作为 key，而响应作为 value**，两者形成映射关系。 
-  这样当后续发起相同的请求时，就可以先在本地磁盘上**通过 key 查到对应的 value**，也就是响应，如果找到了，就直接从本地读取该响应。 

##### 3.1.2、缓存正确性保证

**强制缓存与协商缓存**，查看HTTP缓存技术中的内容。

#### 3.2、减少HTTP请求次数

##### 3.2.1、减少重定向请求

资源迁移后，客户端会收到服务端的重定向响应，这导致了多次发送HTTP请求。可以把重定向规则交给代理服务器，减少重定向的次数。

##### 3.2.2、合并请求

多个小文件的请求合并成一个大请求，传输的数据不变，但是减少了重复发送的HTTP头部。

- **CSS Image Sprites技术**：将网页上的多个小图标，合并成一个大图片来请求，之后再切割使用。
- **webpack打包工具**：将js、css等资源文件打包成大文件。
- **base64编码**：将图的二进制信息使用base64编码后，以URL形式跟随HTML文件一起发送。

这样做有一个缺点：如果一个小文件发生了变化，整个大文件也需要重新下载，网络消耗大。

##### 3.2.3、延迟发送请求

请求网页时，不必要直接获取全部资源，只获取用户看到的这部分。

#### 3.3、减少服务器的 HTTP 响应的数据大小

##### 3.3.1、无损压缩

使用**霍夫曼编码**压缩数据。根据字符出现频率进行统计，再构建对应的霍夫曼树，得到每个字符的霍夫曼编码，这样全部数据的码量就是最少的。

##### 3.3.2、有损压缩

- HTTP请求头部的Accept字段中的q质量因子，告诉服务器期望的图像质量。
- **WebP**格式压缩网页格式。
- 音视频由于每帧有时序关系，只需要在一个静态的关键帧，使用**增量数据**来表达后续的帧，这样便减少了很多数据，提高了网络传输的性能

### 4、HTTP/2的改进

**HTTP/2 协议是基于 HTTPS 的**，所以 HTTP/2 的安全性也是有保障的。 

#### 4.1、**头部压缩**

HTTP/2 会**压缩头**。如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的部分**。HTTP/2 头部的编码通过「静态表、动态表、Huffman 编码」共同完成的。

**`HPACK` 算法**：在客户端和服务器同时维护一张**头信息表**，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。

##### 4.1.1、静态表编码

HTTP/2 为高频出现在头部的字符串和字段建立了一张**静态表**，它是写入到 HTTP/2 框架里的，不会变化的。在统计大量的 HTTP 头部后，HTTP/2 根据出现频率将 ASCII 码编码为了 Huffman 编码表，可以在 RFC7541 文档找到这张**静态 Huffman 表**。

##### 4.1.2、动态表编码

在静态表范围内的头部字符串就要自行构建**动态表**，它的 Index 从 `62` 起步，会在编码解码的时候随时更新。

#### 4.2、二进制帧

HTTP/2将 HTTP/1 的文本格式改成二进制格式传输数据，极大提高了 HTTP 传输效率，而且二进制数据使用位运算能高效解析。头信息和数据体都是二进制，并且统称为**帧（frame）**：**头信息帧（Headers Frame）和数据帧（Data Frame）**。 

头信息帧中存放帧长度、流标识等。数据帧中存放使用**HPACK算法**压缩的头部和包体。

#### 4.3、并发传输

HTTP/2 引出了 **Stream** 概念，**多个 Stream 复用在一条 TCP 连接**。

##### 4.3.1、HTTP/2的数据格式

- **1 个 TCP 连接包含一个或者多个 Stream**，Stream 是 HTTP/2 并发的关键技术；
- **Stream 里可以包含 1 个或多个 Message**，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成；
- **Message 里包含一条或者多个 Frame**，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）；

**不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）**，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，而**同一 Stream 内部的帧必须是严格有序的**。

##### 4.3.2、Stream并发传输的优势

**当 HTTP/2 实现 100 个并发 Stream 时，只需要建立一次 TCP 连接，而 HTTP/1.1 需要建立 100 个 TCP 连接，每个 TCP 连接都要经过 TCP 握手、慢启动以及 TLS 握手过程，这些都是很耗时的。**

HTTP/2 还可以对每个 Stream 设置不同**优先级**，帧头中的「标志位」可以设置优先级，比如客户端访问 HTML/CSS 和图片资源时，希望服务器先传递 HTML/CSS，再传图片，那么就可以通过设置 Stream 的优先级来实现，以此提高用户体验。

#### 4.4、服务器主动推送资源

**服务器推送**：服务端不再是被动地响应，可以**主动**向客户端发送消息。

客户端和服务器**双方都可以建立 Stream**， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。

### 4、HTTP/2的缺陷

**队头阻塞问题**（解决了请求、应答的队头阻塞，但是发生在**TCP层面队头阻塞**）。

HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用。那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。 

所以，一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的**所有的 HTTP 请求都必须等待这个丢了的包被重传回来**。

### 5、HTTP/3的优化

解决了队头阻塞： **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP**。  UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议 可以实现类似 TCP 的可靠性传输。 **

QUIC 有以下 3 个特点：

- **无队头阻塞**。 QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。 

  **当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题**。所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。 

- **更快的连接建立**。HTTP/3 在传输数据前虽然需要 **QUIC 协议握手**，这个握手过程只需要 **1 RTT**，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。 

- **连接迁移**。基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。

  那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

  而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。 

所以， QUIC 是一个在 UDP 之上的**伪** TCP + TLS + HTTP/2 的多路复用的协议。 QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，因此，HTTP/3现在仍未完全普及。

## 九、其他问题

### 1、HTTPS协议一定安全吗？

问题情景：客户端通过浏览器向服务端发起 HTTPS 请求时，被「假基站」转发到了一个「中间人服务器」，于是**客户端是和「中间人服务器」完成了 TLS 握手，然后这个「中间人服务器」再与真正的服务端完成 TLS 握手**。具体过程中：

- 客户端向服务端发起 HTTPS 建立连接请求时，然后被「假基站」转发到了一个「中间人服务器」，接着中间人向服务端发起 HTTPS 建立连接请求，此时**客户端与中间人进行 TLS 握手，中间人与服务端进行 TLS 握手**；
- 在客户端与中间人进行 TLS 握手过程中，**中间人会发送自己的公钥证书给客户端**，**客户端验证证书的真伪**，然后从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给中间人，中间人使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（A），后续客户端与中间人通信就用这个对称加密密钥来加密数据了。
- 在中间人与服务端进行 TLS 握手过程中，**服务端会发送从 CA 机构签发的公钥证书给中间人**，从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给服务端，服务端使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（B），后续中间人与服务端通信就用这个对称加密密钥来加密数据了。
- 后续的通信过程中，中间人用对称加密密钥（A）解密客户端的 HTTPS 请求的数据，然后用对称加密密钥（B）加密 HTTPS 请求后，转发给服务端，接着服务端发送 HTTPS 响应数据给中间人，中间人用对称加密密钥（B）解密 HTTPS 响应数据，然后再用对称加密密钥（A）加密后，转发给客户端。

从客户端的角度看，其实**并不知道网络中存在中间人服务器这个角色**。那么中间人就可以解开浏览器发起的 HTTPS 请求里的数据，也可以解开服务端响应给浏览器的 HTTPS 响应数据。相当于，中间人能够 “偷看” 浏览器与服务端之间的 HTTPS 请求和响应的数据。

**但是要发生这种场景是有前提的，前提是用户点击接受了中间人服务器的证书。**中间人服务器与客户端在 TLS 握手过程中，实际上发送了自己**伪造的证书**给浏览器，而这个伪造的证书是能被浏览器（客户端）识别出是非法的，于是就会提醒用户该证书存在问题。

**这两个情况会有风险：**

1. 如果用户执意点击「继续浏览此网站」，相当于**用户接受了中间人伪造的证书**，那么后续整个 HTTPS 通信都能被中间人监听了。
2. 电脑中毒了，被**恶意导入了中间人的根证书**，那么在验证中间人的证书的时候，由于操作系统信任了中间人的根证书，那么等同于中间人的证书是合法的，这种情况下，浏览器是不会弹出证书存在问题的风险提醒的。

所以，**HTTPS 协议本身到目前为止还是没有任何漏洞的**，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全。

### 2、为什么抓包工具可以截取HTTPS数据

很多抓包工具 之所以可以明文看到 HTTPS 数据，工作原理与**中间人**一致的。对于 HTTPS 连接来说，中间人要满足以下两点，才能实现真正的明文代理：

1. 中间人，作为客户端与真实服务端建立连接这一步不会有问题，因为服务端不会校验客户端的身份；
2. 中间人，作为服务端与真实客户端建立连接，这里会有**客户端信任服务端的问题，也就是服务端必须有对应域名的私钥；**

中间人要拿到私钥只能通过如下方式：

1. 去网站服务端拿到私钥；
2. 去CA处拿域名签发私钥；
3. **自己签发证书，且要被浏览器信任；**抓包工具只能使用第三种方式取得中间人的身份。

使用抓包工具进行 HTTPS 抓包的时候，需要在客户端安装 Fiddler 的根证书，这里实际上起认证中心（CA）的作用。

抓包工具能够抓包的关键是**客户端会往系统受信任的根证书列表中导入抓包工具生成的证书**，而这个证书会被浏览器信任，也就是抓包工具给自己创建了一个认证中心 CA，客户端拿着中间人签发的证书去中间人自己的 CA 去认证，当然认为这个证书是有效的。

### 3、如何避免被中间人抓取数据

当然，我们还可以通过 **HTTPS 双向认证**来避免这种问题。一般我们的 HTTPS 是单向认证，客户端只会验证了服务端的身份，但是服务端并不会验证客户端的身份。如果用了双向认证方式，不仅**客户端会验证服务端的身份，而且服务端也会验证客户端的身份**。服务端一旦验证到请求自己的客户端为不可信任的，服务端就拒绝继续通信，客户端如果发现服务端为不可信任的，那么也中止通信。

### 4、TLS 和 SSL 实际上是一个东西，是一个东西不同阶段的不同名称。

### 5、https 和 http 相比，就是传输的内容多了对称加密，可以这么理解吗？

1. 建立连接时候：**https 比 http多了 TLS 的握手过程**；
2. 传输内容的时候：https 会把数据进行加密，通常是**对称加密**数据；

## 十、HTTPS握手

### 1、TLS握手

**通常经过「四个消息」就可以完成 TLS 握手，也就是需要 2个 RTT 的时延**，然后就可以在安全的通信环境里发送 HTTP 报文，实现 HTTPS 协议。HTTPS是应用层协议，需要先完成TCP连接，再进行TLS握手。不同的密钥交换算法，TLS 的握手过程可能会有一些区别。

### 2、RSA握手

RSA加密是一种非对称加密，可以**在不直接传递密钥的情况下，完成解密**。这能够确保信息的安全性，避免了直接传递密钥所造成的被破解的风险。命名来自于三个发明者名字缩写。

在 RSA 密钥协商算法中，客户端会生成随机密钥，并使用服务端的公钥加密后再传给服务端。根据非对称加密算法，公钥加密的消息仅能通过私钥解密，这样服务端解密后，双方就得到了相同的密钥，再用它加密应用消息。

#### 2.1、TLS第一次握手

客户端首先会发一个「**Client Hello**」消息，消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的**随机数（Client Random）**，这个随机数会被服务端保留，它是生成对称加密密钥的材料之一。

#### 2.2、TLS第二次握手

1. 当服务端收到客户端的「Client Hello」消息后，会确认 TLS 版本号是否支持，和从密码套件列表中选择一个密码套件，以及生成**随机数（Server Random）**。
2. 服务端返回「**Server Hello**」消息，消息里面有服务器确认的 TLS 版本号，也给出了随机数（Server Random），然后从客户端的密码套件列表选择了一个合适的密码套件。
3. 然后，服务端为了证明自己的身份，会发送「**Server Certificate**」给客户端，这个消息里含有数字证书。
4. 服务端发了「**Server Hello Done**」消息，发送完毕。

前面这两个客户端和服务端相互「打招呼」的过程，客户端和服务端就已确认了 **TLS 版本和使用的密码套件**，而且客户端和服务端都会各自生成一个随机数，并且还会把随机数传递给对方，这两个随机数是后续生成**会话密钥**的条件。

#### 2.3、客户端验证证书

CA 签发证书的过程：

1. 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；
2. 然后 CA 会使用自己的私钥将该 Hash 值加密，生成数字签名；
3. 最后将 Certificate Signature 添加在文件证书上，形成数字证书；

客户端校验服务端的数字证书的过程：

1. 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；
2. 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；
3. 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。

**证书信任链：**向 CA 申请的证书一般不是根证书签发的，而是中间证书签发的，如果追溯到最后的根证书在系统的信任列表中，就可以信任这个链条上的证书。

> 为什么不全部由Root CA签发？
>
> 是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。

#### 2.4、TLS第三次握手

客户端验证完证书后，认为可信则继续往下走。

1. 客户端就会生成一个新的**随机数 (pre-master)**，用服务器的 RSA 公钥加密该随机数，通过「**Client Key Exchange**」消息传给服务端。
2. 服务端收到后，用 RSA 私钥解密，得到客户端发来的随机数 (pre-master)。
3. 至此，**客户端和服务端双方都共享了三个随机数，分别是 Client Random、Server Random、pre-master**。于是，双方根据已经得到的三个随机数，生成**会话密钥（Master Secret）**，它是对称密钥，用于对后续的 HTTP 请求/响应的数据加解密。
4. 生成完「会话密钥」后，然后客户端发一个「**Change Cipher Spec**」，告诉服务端开始使用加密方式发送消息。「**Change Cipher Spec**」之前的都是明文传输，之后都是密钥加密的密文。
5. 然后，客户端再发一个「**Encrypted Handshake Message（Finishd）**」消息，把之前所有发送的数据做个**摘要**，再用会话密钥（master secret）加密一下，让服务器做个验证，验证加密通信「是否可用」和「之前握手信息是否有被中途篡改过」。

#### 2.5、TLS第四次握手

服务器也是同样的操作，发「**Change Cipher Spec**」和「**Encrypted Handshake Message**」消息，如果双方都验证加密和解密没问题，那么握手正式完成，就可以用会话密钥加解密HTTP请求和响应。

#### 2.6、RSA算法的缺陷

**使用 RSA 密钥协商算法的最大问题是不支持前向保密**。

因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解。

为了解决这个问题，后面就出现了 ECDHE 密钥协商算法，我们现在大多数网站使用的正是 ECDHE 密钥协商算法。

### 3、ECDHE 握手

#### 3.1、DH算法

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E7%A6%BB%E6%95%A3%E5%AF%B9%E6%95%B0.png" alt="img" style="zoom: 67%;" />

底数 a 和模数 p 是离散对数的公共参数，也就说是公开的，b 是真数，i 是对数。知道了对数，就可以用上面的公式计算出真数。但反过来，知道真数却很难推算出对数。

**特别是当模数 p 是一个很大的质数，即使知道底数 a 和真数 b ，在现有的计算机的计算水平是几乎无法算出离散对数的，这就是 DH 算法的数学基础。**

##### 3.1.1、DH算法交换密钥

模数P和底数G是公开参数。然后小红和小明各自生成一个随机整数作为**私钥**，双方的私钥要各自严格保管，不能泄漏，小红的私钥用 a 代称，小明的私钥用 b 代称。

1. **私钥：**

   小红的私钥用 a 代称，小明的私钥用 b 代称。私钥是随机生成的，各自严格保密。

   私钥在计算中充当**指数**。

2. **公钥**：

   小红的公钥记作 A，A = G ^ a ( mod P )；

   小明的公钥记作 B，B = G ^ b ( mod P )；

3. 根据离散对数的原理，从公钥A反向算出私钥的指数是非常困难的。

   双方交换各自 DH 公钥后，小红手上共有 5 个数：P、G、a、A、B，小明手上也同样共有 5 个数：P、G、b、B、A。

   然后小红执行运算： B ^ a ( mod P )，其结果为 K，因为离散对数的幂运算有交换律，所以小明执行运算： A ^ b ( mod P )，得到的结果也是 K。这个 K 就是小红和小明之间用的**对称加密密钥**，可以作为会话密钥使用。

#### 3.2、DHE算法

##### 3.2.1、static DH 算法

static DH 算法里有一方的私钥是静态的，也就说每次密钥协商的时候有一方的私钥都是一样的，一般是服务器方固定，即 a 不变，客户端的私钥则是随机生成的。**static DH 算法不具备前向安全性**，时间长了就会被暴力破解私钥。

##### 3.2.2、DHE算法

让双方的私钥在每次密钥交换通信时，都是随机生成的、临时的，这个方式也就是 DHE 算法，E 全称是 ephemeral（临时性的）。**每个通信过程的私钥都是没有任何关系的，都是独立的，这样就保证了「前向安全」**。

#### 3.3、ECDHE 算法

DHE 算法由于计算性能不佳，因为需要做大量的乘法，为了提升 DHE 算法的性能，所以就出现了现在广泛用于密钥交换算法 —— **ECDHE 算法**。在 DHE 算法的基础上利用了 ECC 椭圆曲线特性，可以用更少的计算量计算出公钥，以及最终的会话密钥。

 ECDHE 密钥交换算法的过程：

- 双方事先确定好使用哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的；
- 双方各自随机生成一个随机数作为**私钥d**，并与基点 G相乘得到**公钥Q**（Q = dG），此时小红的公私钥为 Q1 和 d1，小明的公私钥为 Q2 和 d2；
- 双方交换各自的公钥，最后小红计算点（x1，y1） = d1Q2，小明计算点（x2，y2） = d2Q1，由于椭圆曲线上是可以满足乘法交换和结合律，所以 d1Q2 = d1d2G = d2d1G = d2Q1 ，因此**双方的 x 坐标是一样的，所以它是共享密钥，也就是会话密钥**。

这个过程中，双方的私钥都是随机、临时生成的，都是不公开的，即使根据公开的信息（椭圆曲线、公钥、基点 G）也是很难计算出椭圆曲线上的离散对数（私钥）。

#### 3.4、ECDHE握手过程

**使用了 ECDHE，在 TLS 第四次握手前，客户端就已经发送了加密的 HTTP 数据**，而对于 RSA 握手过程，必须要完成 TLS 四次握手，才能传输应用数据。

所以，**ECDHE 相比 RSA 握手过程省去了一个消息往返的时间**，这个有点「抢跑」的意思，它被称为是「*TLS False Start*」，跟「*TCP Fast Open*」有点像，都是在还没连接完全建立前，就发送了应用数据，这样便提高了传输的效率。

##### 3.4.1、TLS 第一次握手

和RSA算法一样，客户端首先会发一个「**Client Hello**」消息，消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的**随机数（Client Random）**。

##### 3.4.2、TLS 第二次握手

1. 服务端收到客户端的「打招呼」会返回「**Server Hello**」消息，消息面有服务器确认的 TLS 版本号，也给出了一个**随机数（Server Random）**，然后从客户端的密码套件列表选择了一个合适的密码套件。
2. 服务端为了证明自己的身份，发送「**Certificate**」消息，会把证书也发给客户端。
3. 这里和RSA区别很大，会在发送完证书后，发送「**Server Key Exchange**」消息。
   - 选择了**名为 x25519 的椭圆曲线**，选好了椭圆曲线相当于椭圆曲线基点 G 也定好了，这些都会公开给客户端；
   - 生成随机数作为服务端椭圆曲线的私钥，保留到本地；
   - 根据基点 G 和私钥计算出**服务端的椭圆曲线公钥**，这个会公开给客户端。
4. 随后，就是「**Server Hello Done**」消息，服务端跟客户端表明此次握手完毕。

至此，TLS 两次握手就已经完成了，目前客户端和服务端通过明文共享了这几个信息：**Client Random、Server Random 、使用的椭圆曲线、椭圆曲线基点 G、服务端椭圆曲线的公钥**，这几个信息很重要，是后续生成会话密钥的材料。

##### 3.4.3、TLS 第三次握手

客户端验证服务端证书合法后：

1. 客户端会生成一个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前面给的信息，生成**客户端的椭圆曲线公钥**，然后用「**Client Key Exchange**」消息发给服务端。
2. 至此，双方都有对方的椭圆曲线公钥、自己的椭圆曲线私钥、椭圆曲线基点 G。于是，双方都就计算出点（x，y），其中 x 坐标值双方都是一样的，前面说 ECDHE 算法时候，说 x 是会话密钥，**但实际应用中，x 还不是最终的会话密钥**。
3. **最终的会话密钥，就是用「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料生成的**。
4. 客户端会发一个「**Change Cipher Spec**」消息，告诉服务端后续改用对称算法加密通信。
5. 客户端会发「**Encrypted Handshake Message**」消息，把之前发送的数据做一个摘要，再用对称密钥加密一下，让服务端做个验证，验证下本次生成的对称密钥是否可以正常使用。

##### 3.4.4、TLS 第四次握手

最后，服务端也会有一个同样的操作，发「**Change Cipher Spec**」和「**Encrypted Handshake Message**」消息，如果双方都验证加密和解密没问题，那么握手正式完成。于是，就可以正常收发加密的 HTTP 请求和响应了。

### 4、RSA 和 ECDHE 握手过程的区别

- RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法**「支持」前向保密**；
- 使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，**节省了一个消息的往返时间**；
- 使用 ECDHE， 在 **TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息**，而 RSA 握手过程没有该消息。

## 十一、远程过程调用RPC

### 1、RPC的功能

可以直接调用远程服务器的方法。

### 2、有了RPC，为什么还要HTTP

多年以前，**HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构。但现在其实已经没分那么清了，B/S 和 C/S 在慢慢融合。**

### 3、HTTP 和 RPC 有什么区别

#### 3.1、传输内容序列化

传输内容中，要将内容转化为01串。字符串和数字都可以直接转换，但是结构体需要特别转换。将结构体转为二进制数组的过程就叫**序列化**，反过来将二进制数组复原成结构体的过程叫**反序列化**。

- HTTP中使用json序列化结构体。缺点是非常冗余。
- RPC的定制化程度更高，可以采用体积更小的Protobuf或其他序列化协议。也不需要像 HTTP 那样考虑各种浏览器行为，比如 302 重定向跳转啥的。**因此性能也会更好一些，这也是在公司内部微服务中抛弃 HTTP，选择使用 RPC 的最主要原因。**

HTTP，其实**特指的是现在主流使用的 HTTP/1.1**，`HTTP/2` 在前者的基础上做了很多改进，所以**性能可能比很多 RPC 协议还要好**，甚至连 `gRPC` 底层都直接用的 `HTTP/2`。

由于历史原因，现在还保留着RPC协议的使用。

### 4、总结

- 纯裸 TCP 是能收发数据，但它是个**无边界**的数据流，上层需要定义**消息格式**用于定义**消息边界**。于是就有了各种协议，HTTP 和各类 RPC 协议就是在 TCP 之上定义的应用层协议。
- **RPC 本质上不算是协议，而是一种调用方式**，而像 gRPC 和 Thrift 这样的具体实现，才是协议，它们是实现了 RPC 调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时 RPC 有很多种实现方式，**不一定非得基于 TCP 协议**。
- 从发展历史来说，**HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构。但现在其实已经没分那么清了，B/S 和 C/S 在慢慢融合**。很多软件同时支持多端，所以对外一般用 HTTP 协议，而内部集群的微服务之间则采用 RPC 协议进行通讯。
- RPC 其实比 HTTP 出现的要早，且比目前主流的 HTTP/1.1 **性能**要更好，所以大部分公司内部都还在使用 RPC。
- **HTTP/2.0** 在 **HTTP/1.1** 的基础上做了优化，性能可能比很多 RPC 协议都要好，但由于是这几年才出来的，所以也不太可能取代掉 RPC。

## 十二、WebSocket

### 1、建立WebSocket协议

在 **TCP 三次握手**建立连接之后，都**统一使用 HTTP 协议**先进行一次通信。

1. 如果此时是**普通的 HTTP 请求**，那后续双方就还是老样子继续用普通 HTTP 协议进行交互，这点没啥疑问。
2. 如果这时候是**想建立 WebSocket 连接**，就会在 HTTP 请求里带上一些**特殊的header 头**，浏览器想**升级协议（Connection: Upgrade）**，并且**想升级成 WebSocket 协议（Upgrade: WebSocket）**。同时带上一段**随机生成的 base64 码（Sec-WebSocket-Key）**，发给服务器。
3. 如果服务器正好支持升级成 WebSocket 协议。就会走 WebSocket 握手流程，同时根据客户端生成的 base64 码，用某个**公开的**算法变成另一段字符串，放在 HTTP 响应的 `Sec-WebSocket-Accept` 头里，同时带上`101状态码`，发回给浏览器。
4. 之后，浏览器也用同样的**公开算法**将`base64码`转成另一段字符串，如果这段字符串跟服务器传回来的**字符串一致**，那验证通过。

### 2、WebSocket的使用场景

WebSocket完美继承了 TCP 协议的**全双工**能力，并且还提供了解决粘包的方案。它适用于**需要服务器和客户端（浏览器）频繁交互**的大部分场景，比如网页/小程序游戏，网页聊天室，以及一些类似飞书这样的网页协同办公软件。

### 3、服务器推送

如何**在用户不做任何操作的情况下，网页能收到消息并发生变更。**

#### 3.1、HTTP定时轮询

**网页的前端代码里不断定时发 HTTP 请求到服务器，服务器收到请求后给客户端响应消息。**常用于扫码登录等场景，会有一些卡顿。

#### 3.2、长轮询

如果我们的 HTTP 请求**将超时设置的很大**，比如 30 秒，**在这 30 秒内只要服务器收到了扫码请求，就立马返回给客户端网页。如果超时，那就立马发起下一次请求。**

这样就减少了 HTTP 请求的个数，并且由于大部分情况下，用户都会在某个 30 秒的区间内做扫码操作，所以响应也是及时的。

### 4、总结

- TCP 协议本身是**全双工**的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是**半双工**的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。
- 在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用**定时轮询或者长轮询**的方式实现**服务器推送**(comet)的效果。
- 对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。
- WebSocket 和 socket 几乎没有任何关系，只是叫法相似。
- 正因为各个浏览器都支持 HTTP协 议，所以 WebSocket 会先利用HTTP协议加上一些特殊的 header 头进行握手升级操作，升级成功后就跟 HTTP 没有任何关系了，之后就用 WebSocket 的数据格式进行收发数据。

## 十三、TCP基本知识

### 1、TCP头部格式

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzYuanBn?x-oss-process=image/format,png" alt="TCP 头格式" style="zoom:50%;" /> 

- **序列号**：建立连接时就生成一个随机数作为初始值，通过SYN传送给接收端住机。每次发送数据，序列号就会累加一个 “数据字节数” 的大小。标识了发送端到接收端的一个**字节**号。**解决网络包乱序问题。**
- **确认应答号**：指下一次期望收到的数据的序列号。发送端接收到确认应答号之后可以认为这之前的数据都已正常接收。**解决丢包问题**。
- 控制位：
  - ACK：为1时，确认应答的字段有效，TCP规定除了最初建立连接时SYN包之外该位必须设置为1。
  - RST：为1时，表示TCP连接出现异常必须强制断开。
  - SYN：为1时，表示希望建立连接，根据序列号字段进行初始化。
  - FIN：为1时，结束标志， 当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位为 1 的 TCP 段。 

### 2、TCP功能

`IP` 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。 如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 `TCP` 协议来负责。因为 TCP 是一个工作在**传输层**的**可靠**数据传输的服务，它能确保接收端接收的网络包是**无损坏、无间隔、非冗余和按序的。**

建立一个 TCP 连接是需要客户端与服务端达成上述三个信息的共识。

- **Socket**：由 IP 地址和端口号组成。
- **序列号**：用来解决乱序问题等。
- **窗口大小**：用来做流量控制。

### 3、TCP特点

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。 

- **面向连接**：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；

- **可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；

- **字节流**：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文。
- 如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。

- TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理。

- 对「重复」的 TCP 报文会自动丢弃。

### 4、唯一确定一个TCP连接

TCP四元组可以唯一确定一个连接：源地址、源端口、目的地址、目的端口。

源地址和目的地址的字段（32位）是在 **IP 头部** 中，作用是通过 IP 协议发送报文给对方主机。

源端口和目的端口的字段（16位）是在 **TCP 头部** 中，作用是告诉 TCP 协议应该把报文发给哪个进程。

### 5、TCP的最大连接数

最大TCP连接数=客户端的IP数*客户端的端口数。对 IPv4，客户端的 IP 数最多为 `2` 的 `32` 次方，客户端的端口数最多为 `2` 的 `16` 次方，也就是服务端单机最大 TCP 连接数，约为 `2` 的 `48` 次方。 但是，服务端最大并发TCP会受到限制：

- **文件描述符限制**：**每个TCP连接都是一个文件**，如果文件描述符占满了，会发生too many open files。Linux对可打开的文件描述符的数量作了三个方面的限制：系统、用户、进程能打开的最大文件数量都有限制。
- **内存限制**，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。

### 6、多个 TCP 服务进程可以同时绑定同一个端口吗？

如果两个 TCP 服务进程同时绑定的 **IP 地址和端口都相同，那么执行 bind() 时候就会出错**，错误是“Address already in use”。如果两个 TCP 服务进程绑定的端口都相同，而 IP 地址不同，那么执行 bind() 不会出错。

### 7、客户端的端口可以重复使用吗？

客户端在执行 connect 函数的时候，会在内核里随机选择一个端口，然后向服务端发起 SYN 报文，然后与服务端进行三次握手。**端口可以重复使用建立TCP连接**。

**TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的**，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的。所以如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的，因为内核是通过四元祖信息来定位一个 TCP 连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。

### 8、TCP重启时Address in use的问题

**问题描述**：当 TCP 服务进程重启之后，总是碰到“Address in use”的报错信息，TCP 服务进程不能很快地重启，而是要过一会才能重启成功。

**问题原因：**当 TCP 服务进程重启时，服务端会出现 **TIME_WAIT 状态的连接**，TIME_WAIT 状态的连接使用的 IP+PORT 仍然被认为是一个有效的 IP+PORT 组合，相同机器上不能够在该 IP+PORT 组合上进行绑定，那么执行 bind() 函数的时候，就会返回了 Address already in use 的错误。

**解决方法：**调用 bind 前，对 socket 设置 SO_RE USE ADDR 属性，可以解决这个问题。如果当前启动进程绑定的 IP+PORT 与处于TIME_WAIT 状态的连接占用的 IP+PORT 存在冲突，但是新启动的进程使用了 SO_REUSEADDR 选项，那么该进程就可以绑定成功。**会帮助我们在很快时间内重启服务端程序。‍**

### 9、客户端TCP连接TIME_WAIT的端口耗尽问题

**问题描述**：如果客户端都是**与同一个服务器（目标地址和目标端口一样）建立连接**，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就**无法与这个服务器再建立连接**了。但还是可以与**其他服务器**建立连接的，只要客户端连接的服务器不是同一个，那么端口是重复使用的。

**解决方法**：使用**TCP复用功能。打开 net.ipv4.tcp_tw_reuse 这个内核参数**。因为开启了这个内核参数后，客户端调用 connect 函数时，如果选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态。如果**该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒**，那么就会**重用这个连接**，然后就可以正常使用该端口了。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/port/%E7%AB%AF%E5%8F%A3%E9%80%89%E6%8B%A9.jpg" alt="img" style="zoom: 33%;" />

## 十四、UDP和TCP的区别

UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。 

### 1、UPD的头部

头部只有 `8` 个字节。 

- **目标和源端口**：主要是告诉 UDP 协议应该把报文发给哪个进程。
- **包长度**：该字段保存了 UDP 首部的长度跟数据的长度之和。
- **校验和**：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP包。

### 2、TCP和UDP的区别

- **连接**：TCP是面向连接的，UDP不需要连接。

- **服务对象**：TCP是一对一的，UDP支持一对一、一对多、多对多。

- **可靠性**：TCP保证可靠交付数据，无差错，不丢失，不重复，按序。UDP是尽最大努力交付，不保证可靠交付。但是也能通过QUIC协议实现可靠传输。

- **拥塞控制、流量控制**：TCP有拥塞控制和流量控制，保证数据传输安全。UDP没有，网络拥堵不影响发送速率。

- **首部开销**：TCP首部更长，没有使用“选项”字段20字节，选用了会更长。UDP首部只有固定的8个字节。

- **传输方式**：TCP是流式传输，没有边界，保证顺序可靠。UDP是一个一个包发送，是有边界的，可能会丢包乱序。

- **分片不同**：TCP中数据大小如果大于MSS大小，就会在传输层进行分片，目标主机收到后就会进行组装。如果只丢失了一个分片，只传输这个分片。

  UDP数据大小如果大于MTU大小，就会在IP层进行分片，目标主机收到后在IP层组装，再传给传输层。

> Q1:为什么TCP头部有  “首部长度” 字段，UDP没有？
>
> 因为**UDP长度固定**，TCP有可选的选项字段，长度可变。
>
> Q2:为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？
>
> TCP的包长度可以直接算出来。其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。
>
> 但其实UDP也是基于IP协议的，也可以用这个公式计算。有两种说法：
>
> - 第一种说法：因为为了网络设备硬件设计和处理方便，首部长度需要是 `4` 字节的整数倍。如果去掉 UDP 的「包长度」字段，那 UDP 首部长度就不是 `4` 字节的整数倍了，所以我觉得这可能是为了补全 UDP 首部长度是 `4` 字节的整数倍，才补充了「包长度」字段。
> - 第二种说法：如今的 UDP 协议是基于 IP 协议发展的，而当年可能并非如此，依赖的可能是别的不提供自身报文长度或首部长度的网络层协议，因此 UDP 报文首部需要有长度字段以供计算。

### 3、TCP和UDP的应用场景

- 由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：`FTP` 文件传输；HTTP / HTTPS；


- 由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：包总量较少的通信，如 `DNS` 、`SNMP` 等；视频、音频等多媒体通信；广播通信；


### 4、TCP 和 UDP 可以同时绑定同一个端口吗？

**可以。**传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。

传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。当主机收到数据包后，可以**在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP**，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。

## 十五、TCP连接建立

### 1、TCP三次握手

TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而**建立连接是通过三次握手来进行的**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="TCP 三次握手" style="zoom:33%;" />

1. 一开始，客户端和服务端都处于 `CLOSE` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态。

2. **第一次握手**：客户端会随机初始化序号（客户端序列号`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 **`SYN` 标志位置为 `1`**，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后**客户端处于 `SYN-SENT` 状态**。

3. **第二次握手**：服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（服务端序列号`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1` 客户端序列号 + 1, 接着把 **`SYN` 和 `ACK` 标志位置为 `1`**。最后把该报文发给客户端，该报文也不包含应用层数据，之后**服务端处于 `SYN-RCVD` 状态**。

4. **第三次握手**：客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 **`ACK` 标志位置为 `1`** ，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，**这次报文可以携带客户到服务端的数据**，之后**客户端处于 `ESTABLISHED` 状态**。

5. 服务端收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**。一旦完成三次握手，双方都处于 `ESTABLISHED` 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。

### 2、如何在 Linux 系统中查看 TCP 状态？

TCP 的连接状态查看，在 Linux 可以通过 `netstat -napt` 命令查看。

### 3、为什么是三次握手？不是两次、四次？

#### 3.1、主要原因：避免历史连接

客户端先发送了 SYN（seq = 90）报文，然后客户端宕机了，而且这个 SYN 报文还被网络阻塞了，服务端并没有收到，接着客户端重启后，又重新向服务端建立连接，发送了 SYN（seq = 100）报文。

<img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230525514.png" alt="三次握手避免历史连接" style="zoom:50%;" />

客户端连续发送多次 SYN（都是同一个四元组）建立连接的报文，在**网络拥堵**情况下：

- 一个「旧 SYN 报文」比「最新的 SYN」 报文早到达了服务端，那么此时服务端就会回一个 `SYN + ACK` 报文给客户端，此报文中的确认号是 91（90+1）。
- 客户端收到后，发现自己期望收到的确认号应该是 100 + 1，而不是 90 + 1，于是就会回 RST 报文。
- 服务端收到 RST 报文后，就会释放连接。
- 后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了。

上述中的**「旧 SYN 报文」称为历史连接**，TCP 使用三次握手建立连接的**最主要原因就是防止「历史连接」初始化了连接**。

> **Q1：如果服务端在收到 RST 报文之前，先收到了「新 SYN 报文」，也就是服务端收到客户端报文的顺序是：「旧 SYN 报文」->「新 SYN 报文」，此时会发生什么?**
>
> 1.当服务端第一次收到 SYN 报文，也就是收到 「旧 SYN 报文」时，就会回复 `SYN + ACK` 报文给客户端，此报文中的确认号是 91（90+1）。
>
> 2.然后这时再收到「新 SYN 报文」时，就会回 [Challenge Ack (opens new window)](https://xiaolincoding.com/network/3_tcp/challenge_ack.html)报文给客户端，**这个 ack 报文并不是确认收到「新 SYN 报文」的，而是上一次的 ack 确认号**，也就是91（90+1）。所以客户端收到此 ACK 报文时，发现自己期望收到的确认号应该是 101，而不是 91，于是就会回 RST 报文。

##### 3.1.1、两次连接不能解决历史连接

主要是因为**在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费**，最好就是在服务端发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就**需要三次握手**。

#### 3.2、原因2：同步双方初始序列号

TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：

- 接收方可以去除重复的数据；
- 接收方可以根据数据包的序列号**按序接收**；解决包乱序问题
- 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

四次握手其实也能够可靠的同步双方的初始化序号，但由于**第二步和第三步可以优化成一步**，所以就成了「三次握手」。

而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。

#### 3.3、原因3：避免无效连接

如果只有「两次握手」，当客户端发生的 `SYN` 报文在网络中阻塞，客户端没有接收到 `ACK` 报文，就会重新发送 `SYN` ，**由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 `ACK` 报文，所以服务端每收到一个 `SYN` 就只能先主动建立一个连接**。如果客户端发送的 `SYN` 报文在网络中阻塞了，重复发送多次 `SYN` 报文，那么服务端在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**

TCP 建立连接时，通过三次握手**能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号**。序列号能够保证数据包不重复、不丢弃和按序传输。

#### 3.4、不使用「两次握手」和「四次握手」的原因

- 「两次握手」：无法防止历史连接的建立，会建立无效连接，也无法可靠的同步双方序列号；
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

### 4、为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？

#### 4.1、主要原因：防止历史报文被下一个相同的四元组连接接收。

- 客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，然后**超时重传了这个数据包**。

  而此时服务端设备断电重启了，之前与客户端建立的连接就消失了，于是在收到客户端的数据包的时候就会发送 **RST 报文**。

- 紧接着，客户端又与服务端**建立了与上一个连接相同四元组的连接**；

- 在新连接建立完成后，上一个连接中**被网络阻塞的数据包正好抵达了服务端**，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。

可以看到，**如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题**。 

如果每次建立连接客户端和服务端的初始化序列号都「不一样」，就有大概率因为历史报文的序列号「不在」对方接收窗口，从而很大程度上避免了历史报文。并不是完全避免了（因为**序列号会有回绕的问题**，所以需要用**时间戳**的机制来判断历史报文）。

#### 4.2、原因2：安全上防止黑客伪造的相同序列号的TCP报文被对方接收。

### 5、既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

#### 5.1、MTU和MSS

- **MTU：最大传输单元**。是以太网数据链路层中约定的数据载荷部分的最大长度， 一般为 `1500` 字节； 
- **MSS：TCP最大段大小**。 **这个MSS正好是IP中不会被分片处理的最大数据长度**。TCP在传送大量数据时，是以MSS的大小将数据进行分割发送的，重发时也是以MSS为单位。 

 MSS = MTU - IP header头大小 - TCP 头大小。

#### 5.2、主要作用：将超时重传的功能不要交给IP，而是TCP

**当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传，效率很低**。因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。

#### 5.3、IP的重传方法 - 重传整个TCP报文

当某一个 IP 分片丢失后，接收方的 IP 层就无法组装成一个完整的 TCP 报文（头部 + 数据），也就无法将数据报文送到 TCP 层，所以接收方不会响应 ACK 给发送方。因为发送方迟迟收不到 ACK 确认报文，所以会**触发超时重传，就会重发「整个 TCP 报文（头部 + 数据）」。**

为了达到最佳的传输效能 ，TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。  经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率 。

### 6、建立连接握手丢失问题

#### 6.1、第一次握手丢失了，会发生什么？

**客户端会重传SYN报文。**

- 当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 `SYN_SENT` 状态。


- 在这之后，如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「**超时重传**」机制，重传 SYN 报文，而且**重传的 SYN 报文的序列号都是一样的**。


- 通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。**每次超时的时间是上一次的 2 倍**。 当第五次超时重传后，会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接。所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。


#### 6.2、第二次握手丢失了，会发生什么？

**客户端和服务端都会重传。**

- 客户端会**重传 SYN 报文**，也就是第一次握手，因为一直没收到服务端的SYN-ACK报文。
- 服务端会**重传 SYN-ACK 报文**，也就是第二次握手，因为服务端一直没收到第三次握手的报文，出发了服务端的重传机制。

这两个重传次数都是可以在内核参数设置的。当服务端客户端的重传次数超过了各自设定的上限后，就会终止重传。

#### 6.3、第三次握手丢失了，会发生什么？

**服务端会重传SYN-ACK报文，ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文。**

- 客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 `ESTABLISH` 状态。


- 因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。


当服务端重传超过设定上限之后，就会断开连接。

### 7、什么是 SYN 攻击？如何避免 SYN 攻击？

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列；
- 全连接队列，也称 accept 队列；

TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务端不能为正常用户服务。 

#### 7.1、正常流程

- 当服务端接收到客户端的 SYN 报文时，会创建一个半连接的对象，然后将其加入到内核的「 SYN 队列」；

  接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；

- 服务端接收到 ACK 报文后，从「 SYN 队列」取出一个半连接对象，然后创建一个新的连接对象放入到「 Accept 队列」；

  应用通过调用 `accpet()` socket 接口，从「 Accept 队列」取出连接对象。

不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，默认情况都会丢弃报文。

**SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。**

#### 7.2、应对方式

- 方式一： 调大 netdev_max_backlog 

  当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值如下参数，默认值是 1000，我们要适当调大该参数的值。这样会避免因为内核队列阻塞导致包都被丢掉，但是还是会承受SYN攻击。

- 方式二：增大 **TCP 半连接队列**，要同时增大下面这三个参数：

  - 增大 net.ipv4.tcp_max_syn_backlog
  - 增大 listen() 函数中的 backlog
  - 增大 net.core.somaxconn

- 方式三：开启 **syncookies 功能**

  开启 syncookies 功能就可以在**不使用 SYN 半连接队列的情况下成功建立连接**，相当于绕过了 SYN 半连接来建立连接。 

- 方式四：**减少 SYN+ACK 重传次数** 

  针对 SYN 攻击的场景，我们可以减少 SYN-ACK 的重传次数，以**加快处于 SYN_REVC 状态的 TCP 连接断开。**


### 8、为什么说TCP是面向字节流的协议

#### 8.1、为什么说UDP是面向报文的协议？

当用户消息通过 UDP 协议传输时，**操作系统不会对消息进行拆分**，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是**每个 UDP 报文就是一个用户消息的边界**，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。  

操作系统在收到 UDP 报文后，会将其插入到队列里，**队列里的每一个元素就是一个 UDP 报文** 。

#### 8.2、面向字节流

- 当用户消息通过 TCP 协议传输时，**消息可能会被操作系统分组成多个的 TCP 报文**，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。 **不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议**。 

- 并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理。
- 同时对「重复」的 TCP 报文会自动丢弃。

#### 8.3、粘包问题

 粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。 

- 方式一： 固定长度的消息 。不灵活，不常使用。

- 方式二：**特殊字符作为边界**。  正如**HTTP中通过设置回车、换行作为HTTP报文协议的边界**。可能需要对特殊字符进行转义。

- 自定义消息结构，包头+数据。在包头中说明数据大小。

### 9、TCP传递的数据一定不会丢吗？

#### 9.1、TCP数据传输过程概括

1. 两端首先会通过**三次握手**，建立TCP连接。
2. 一个数据包，从聊天框里发出，消息会从**聊天软件**所在的**用户空间**拷贝到**内核空间**的**发送缓冲区（send buffer）**。
3. 数据包就这样顺着**传输层、网络层，进入到数据链路层，在这里数据包会经过流控（qdisc），再通过RingBuffer发到物理层的网卡**。
4. 数据就这样顺着**网卡**发到了网络中。这里头数据会经过n多个**路由器和交换机**之间的跳转，最后到达**目的机器的网卡**处。
5. 目的机器的网卡会通知**DMA**将数据包信息放到`RingBuffer`中，再触发一个**硬中断**给`CPU`，`CPU`触发**软中断**让`ksoftirqd`去`RingBuffer`收包。
6. 于是一个数据包就这样顺着**物理层，数据链路层，网络层，传输层**，最后从内核空间拷贝到用户空间里的**聊天软件**里。

#### 9.2、丢包情况一：建立连接时丢包

在建立TCP连接三次握手的过程中，服务器会在**第一次握手后**，建立**半连接**，放入**半连接队列**。**第三次握手收到后**，建立**全连接**，放入**全连接队列**。如果队列满导致溢出，新来的包就会被丢弃。

可以通过下面的方式查看是否存在这种丢包行为。

```shell
# 全连接队列溢出次数
# netstat -s | grep overflowed
    4343 times the listen queue of a socket overflowed

# 半连接队列溢出次数
# netstat -s | grep -i "SYNs to LISTEN sockets dropped"
    109 times the listen queue of a socket overflowed 
```

#### 9.3、丢包情况二：流量控制丢包

为了避免数据直接冲入网卡，超出网卡承受能力，让数据按一定的规则排个队依次处理，也就是所谓的**qdisc**(**Q**ueueing **Disc**iplines，排队规则)，**流量控制**机制。

当发送数据过快，流控队列长度`txqueuelen`又不够大时，就容易出现**丢包**现象。当遇到这种情况时，我们可以尝试修改下流控队列的长度。比如像下面这样将eth0网卡的流控队列长度从1000提升为1500.

```shell
# ifconfig eth0 txqueuelen 1500
```

#### 9.4、丢包情况三：网卡丢包

##### 9.4.1、网卡内RingBuffer过小导致丢包

在接收数据时，会将数据暂存到`RingBuffer`接收缓冲区中，然后等着内核触发软中断慢慢收走。如果这个**缓冲区过小**，而这时候发送的数据又过快，就有可能发生溢出，此时也会产生**丢包**。

```shell
# ifconfig
eth0:  RX errors 0  dropped 0  overruns 0  frame 0
```

查看上面的`overruns`指标，它记录了由于`RingBuffer`长度不足导致的溢出次数。

##### 9.4.2、网卡性能不足

网卡作为硬件，**传输速度是有上限的**。当网络传输速度过大，达到网卡上限时，就会发生丢包。这种情况一般常见于压测场景。我们可以通过`ethtool`加网卡名，获得当前网卡支持的最大速度。

```shell
# ethtool eth0
Settings for eth0:
    Speed: 10000Mb/s
```

#### 9.5、丢包情况四：接收缓冲区丢包

我们一般使用`TCP socket`进行网络编程的时候，内核都会分配一个**发送缓冲区**和一个**接收缓冲区**。

当我们想要发一个数据包，会在代码里执行`send(msg)`，这时候数据拷贝到内核**发送缓冲区**就**返回**了，至于**什么时候发数据，发多少数据**，这个后续由内核自己做决定。这两个缓冲区是有大小限制的，可以通过下面的命令去查看。

```shell
# 查看接收缓冲区
# sysctl net.ipv4.tcp_rmem
net.ipv4.tcp_rmem = 4096    87380   6291456

# 查看发送缓冲区
# sysctl net.ipv4.tcp_wmem
net.ipv4.tcp_wmem = 4096    16384   4194304
```

不管是接收缓冲区还是发送缓冲区，都能看到三个数值，分别对应缓冲区的**最小值，默认值和最大值 （min、default、max）。缓冲区会在min和max之间动态调整。**

如果**发送缓冲区**设置过小：

- 执行send的时候如果是**阻塞**调用，就会等待缓冲区有空位时发送。
- **非阻塞**调用会立刻返回一个EAGAIN错误信息，让应用程序下次再发。

如果**接收缓冲区**设置过小：

接收缓冲区满了之后，它的TCP接收窗口会变为0，也就是所谓的**零窗口**，并且会通过数据包里的`win=0`，告诉发送端不要再发送。一般这种情况下，发送端就该停止发消息了，但如果这时候确实还有数据发来，就会发生**丢包**。

#### 9.6、丢包情况五：两端间的网络丢包

丢包情况还可能发生在两端之间的某个中间链路上。

##### 9.6.1、ping命令

只能知道**你的机器和目的机器之间有没有丢包。**

##### 9.6.2、**mtr命令**

mtr命令可以查看到**你的机器和目的机器之间的每个节点的丢包情况**。**mtr默认用的是ICMP包**，有些节点限制了**ICMP包**，导致不能正常展示，可以使用mtr -u 命令使用UDP包，得到比较完整的链路图。

### 10、TCP中的序列号、确认号是如何变化的

#### **10.1、万能公式**

- **公式一：序列号 = 上一次发送的序列号 + len（数据长度）。特殊情况，如果上一次发送的报文是 SYN 报文或者 FIN 报文，则改为 上一次发送的序列号 + 1。**
- **公式二：确认号 = 上一次收到的报文中的序列号 + len（数据长度）。特殊情况，如果收到的是 SYN 报文或者 FIN 报文，则改为上一次收到的报文中的序列号 + 1。**

#### **10.2、序列号、确认号的作用**

- **序列号**：在建立连接时由内核生成的随机数作为其初始值，通过 SYN 报文传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。**用来解决网络包乱序问题。**
- **确认号**：指下一次「期望」收到的数据的序列号，发送端收到接收方发来的 ACK 确认报文以后，就可以认为在这个序号以前的数据都已经被正常接收。**用来解决丢包的问题。**

#### 10.3、三次握手阶段的序列号变化

1. 初始化和第一次握手：假设客户端的初始化序列号为 client_isn，服务端的初始化序列号为 server_isn;
2. 第二次握手：服务端收到客户端的 SYN 报文后，会将 SYN-ACK 报文（第二次握手报文）中序列号和确认号分别设置为：

   - 序列号设置为服务端随机初始化的序列号 server_isn。
   - **确认号设置为 client_isn + 1**，服务端上一次收到的报文是客户端发来的 SYN 报文，该报文的 seq = client_isn，可以得出当前确认号 = client_isn + 1。
3. 第三次握手：客户端收到服务端的 SYN-ACK 报文后，会将 ACK 报文（第三次握手报文）中序列号和确认号分别设置为：

   - 序列号设置为 client_isn + 1。客户端上一次发送报文是 SYN 报文，SYN 的序列号为 client_isn，所以**当前的序列号为 client_isn + 1**。
   - 确认号设置为 server_isn + 1，客户端上一次收到的报文是服务端发来的 SYN-ACK 报文，该报文的 seq = server_isn，可以得出**当前确认号 = server_isn + 1**。

> 为什么第二次和第三次握手报文中的确认号是将对方的序列号 + 1 后作为确认号呢？
>
> SYN 报文是特殊的 TCP 报文，用于建立连接时使用，**虽然 SYN 报文不携带用户数据，但是 TCP 将 SYN 报文视为 1 字节的数据**，当对方收到了 SYN 报文后，在回复 ACK 报文时，就需要将 ACK 报文中的确认号设置为 SYN 的序列号 + 1 ，这样做是有两个目的：
>
> - **告诉对方，我方已经收到 SYN 报文。**
> - **告诉对方，我方下一次「期望」收到的报文的序列号为此确认号，比如客户端与服务端完成三次握手之后，服务端接下来期望收到的是序列号为 client_isn + 1 的 TCP 数据报文。**

#### 10.4、数据传输阶段的变化

假设建立连接后，客户端发出了10字节的数据。

##### 客户端

- **序列号设置为 client_isn + 1**。客户端上一次发送报文是 ACK 报文（第三次握手），该报文的 seq = client_isn + 1，由于是一个单纯的 ACK 报文，没有携带用户数据，所以 len = 0。
- 确认号设置为 server_isn + 1。还是和第三次握手的 ACK 报文的确认号一样，这是因为客户端三次握手之后，发送 TCP 数据报文 之前，如果没有收到服务端的 TCP 数据报文，确认号还是延用上一次的。

可以看到，**客户端与服务端完成 TCP 三次握手后，发送的第一个 「TCP 数据报文的序列号和确认号」都是和「第三次握手的 ACK 报文中序列号和确认号」一样的**。

##### 服务端

- 序列号设置为 server_isn + 1。服务端上一次发送报文是 SYN-ACK 报文，序列号为 server_isn，所以当前的序列号为 server_isn + 1。
- 确认号设置为 client_isn + 11 。服务端上一次收到的报文是客户端发来的 10 字节 TCP 数据报文，该报文的 seq = client_isn + 1，len = 10。也就是将「收到的 TCP 数据报文中的序列号 client_isn + 1，再加上 10（len = 10） 」的值作为了确认号，表示自己收到了该 10 字节的数据报文。

> 如果客户端发送的第三次握手 ACK 报文丢失了，处于 SYN_RCVD 状态服务端收到了客户端第一个 TCP 数据报文会发生什么？
>
> 因为建立连接后，**客户端发送的第一个TCP数据报文的序列号、确认号和第三次握手一样。**并且这个TCP报文也将ACK标志位设置为1，所以可以正常完成握手，并接收数据包。

#### 10.5、四次挥手阶段的变化

数据传输阶段结束后，客户端发起了 FIN 报文，请求服务端端开该 TCP 连接，此时就进入了 TCP 四次挥手阶段：

##### 10.5.1、客户端

**第一次挥手**

- **序列号设置为 client_isn + 11**。客户端上一次发送的报文是 [PSH, ACK] ，该报文的 seq = client_isn + 1, len = 10，可以得出当前的序列号为 client_isn + 11。
- **确认号设置为 server_isn + 1**。客户端上一次收到的报文是服务端发来的 ACK 报文，该报文的 seq = server_isn + 1，是单纯的 ACK 报文，不携带用户数据，所以 len 为 0。

**第四次挥手**

- **序列号设置为 client_isn + 12**。客户端上一次发送的报文是 FIN 报文，该报文的 seq = client_isn + 11，可以得出当前的序列号为 client_isn + 11 + 1，也就是 client_isn + 12。
- **确认号设置为 server_isn + 2**。客户端上一次收到的报文是服务端发来的 FIN 报文，该报文的 seq = server_isn + 1，可以得出当前的确认号为 server_isn + 1 + 1，也就是 server_isn + 2。

##### 10.5.2、服务端

**第二次挥手**

- **序列号设置为 server_isn + 1**。服务端上一次发送的报文是 ACK 报文，该报文的 seq = server_isn + 1，而该报文是单纯的 ACK 报文，不携带用户数据，所以 len 为 0。
- **确认号设置为 client_isn + 12**。服务端上一次收到的报文是客户端发来的 FIN 报文，该报文的 seq = client_isn + 11，可以得出当前的确认号为 client_isn + 11 + 1，也就是 client_isn + 12。

**第三次挥手**

如果后续服务端没有再发送数据的话，序列号、确认号与第二次挥手一样。

- 序列号设置为 server_isn + 1。
- 确认号设置为 client_isn + 12。

### 11、服务端如果没有listen，客户端发起连接，会发生什么？

如果服务端只bind了ip和端口，但是没有调用listen让这个socket监听连接，如果此时客户端朝这个socket发数据：

这属于是**传输层**的问题，不会触发网络层的控制报文ICMP，而是会导致**服务端发回RST报文**。

### 12、没有listen，能建立TCP连接吗？

**可以，客户端是可以自己连自己的形成连接（TCP自连接），也可以两个客户端同时向对方发出请求建立连接（TCP同时打开），这两个情况都有个共同点，就是没有服务端参与，也就是没有listen，就能建立连接**。

#### 12.1、没有listen方法的自连接、两客户端连接如何建立

listen在执行时，会创建半连接和全连接队列，暂存三次握手的连接信息，可以在**握手时根据IP+端口找到对应的socket**。

但是**客户端没有执行listen**，而是**在内核的全局hash表中存放socket信息**。

在 TCP 自连接的情况中，客户端在 connect 方法时，最后会将自己的连接信息放入到这个**全局 hash 表**中，然后将信息发出，消息在经过**回环地址**重新回到 TCP 传输层的时候，就会根据 IP + 端口信息，再一次从这个全局 hash 中取出信息。于是握手包一来一回，最后成功建立连接。

两客户端连接建立时也是同样的方法。

### 13、没有accept，能建立TCP连接吗？

**就算不执行accept()方法，三次握手照常进行，并顺利建立连接。**并且，在服务端执行accept()前，如果客户端发送消息给服务端，服务端是能够**正常回复ack确认包**的。

#### 13.1、建立连接服务端伪代码

```c
int main()
{
    /*Step 1: 创建服务器端监听socket描述符listen_fd*/    
    listen_fd = socket(AF_INET, SOCK_STREAM, 0);
    /*Step 2: bind绑定服务器端的IP和端口，所有客户端都向这个IP和端口发送和请求数据*/    
    bind(listen_fd, xxx);
    /*Step 3: 服务端开启监听*/    
    listen(listen_fd, 128);
    /*Step 4: 服务器等待客户端的链接，返回值cfd为客户端的socket描述符*/    
    cfd = accept(listen_fd, xxx);
    /*Step 5: 读取客户端发来的数据*/
    n = read(cfd, buf, sizeof(buf));
}
```

#### 13.2、建立连接客户端伪代码

```c
int main()
{
    /*Step 1: 创建客户端端socket描述符cfd*/    
    cfd = socket(AF_INET, SOCK_STREAM, 0);
    /*Step 2: connect方法,对服务器端的IP和端口号发起连接*/    
    ret = connect(cfd, xxxx);
    /*Step 4: 向服务器端写数据*/
    write(cfd, buf, strlen(buf));
}
```

#### 13.3、连接建立流程

1.在执行`listen()`方法之后还会执行一个`accept()`方法。**一般情况**下，如果启动服务器，会发现最后程序会**阻塞在**`accept()`里。

2.客户端在创建好socket后，发起connect方法。

3.服务端阻塞的accept方法就会继续执行。

#### 13.4、accept的功能

accept实际上就是从全连接队列中**取出一条连接**，**创建连接过程不需要accept**。如果已经建立的连接呆在全连接队列中，此时客户端发送数据给这个连接，是可以正常回复ACK的。

但是，accep**t仅仅是与连接无关，但是会影响后面的接收信息。**没调用accept会导致**应用程序无法使用TCP连接，即不能接收信息，不能关闭连接。**

#### 13.5、总结

- **每一个**`socket`执行`listen`时，内核都会自动创建一个半连接队列和全连接队列。
- 第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。
- `accept方法`只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎**毫无关系**。
- 出于效率考虑，虽然都叫队列，但半连接队列其实被设计成了**哈希表**，而全连接队列本质是**链表**。
- 全连接队列满了，再来第三次握手也会丢弃，此时如果`tcp_abort_on_overflow=1`，还会直接发`RST`给客户端。
- 半连接队列满了，可能是因为受到了`SYN Flood`攻击，可以设置`tcp_syncookies`，绕开半连接队列。
- 客户端没有半连接队列和全连接队列，但有一个**全局hash**，可以通过它实现自连接或两客户端TCP连接，因此没有listen方法也能建立TCP连接。

## 十六、TCP连接断开

### 1、四次挥手过程

 <img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzMwLmpwZw?x-oss-process=image/format,png" alt="客户端主动关闭连接 —— TCP 四次挥手" style="zoom: 33%;" /> 

1. **第一次挥手**：客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
2. **第二次挥手**：服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSE_WAIT` 状态。
3. 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
4. **第三次挥手**：等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
5. **第四次挥手**：客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
6. 服务端收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。
7. 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。这里一点需要注意是：**主动关闭连接的，才有 TIME_WAIT 状态。**

### 2、网络概念区分

1. MSL： **报文最大生存时间** 。它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。 

   2MSL：主动关闭的一方确认被动关闭的一方接收到了自己回复的ACK报文。如果没有接受到，被动一方会要求主动方重传ACK。

2. TTL：**生存时间字段**。在**IP首部中的8位字段**。该字段不是存的具体时间，而是设置了**数据报可以经过的最多路由器数**。  TL的初始值由源主机设置（通常为32或64），一旦经过一个处理它的路由器，它的值就减去1.当该字段值为0时，数据报就被丢弃，并发送ICMP报文通知源主机。 

   MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。**TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了**。

3. RTT：**往返时间**。客户端到服务端往返所花时间。RTT受网络传输拥塞的变化而变化。TCP含有动态估算RTT的算法 。RTT是**TCP超时与重传**中用到的概念。

4. RTO：超时重传时间。

### 3、为什么挥手需要四次

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，因此是需要四次挥手。但是**在特定情况下，四次挥手是可以变成三次挥手的**。

### 4、挥手丢失

以服务端（被动关闭方）、客户端（主动关闭方）为例。

#### 4.1、第一次挥手丢失了，会发生什么

**客户端重传FIN报文。**

客户端迟迟收不到被动方的 ACK 的话，会触发超时重传机制，重传 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制。

当客户端重传 FIN 报文的次数超过 `tcp_orphan_retries` 后，就不再发送 FIN 报文，则会在等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到第二次挥手，那么直接进入到 `close` 状态。

#### 4.2、第二次挥手丢失了，会发生什么？

**客户端重传FIN报文，服务端的ACK报文不会重传。**

当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 **`CLOSE_WAIT` 状态**。 **ACK 报文是不会重传的**，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。 

>  **`FIN_WAIT2` 状态不会持续太久。**
>
>  当客户端收到第二次挥手，也就是收到服务端发送的 ACK 报文后，客户端就会处于 `FIN_WAIT2` 状态，在这个状态需要等服务端发送第三次挥手，也就是服务端的 FIN 报文。
>
>  对于 close 函数关闭的连接，由于无法再发送和接收数据，所以`FIN_WAIT2` 状态不可以持续太久，而 `tcp_fin_timeout` 控制了这个状态下连接的持续时长，默认值是 60 秒。
>
>  这意味着对于**调用 close 关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭**。

#### 4.3、第三次挥手丢失了，会发生什么？

**服务端重传FIN报文。**

- 服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 `CLOSE_WAIT` 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。

  此时，**内核是没有权利替代进程关闭连接**，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。

- 服务端处于 **CLOSE_WAIT 状态**时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 **LAST_ACK 状态**，等待客户端返回 ACK 来确认连接关闭。

  如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 `tcp_orphan_retrie`s 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。

- 客户端不会一直等待第三次握手的报文的，因为它已经被close函数关闭了，60秒后还没收到服务端的FIN报文就会直接关闭。

#### 4.4、第四次挥手丢失了，会发生什么？

**服务端会重传FIN报文；客户端进入TIME_WAIT 状态，持续2MSL时间后关闭。**

当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 `TIME_WAIT` 状态。

服务端（被动关闭方）没有收到 ACK 报文前，还是处于 LAST_ACK 状态。

- 当服务端重传第三次挥手报文达到了最大重传次数，如果还是没能收到客户端的第四次挥手（ACK 报文），那么服务端就会断开连接。
- 客户端在收到第三次挥手后，就会进入 TIME_WAIT 状态，开启时长为 2MSL 的定时器，如果途中再次收到第三次挥手（FIN 报文）后，就会**重置定时器，当等待 2MSL 时长后，客户端就会断开连接**。

### 5、TIME_WAIT 问题

#### 5.1、为什么 TIME_WAIT 等待的时间是 2MSL？

**2MSL时长** 这其实是相当于**至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。 `2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。 

为什么不是 4 或者 8 MSL 的时长呢？连续丢包概率实在是太小了，忽略它比解决它更具性价比。 

#### 5.2、为什么需要 TIME_WAIT 状态？

主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。 

##### 5.2.1、原因一：防止历史连接中的数据，被后面相同四元组的连接错误的接收

> - **序列号**，标识了 TCP 发送端到 TCP 接收端的数据流的**一个字节**，因为 TCP 是面向字节流的可靠协议，为了保证消息的顺序性和可靠性，TCP 为每个传输方向上的每个字节都赋予了一个编号，以便于传输成功后确认、丢失后重传以及在接收端保证不会乱序。**序列号是一个 32 位的无符号数，因此在到达 4G 之后再循环回到 0**。
> - **初始序列号**，在 TCP 建立连接的时候，客户端和服务端都会各自生成一个初始序列号，它是基于时钟生成的一个随机数，来保证每个连接都拥有不同的初始序列号。**初始化序列号可被视为一个 32 位的计数器，该计数器的数值每 4 微秒加 1，循环一次需要 4.55 小时**。
>
> 序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据。

如果连接关闭后，马上又以相同四元组建立连接，就会导致错误接收之前的数据。

为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 `2MSL` 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。**

##### 5.2.2、保证「被动关闭连接」的一方，能被正确的关闭 

**等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。** 

假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSE 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会**回 RST 报文**。

**服务端收到这个 RST 并将其解释为一个错误**，这对于一个可靠的协议来说不是一个优雅的终止方式。 

#### 5.3、TIME_WAIT 过多有什么危害？

TIME-WAIT 状态主要的危害有两种：

- 第一是占用**系统资源**，比如文件描述符、内存资源、CPU 资源、线程资源等；
- 第二是占用**端口资源**，端口资源也是有限的，一般可以开启的端口为 `32768～61000`，也可以通过 `net.ipv4.ip_local_port_range`参数指定范围。

客户端和服务端 TIME_WAIT 过多，造成的影响是不同的。 **TIME_WAIT是主动关闭连接方才会有的的状态。**下面说的客户端、服务端都是他们作为主动关闭一方的情况。

- **如果客户端的 TIME_WAIT 状态过多**，**占满了所有端口资源**，那么就无法对「目的 IP+ 目的 PORT」都一样的服务端发起连接了，但是被使用的端口，还是可以继续对另外一个服务端发起连接的。 
- **如果服务端的 TIME_WAIT 状态过多**，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会**占用系统资源**，比如文件描述符、内存资源、CPU 资源、线程资源等。 

### 6、优化TIME_WAIT

#### 6.1、解决TIME_WAIT

可以打开TCP时间戳和TCP复用机制，这样客户端就会选择一个TIME_WAIT时间超过了1s的连接，建立新连接。因为引入了时间戳，之前TIME_WAIT需要避免的历史连接问题也就解决了。

#### 6.2、避免服务器主动断开连接

其实并不应该强硬的解决TIME_WAIT状态，而是应该巧妙利用。如果服务端出现了大量的TIME_WAIT状态，说明服务端大量主动断开连接。应该让分散各地的客户端断开连接，让客户端承受TIME_WAIT的压力。

##### 6.2.1、HTTP没有使用长连接

关闭 HTTP 长连接机制后，每次请求都要经历这样的过程：建立 TCP -> 请求资源 -> 响应资源 -> 释放连接，那么此方式就是 **HTTP 短连接**。

**当服务端出现大量的 TIME_WAIT 状态连接的时候，可以排查下是否客户端和服务端都开启了 HTTP Keep-Alive**，因为任意一方没有开启 HTTP Keep-Alive，都会导致服务端在处理完一个 HTTP 请求后，就主动关闭连接，此时服务端上就会出现大量的 TIME_WAIT 状态的连接。可以让客户端和服务端都开启 HTTP Keep-Alive 机制。

##### 6.2.2、HTTP长连接超时

服务端建立起长连接后，如果一段时间没有接收到客户端的请求，就会主动断开连接。可以往**网络问题**的方向排查，比如是否是因为网络问题，导致客户端发送的数据一直没有被服务端接收到，以至于 HTTP 长连接超时。

##### 6.2.3、HTTP长连接的请求达到上限

nginx 的 keepalive_requests 参数限制了可以同时建立的HTTP长连接数量，一旦超过**nginx 就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态**。

### 7、CLOSE_WAIT问题

CLOSE_WAIT 状态是「被动关闭方」才会有的状态，而且如果「被动关闭方」没有调用 close 函数关闭连接，那么就无法发出 FIN 报文，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态。

所以，**当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接**。

#### 7.1、TCP服务端的流程

1. 创建服务端 socket，bind 绑定端口、listen 监听端口
2. 将服务端 socket 注册到 epoll
3. epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket
4. 将已连接的 socket 注册到 epoll
5. epoll_wait 等待事件发生
6. 对方连接关闭时，我方调用 close

在close之前的一些流程如果发生异常，**不能正确调用close，就会出现大量CLOSE_WAIT。**

#### 7.2、建立连接后，客户端主机断电

服务端无法察觉到客户端断电的情况，为了避免这种情况，TCP 搞了个**保活机制**。每隔一段时间发送探测报文，连续几次没有回应就断开连接。

> 注意，宕机不是客户端进程崩溃。如果客户端进程崩溃，客户端内核就会检测到，替进程发送FIN报文断开连接，并且回收资源。

开启了 TCP 保活，需要考虑以下几种情况：

- 第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
- 第二种，对端主机宕机并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，**会产生一个 RST 报文**，这样很快就会发现 TCP 连接已经被重置。
- 对端主机宕机，探测报文石沉大海，该TCP连接死亡。

##### 7.2.1、心跳机制

由于TCP保活机制时间非常长，可以在应用层自己实现一个心跳机制。**心跳包**便是在客户端和服务器之间自动通报对方一个结构体，让对方知道自己还活着，以确保连接的有效性的机制。

比如，web 服务软件一般都会提供 `keepalive_timeout` 参数，用来指定 HTTP 长连接的超时时间。如果设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会**启动一个定时器**，如果客户端在完成一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，**定时器的时间一到，就会触发回调函数来释放该连接。**

#### 7.3、建立连接后，服务端进程崩溃

**服务端会发送 FIN 报文，与客户端进行四次挥手**。TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，**后续的挥手过程也都是在内核完成，并不需要进程的参与**，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。

### 8、Socket编程

#### 8.1、TCP的连接流程

<img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230545997.png" alt="基于 TCP 协议的客户端和服务端工作" style="zoom:50%;" />

1. 服务端和客户端**初始化 `socket`，得到文件描述符**；
2. 服务端调用 `bind`，将 **socket 绑定在指定的 IP 地址和端口;**
3. 服务端调用 `listen`，进行**监听**；
4. 服务端调用 `accept`，**等待客户端连接**；
5. 客户端调用 `connect`，向**服务端的地址和端口发起连接请求**；
6. 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。
7. 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。
8. 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。

#### 8.2、listen 时候参数 backlog 的意义

```c
int listen (int socketfd, int backlog)
```

**backlog 是 accept 队列（全连接队列）的长度。**

**但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 = min(backlog, somaxconn)。**

#### 8.3、accept发生在三次握手的哪一步

**第一次握手**：客户端的协议栈向服务端发送了 SYN 包，并告诉服务端当前发送序列号 client_isn，客户端进入 SYN_SENT 状态；

**第二次握手**：服务端的协议栈收到这个包之后，和客户端进行 ACK 应答，应答的值为 client_isn+1，表示对 SYN 包 client_isn 的确认。

同时服务端也发送一个 SYN 包，告诉客户端当前我的发送序列号为 server_isn，服务端进入 SYN_RCVD 状态；

客户端协议栈收到 ACK 之后，使得应用程序从 `connect` 调用返回，表示客户端到服务端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务端的 SYN 包进行应答，应答数据为 server_isn+1；

**第三次握手**：ACK 应答包到达服务端后，服务端的 TCP 连接进入 ESTABLISHED 状态，同时服务端协议栈使得 `accept` 阻塞调用返回，这个时候服务端到客户端的单向连接也建立成功。至此，客户端与服务端两个方向的连接都建立成功。

从上面的描述过程，我们可以得知**客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。**

#### 8.4、客户端调用了close，连接断开的流程

- 客户端调用 `close`，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态；
- 服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 `EOF` 到接收缓冲区中，应用程序可以通过 `read` 调用来感知这个 FIN 包。这个 `EOF` 会被**放在已排队等候的其他已接收的数据之后**，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态；
- 接着，当处理完数据后，自然就会读到 `EOF`，于是也调用 `close` 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态；
- 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；
- 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；
- 客户端经过 `2MSL` 时间之后，也进入 CLOSE 状态；

#### 8.5、没有accept，也能建立连接

accpet 系统调用并不参与 TCP 三次握手过程，它只是负责从 TCP 全连接队列取出一个已经建立连接的 socket，用户层通过 accpet 系统调用拿到了已经建立连接的 socket，就可以对该 socket 进行读写操作了。

#### 8.6、没有 listen，也能建立 TCP 连接

客户端是可以自己连自己的形成连接（**TCP自连接**），也可以两个客户端同时向对方发出请求建立连接（**TCP同时打开**），这两个情况都有个共同点，就是**没有服务端参与，也就是没有 listen，就能 TCP 建立连接。**

### 9、TCP一定需要四次挥手吗？

#### 9.1、需要四次挥手的关键原因

服务器收到客户端的 FIN 报文时，内核会马上回一个 ACK 应答报文，**但是服务端应用程序可能还有数据要发送，所以并不能马上发送 FIN 报文，而是将发送 FIN 报文的控制权交给服务端应用程序**：

- 如果服务端应用程序有数据要发送的话，就发完数据后，才调用关闭连接的函数；
- 如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，

 是否要发送第三次挥手的**控制权不在内核，而是在被动关闭方的应用程序**，因为应用程序可能还有数据要发送，由应用程序决定什么时候调用关闭连接的函数，当调用了关闭连接的函数，内核就会发送 FIN 报文了。所以**服务端的 ACK 和 FIN 一般都会分开发送**。 

> FIN报文一定会在调用关闭连接的函数处才会发送吗？
>
> **不一定。**如果进程退出了，不管是不是正常退出，还是异常退出（如进程崩溃），内核都会发送 FIN 报文，与对方完成四次挥手。

#### 9.2、关闭连接的两种函数

关闭的连接的函数有两种函数：

- **close 函数**，**同时 socket 关闭发送方向和读取方向**，**是粗暴的关闭方式**。也就是 socket 不再有发送和接收数据的能力。

  如果有多进程/多线程共享同一个 socket，如果有一个进程调用了 close 关闭只是让 socket 引用计数 -1，并不会导致 socket 不可用，同时也不会发出 FIN 报文，其他进程还是可以正常读写该 socket，直到引用计数变为 0，才会发出 FIN 报文。

- **shutdown 函数**，可以**指定 socket 只关闭发送方向而不关闭读取方向**，也就是 socket 不再有发送数据的能力，但是还是具有接收数据的能力。

  如果有多进程/多线程共享同一个 socket，shutdown 则不管引用计数，直接使得该 socket 不可用，然后发出 FIN 报文，如果有别的进程企图使用该 socket，将会受到影响。

如果使用粗暴的close函数关闭连接， 如果收到了服务端发送的数据，由于客户端已经不再具有发送和接收数据的能力，所以**客户端的内核会回 RST 报文给服务端，然后内核会释放连接，这时就不会经历完成的 TCP 四次挥手。** 相反的，**使用shutdown就可以完成正常的四次挥手。**

#### 9.3、什么情况下会三次挥手？

当被动关闭方在 TCP 挥手过程中，「**没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。** 

#####  TCP 延迟确认的策略

<img src="https://cdn.xiaolincoding.com//mysql/other/33f3d2d54a924b0a80f565038327e0e4.png" alt="img" style="zoom:50%;" />

- 当有响应数据要发送时，**ACK 会随着响应数据一起立刻发送给对方**；
- 当没有响应数据要发送时，**ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送**；
- 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK。

因为TCP延迟确认默认开启，所以会有大量的三次挥手现象。

### 10、乱序的FIN包比数据包先到达，会发生什么？

问题：四次挥手过程中，第三次挥手的报文，先于被动方的数据包到达，此时会如何处理FIN包？

<img src="https://cdn.xiaolincoding.com//mysql/other/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP5p6XY29kaW5n,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="img" style="zoom:50%;" /> 

可以正常关闭。因为如果 FIN 报文比数据包先抵达客户端，此时 FIN 报文其实是一个**乱序的报文**。

在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「乱序队列」，**并不会进入到 TIME_WAIT 状态**。之后报文到达时，如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。

### 11、TCP连接没有开启keep alive，一端断电和一端进程崩溃的区别

#### 11.1、keep alive机制

是 **TCP 的保活机制** 。

**工作原理**：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，**如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡**，系统内核将错误信息通知给上层应用程序。 

如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。

- 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
- 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。

所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活。

#### 11.2、主机崩溃的情况-无法感知

客户端主机崩溃了，服务端是**无法感知到的**，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，**服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态**，直到服务端重启进程。

在**没有使用 TCP 保活机制**且**双方不传输数据**的情况下，一方的 TCP 连接处在 ESTABLISHED 状态，并不代表另一方的连接还一定正常。

#### 11.3、进程崩溃的情况-内核代劳

TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是**内核会发送第一次挥手 FIN 报文**，**后续的挥手过程也都是在内核完成，并不需要进程的参与**，所以即使服务端的进程退出了，还是能与客户端完成 TCP四次挥手的过程。

**在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手**。

#### 11.4、有数据传输时崩溃

**情景一：客户端主机崩溃，迅速重启。**

客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程：客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会**回复 RST 报文，重置该 TCP 连接**。

所以，**只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接**。

**情景二：客户端主机崩溃，一直没有重启。**

服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。 

### 12、拔掉网线后，原本的TCP连接还存在吗

**网线不会影响传输层。**

#### 12.1、拔掉网线后，有数据传输

服务端由于发出的包无法送达，会触发**重传**机制。

- 如果尽快插回了网线，不影响TCP状态，会继续正常返回ACK报文。

- 如果很久没有插回，超过了重传的阈值，内核会判断这个TCP连接有问题，通过Socket接口告诉应用程序TCP出问题了，断开这个连接。

  等到插回网线后，客户端这边的报文发出时，会发现服务端没有相同四元组的TCP连接，**服务端内核会返回一个RST报文给客户端**，客户端断开连接。

#### 12.2、拔掉后，没有数据传输

- 如果没有开启TCP keep alive机制，客户端拔掉网线后，双发都没有发送数据，这个TCP连接会一直存在。
- 如果开启TCP keep alive机制，拔掉网线后，双方都没有进行数据传输。TCP会发送探测报文：
  - 如果对端工作正常，TCP保活时间会被重置，等到下一次TCP保活时间再检查。
  - 如果对端主机宕机，报文不可达，连续几次后，TCP会报告该TCP连接死亡。

### 13、TCP的保活机制、HTTP长连接

**这两个完全是两样不同东西**，实现的层面也不同：

- HTTP 的 Keep-Alive，是由**应用层（用户态）** 实现的，称为 **HTTP 长连接**；
- TCP 的 Keepalive，是由 **TCP 层（内核态）** 实现的，称为 **TCP 保活机制**；

#### 13.1、HTTP的keep-alive

可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 **HTTP 长连接**。 HTTP 长连接不仅仅减少了 TCP 连接资源的开销，而且这给 **HTTP 流水线**技术提供了可实现的基础。 

##### 13.1.1、HTTP流水线

HTTP 流水线，是**客户端可以先一次性发送多个请求，而在发送过程中不需先等待服务器的回应**，可以减少整体的响应时间。 

**服务器还是按照顺序响应**。**服务器响应完客户端第一批发送的请求后，客户端才能发出下一批的请求**，也就说如果服务器响应的过程发生了阻塞，那么客户端就无法发出下一批的请求，此时就造成了**HTTP应答「队头阻塞」**的问题。 

##### 13.1.2、HTTP定时器

为了避免资源浪费的情况，web 服务软件一般都会提供 `keepalive_timeout` 参数，用来指定 HTTP 长连接的超时时间。

比如设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会**启动一个定时器**，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，**定时器的时间一到，就会触发回调函数来释放该连接。**

## 十七、TCP重传、滑动窗口、流量控制、拥塞控制

### 1、重传机制

TCP 实现可靠传输的方式之一，是通过**序列号与确认应答**。当发送端的数据到达接收主机时，接收端主机会返回一个**确认应答消息，表示已收到消息**。TCP 针对数据包丢失的情况，会用**重传机制**解决。 

#### 1.1、超时重传

重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据，也就是**超时重传**。TCP 会在两种情况发生超时重传：**数据包丢失；确认应答丢失**。

##### 1.1.1、超时时间的设置

`RTT` 指的是**数据发送时刻到接收到确认的时刻的差值**，也就是包的往返时间。

`RTO` 指的是超时重传时间。

- 当超时时间 **RTO 较大**时，重发就慢，丢了老半天才重发，没有效率，性能差；
- 当超时时间 **RTO 较小**时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。

**超时重传时间 RTO 的值应该略大于报文往返 RTT 的值**。 

##### 1.1.2、Linux中RTT时间的计算

实际上「报文往返 RTT 的值」是经常变化的，所以「超时重传时间 RTO 的值」应该是一个**动态变化的值**。 估计往返时间，需要**采样RTT、采样 RTT 的波动范围**两个数据。

##### 1.1.3、再次超时的策略

如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。**

这可能导致超时重传周期长，因此可以用**快速重传**。

#### 1.2、快速重传

TCP 还有另外一种**快速重传（Fast Retransmit）机制**，它**不以时间为驱动，而是以数据驱动重传**。  快速重传的工作方式是当**收到三个相同的 ACK 报文**时，会在定时器过期之前，重传丢失的报文段。

##### 1.2.1、**快速重传缺点**

快速重传机制只解决了超时时间的问题，但是它依然面临着另外一个问题：**重传的时候，是重传一个，还是重传所有的问题。** 

- 如果只选择重传一个报文，那么**重传的效率很低**。因为对于后面丢失的报文，还得在后续收到三个重复的 ACK3 才能触发重传。
- 如果选择重传丢失报文之后已发送的所有报文，虽然能同时重传已丢失的报文，但是没有丢失的部分数据相当于做了一次无用功，**浪费资源**。

不管是重传一个报文，还是重传已发送的报文，都存在问题。为了解决不知道该重传哪些 TCP 报文，于是就有 **`SACK` 方法**。

#### 1.3、选择性确认SACK方法

还有一种实现重传机制的方式叫：`SACK`（ Selective Acknowledgment）， **选择性确认**。

这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以**只重传丢失的数据**。

#### 1.4、Duplicate SACK

Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。** 

##### **1.4.1、ACK丢包**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/12.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="ACK 丢包" style="zoom:50%;" /> 

- 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）
- **于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500**，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 `D-SACK`。
- 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。

##### 1.4.2、**网络延时**

 <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/13.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="网络延时" style="zoom:50%;" />

- 数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。
- 而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；
- **所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。**
- 这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。

##### 1.4.3、D-SACK的 好处

1. 可以让「发送方」知道，是**发出去的包丢了，还是接收方回应的 ACK 包**丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;

### 2、滑动窗口

为每个包确认应答，这样的传输方式有一个缺点：数据包的**往返时间越长，通信的效率就越低**。

为解决这个问题，TCP 引入了**窗口**这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。

#### 2.1、窗口的实现、累计应答

窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到**确认应答返回之前，必须在缓冲区中保留已发送的数据。**如果按期收到确认应答，此时数据就可以从缓存区清除。 

> 假设窗口大小为 `3` 个 TCP 段，那么发送方就可以「连续发送」 `3` 个 TCP 段，并且中途若有 ACK 丢失，可以通过「下一个确认应答进行确认」。 
>
> **累计应答：** ACK 600 确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫**累计确认**或者**累计应答**。 

#### 2.2、窗口大小

TCP 头里有一个字段叫 `Window`，也就是窗口大小。窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。 这个字段是**接收端告诉发送端自己还有多少缓冲区可以接收数据**。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。

通常窗口的大小是由接收方的窗口大小来决定的。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。

#### 2.3、发送方的滑动窗口

四个部分，其中深蓝色方框是发送窗口，紫色方框是可用窗口：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/16.jpg?)

- \#1 是已发送并收到 ACK确认的数据：1~31 字节
- \#2 是已发送但未收到 ACK确认的数据：32~45 字节
- \#3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节
- \#4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后

**实现方式**

TCP 滑动窗口方案使用**三个指针**来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。 

- `SND.WND`：表示发送窗口的大小（大小是由接收方指定的）；
- `SND.UNA`：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节。
- `SND.NXT`：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。

**可用窗口大小 = SND.WND -（SND.NXT - SND.UNA）** 

#### 2.4、接收方的滑动窗口

接下来我们看看接收方的窗口，接收窗口相对简单一些，根据处理的情况划分成三个部分：

- \#1 + #2 是已成功接收并确认的数据（等待应用进程读取）；
- \#3 是未收到数据但可以接收的数据；
- \#4 未收到数据并不可以接收的数据；

![接收窗口](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/20.jpg)

其中三个接收部分，**使用两个指针**进行划分:

- `RCV.WND`：表示接收窗口的大小，它会通告给发送方。
- `RCV.NXT`：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。
- 指向 #4 的第一个字节是个相对指针，它需要 `RCV.NXT` 指针加上 `RCV.WND` 大小的偏移量，就可以指向 #4 的第一个字节了。

>  接收窗口和发送窗口的大小并不是完全相等，**接收窗口的大小是约等于发送窗口的大小的。**
>
>  因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。

### 3、流量控制

发送方不能无脑的发数据给接收方，要考虑接收方处理能力。 **TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。** 

#### 3.1、窗口关闭

**如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。** 

**潜在的风险：**接收方向发送方通告窗口大小时，是通过 `ACK` 报文来通告的。当发送窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，**如果这个通告窗口的 ACK 报文在网络中丢失了，那就再也无法继续传输了，导致死锁**。

> 为了解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**如果持续计时器超时，就会发送**窗口探测报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。
>
> - 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；
> - 如果**接收窗口不是 0，那么死锁的局面就可以被打破了。**

#### 3.2、糊涂窗口综合症

如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。到最后，**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**。 `TCP + IP` 头有 `40` 个字节，为了传输那几个字节的数据，要搭上这么大的开销，这太不经济了。 

所以，糊涂窗口综合症的原因是两方面的：**接收方可以通告一个小的窗口；而发送方可以发送小数据。**

##### 3.2.1、让接收方不通告小窗口

接收方通常的策略如下：当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是**小于 MSS 与 1/2 缓存大小中的最小值时**，阻止了发送方再发数据过来。

MSS：最大报文段长度。MTU最大传输单元。MSS = MTU - IP头 - TCP头。

等到接收方处理了一些数据后，**窗口大小 >= MSS，或者接收方缓存空间有一半可以使用**，就可以把窗口打开让发送方发送数据过来。

##### 3.2.2、让发送方不发送小数据

使用 **Nagle 算法**，延时处理，只有**满足下面任意一个条件**，才可以发送数据：

- 条件一：要等到**窗口大小 >= `MSS` 并且 数据大小 >= `MSS`；**
- 条件二：**收到之前发送数据的 `ack` 回包；**

只要上面两个条件都不满足，发送方一直在囤积数据，直到满足上面的发送条件。

如果接收方不能满足「不通告小窗口给发送方」，那么即使开了 Nagle 算法，也无法避免糊涂窗口综合症。因为如果**对端 ACK 回复很快的话**，Nagle 算法就不会拼接太多的数据包，这种情况下依然会有小数据包的传输，网络总体的利用率依然很低。 

**接收方得满足「不通告小窗口给发送方」+ 发送方开启 Nagle 算法，才能避免糊涂窗口综合症**。 

### 4、拥塞控制

**流量控制是避免「发送方」的数据填满「接收方」的缓存**，但是并不知道网络的中发生了什么。

在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大。

所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。于是，就有了**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**

#### 4.1、拥塞窗口

**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

**发送窗口的大小：**是**拥塞窗口和接收窗口中的最小值**。

> **拥塞的判定标准**：其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**

#### 4.2、拥塞控制算法

##### 4.2.1、慢启动和拥塞避免

**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**  慢启动算法，发包的个数是**指数性的增长**。 慢启动门限 `ssthresh` （slow start threshold）是策略的分界线。

- 当 `cwnd` < `ssthresh` 时，使用慢启动算法。
- 当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」。

进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**

- 当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 `MSS` 大小的数据，变成了**线性增长。**

**拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长**。但是总有一个时候会拥塞，发生拥塞就需要拥塞发生算法。

##### 4.2.2、拥塞发生算法

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：**超时重传；快速重传。**

**4.2.2.1、发生超时重传的拥塞发生算法**

当发生了「超时重传」，则就会使用拥塞发生算法。这个时候，ssthresh 和 cwnd 的值会发生变化：

`慢启动门限ssthresh` 设为 `cwnd/2`，`拥塞窗口cwnd` 重置为 `1` （恢复为 cwnd 初始化值，这里假定 cwnd 初始化值 1）；重新开始慢启动 。

这种方法太过于激进。

**4.2.2.2、发生快速重传的拥塞发生算法**：**拥塞避免-快速恢复-拥塞避免**

**快速重传**：接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

`cwnd = cwnd/2` ，也就是设置为原来的一半；`ssthresh = cwnd`；进入**快速恢复算法。**

##### 4.2.3、快速恢复 <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="快速重传和快速恢复" style="zoom:50%;" /> 

- 先用快速重传：`cwnd = cwnd/2` ，也就是设置为原来的一半；`ssthresh = cwnd`;

- 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了，如果是k个重复ACK就+k）；重传丢失的数据包；

  如果再收到重复的 ACK，那么 cwnd 增加 1；

- 如果**收到新数据的 ACK 后**，把 cwnd 设置为第一步中的 ssthresh 的值，也即**解决了重复ACK之后，再次进入拥塞避免状态**；

> 快速恢复算法的解释：
>
> 1.一开始因为网络堵塞，需要减小窗口。**先用拥塞避免算法**，将ssthresh和cwnd都减半；之后由于接收到了K个重复数据包，cwnd再加上K。
>
> 2.随后继续重传，如果收到重复的ACK，cwnd加1。这是为了**保证重复数据包的尽快发送**，因为**这个算法认为网络此时拥塞的主要原因是该包收不到导致的**。
>
> 3.一旦**收到了新的ACK包**，就认为已经解决了之前导致拥塞的重传包的问题，**进入拥塞避免状态。**

## 十八、TCP半连接队列和全连接队列(SYN报文何时会被丢弃？)

不管是半连接队列还是全连接队列，都有最大长度限制，**超过限制时，内核会直接丢弃SYN报文，或返回 RST 包。** 

### 1、全连接队列溢出

**当超过了 TCP 最大全连接队列，服务端则会丢掉后续进来的 TCP 连接**，丢掉的 TCP 连接的个数会被统计起来，我们可以使用 `netstat -s `命令来查看。

当服务端并发处理大量请求时，如果 TCP 全连接队列过小，就容易溢出。发生 TCP 全连接队溢出的时候，后续的请求就会被丢弃，这样就会出现服务端请求数量上不去的现象。

#### 1.1、查看全连接队列的长度

可以通过 `ss -ltn` 命令查看。

#### **1.2、Linux可以设置全连接队列溢出后的动作** ：丢弃、回RST

`tcp_abort_on_overflow` 共有两个值分别是 0 和 1，其分别表示：

- 0 ：如果全连接队列满了，那么 server **扔掉** client 发过来的 ack ；一般设置为丢弃，有利于应对**突发流量**。因为丢弃ACK包后，客户端会多次重传，只要服务端解决了短期的突发流量，就依然能顺利建立连接。
- 1 ：如果全连接队列满了，server 发送一个 **`reset` 包**给 client，表示废掉这个握手过程和这个连接；只有非常肯定 TCP 全连接队列会长期溢出时，才能设置为 1 以**尽快通知客户端**。

#### **1.3、验证是否是全连接队列溢出导致的连接问题**

可以把 tcp_abort_on_overflow 设置为 1，这时如果在客户端异常中可以看到很多 `connection reset by peer`**RST报文** 的错误，那么就可以证明是由于服务端 TCP 全连接队列溢出的问题。

#### 1.4、如何增大TCP全连接队列

**TCP 全连接队列的最大值取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)**。 

- `somaxconn` 是 Linux 内核的参数，默认值是 128，可以通过 `/proc/sys/net/core/somaxconn` 来设置其值；
- `backlog` 是 `listen(int sockfd, int backlog)` 函数中的 backlog 大小，Nginx 默认值是 511，可以通过修改配置文件设置其长度；

**如果持续不断地有连接因为 TCP 全连接队列溢出被丢弃，就应该调大 backlog 以及 somaxconn 参数。** 

### 2、半连接队列溢出

半连接队列长度不能用ss命令直接查看，可以通过查询处于 `SYN_RECV` 状态的 TCP 连接，就是 TCP 半连接队列。  

#### 2.1、半连接队列溢出攻击-SYN攻击

对服务端一直发送 TCP SYN 包，但是不回第三次握手 ACK，这样就会使得**服务端有大量的处于 `SYN_RECV` 状态的 TCP 连接**。这其实也就是所谓的 **SYN 洪泛、SYN 攻击、DDos 攻击。**

可以通过**` netstat -s `观察半连接队列溢出**的情况。

#### 2.2、半连接队列的大小

**半**连接队列的最大值是 `max_qlen_log` 变量 。**半连接队列最大值不是单单由 max_syn_backlog 决定，还跟 somaxconn 和 backlog 有关系。** 

- 当 max_syn_backlog > min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = min(somaxconn, backlog) * 2;
- 当 max_syn_backlog < min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = max_syn_backlog * 2;

max_qlen_log  只是一个**理论值**，并不一定等于服务端处于SYN_RECV的最大个数。

### 3、应对SYN攻击的方法

#### 3.1、SYNcookies功能

如果 SYN 半连接队列已满，不一定非要丢弃连接。 **开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接。**  

syncookies 参数主要有以下三个值：

- 0 值，表示关闭该功能；
- 1 值，表示**仅当 SYN 半连接队列放不下时**，再启用它；**应对 SYN 攻击时，只需要设置为 1 即可。**
- 2 值，表示无条件开启功能；

1、当它被设置为1的时候，客户端发来**第一次握手**SYN时，服务端**不会将其放入半连接队列中**，而是直接生成一个`cookies`；

2、这个`cookies`会跟着**第二次握手**，发回客户端。

3、客户端在发**第三次握手**的时候带上这个`cookies`，**服务端验证到它就是当初发出去的那个，就会建立连接并放入到全连接队列中**。整个过程不再需要半连接队列的参与。

> **没有cookies队列**，如果有一个cookies队列，还是会还是会被**SYN Flood 攻击**打满。
>
> 它是通过**通信双方的IP地址端口、时间戳、MSS**等信息进行**实时计算**的，保存在**TCP报头**的`seq`里。当服务端收到客户端发来的第三次握手包时，会通过seq还原出**通信双方的IP地址端口、时间戳、MSS**，验证通过则建立连接。

##### 3.1.1、SYNcookies方案不能替代半连接队列

**1、数据丢失，不能重传**

因为服务端并不会保存连接信息，所以如果传输过程中数据包丢了，也不会重发第二次握手的信息。

**2、编码解码，消耗CPU资源-ACK攻击**

编码解码`cookies`，都是比较**耗CPU**的，利用这一点，如果此时攻击者构造大量的**第三次握手包（ACK包）**，同时带上各种瞎编的`cookies`信息，服务端收到`ACK包`后**以为是正经cookies**，憨憨地跑去解码（**耗CPU**），最后发现不是正经数据包后才丢弃。

这种通过构造大量`ACK包`去消耗服务端资源的攻击，叫**ACK攻击**，受到攻击的服务器可能会因为**CPU资源耗尽**导致没能响应正经请求。

#### 3.2、增大半连接队列长度

**想增大半连接队列，我们得知不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大全连接队列**。否则，只单纯增大 tcp_max_syn_backlog 是无效的。增大 tcp_max_syn_backlog 和 somaxconn 的方法是**修改 Linux 内核参数**。

#### 3.3、减少SYN+ACK重传次数

当服务端受到 SYN 攻击时，就会有大量处于 SYN_RECV 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。 

### 4、半连接队列为什么是一个哈希表

**全连接队列（icsk_accept_queue）是个链表**，而**半连接队列（syn_table）是个哈希表**。

- **半连接队列（SYN队列）**，服务端收到**第一次握手**后，会将`sock`加入到这个队列中，队列内的`sock`都处于`SYN_RECV` 状态。
- **全连接队列（ACCEPT队列）**，在服务端收到**第三次握手**后，会将半连接队列的`sock`取出，放到全连接队列中。队列里的`sock`都处于 `ESTABLISHED`状态。这里面的连接，就**等着服务端执行accept()后被取出了。**

全连接队列里是等待被取走的连接，并不关心是哪个连接，只要按顺序取走就好。复杂度是O（1）。

但是半连接队需要等待第三次握手的到来，需要把**对应IP端口的连接从队列中取出。如果半连接队列还是个链表，那我们就需要依次遍历，才能拿到我们想要的那个连接，算法复杂度就是O(n)。**设计成哈希表，复杂度就会是O（1）。

## 十九、TCP的性能提升

### 1、三次握手的性能提升

三次握手的过程在一个 HTTP 请求的平均时间占比 10% 以上，在网络状态不佳、高并发或者遭遇 SYN 攻击等场景中，如果不能有效正确的调节三次握手中的参数，就会对性能产生很多的影响。 客户端和服务端都可以针对三次握手优化性能。主动发起连接的客户端优化相对简单些，而服务端需要监听端口，属于被动连接方，其间保持许多的中间状态，优化方法相对复杂一些。 

#### 1.1、客户端优化

客户端在等待服务端回复的 ACK 报文，正常情况下，服务器会在几毫秒内返回 SYN+ACK ，但**如果客户端长时间没有收到 SYN+ACK 报文，则会重发 SYN 包**，重发的次数由 `tcp_syn_retries` 参数控制，默认是 5 次 。

##### 1.1.1、调整**重传时间**

通常，超时重传的间隔时间，是上一次的 2 倍，重传多次后不再重传。 可以根据网络的稳定性和目标服务器的繁忙程度**修改 SYN 的重传次数，调整客户端的三次握手时间上限**。比如内网中通讯时，就可以适当调低重试次数，**尽快把错误暴露给应用程序**。

#### 1.2、服务端优化

**1.2.1、避免SYN攻击**

我们可以通过该 `netstat -s` 命令给出的统计结果中， 可以得到由于半连接队列已满引发的失败次数。上面输出的数值是**累计值**，表示共有多少个 TCP 连接因为半连接队列溢出而被丢弃。**隔几秒执行几次，如果有上升的趋势，说明当前存在半连接队列溢出的现象**。

- **调整SYN半连接队列大小。**不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大 accept 队列。否则，只单纯增大 tcp_max_syn_backlog 是无效的。
- **开启 syncookies 功能。**以在不使用 SYN 半连接队列的情况下成功建立连接。 （SYN半连接队列已满时，不一定非要丢弃连接）
- **向客户端发送RST复位报文**，让客户端及时知道拥堵的情况（全连接队列已满时，不一定非要丢弃连接）
- **增大服务器SYN+ACK的重发次数**，可以在网络繁忙，报文丢失严重的时候，尽快建立起三次连接。
- **修改全连接队列长度**：accept 队列的长度取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)，其中：
  - somaxconn 是 Linux 内核的参数，默认值是 128，可以通过 `net.core.somaxconn` 来设置其值；
  - backlog 是 `listen(int sockfd, int backlog)` 函数中的 backlog 大小；

#### 1.3、如何绕过三次握手？

三次握手建立连接造成的后果就是，HTTP 请求必须在一个 RTT（从客户端到服务器一个往返的时间）后才能发送。

 <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/21.jpg" alt="常规 HTTP 请求" style="zoom:50%;" /><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/22.jpg" alt="开启 TCP Fast Open 功能" style="zoom:50%;" /> 

##### 1.3.1、使用TCP Fast Open功能减少TCP连接建立的时延

**首次建立连接**

1. 客户端发送 SYN 报文，该报文包含 **Fast Open 选项**，且该选项的 Cookie 为空，这表明客户端请求 Fast Open Cookie；
2. 支持 TCP Fast Open 的**服务器生成 Cookie**，并将其置于 SYN-ACK 数据包中的 Fast Open 选项以发回客户端；
3. 客户端收到 SYN-ACK 后，**本地缓存 Fast Open 选项中的 Cookie**。

所以，**第一次发起 HTTP GET 请求的时候，还是需要正常的三次握手流程**。

**客户端再次向服务器建立连接**

1. 客户端发送 SYN 报文，该报文包含**「数据」**（对于非 TFO 的普通 TCP 握手过程，SYN 报文中不包含「数据」）以及此前记录的 **Cookie**；

2. 支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验。

   - 如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「数据」递送至相应的应用程序；

   - 如果 Cookie 无效，服务器将丢弃 SYN 报文中包含的「数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；

3. 如果服务器接受了 SYN 报文中的「数据」，服务器可在握手完成之前发送「数据」，**这就减少了握手带来的 1 个 RTT 的时间消耗**；

4. 客户端将发送 ACK 确认服务器发回的 SYN 以及「数据」，但如果客户端在初始的 SYN 报文中发送的「数据」没有被确认，则客户端将重新发送「数据」；

5. 此后的 TCP 连接的数据传输过程和非 TFO 的正常情况一致。

所以，**之后发起 HTTP GET 请求的时候，可以绕过三次握手，这就减少了握手带来的 1 个 RTT 的时间消耗**。开启了 TFO 功能，cookie 的值是存放到 **TCP option 字段**里的。

##### 1.3.2、打开Fast Open 功能

在 Linux 系统中，可以通过**设置 tcp_fastopn 内核参数，来打开 Fast Open 功能**： tcp_fastopn 各个值的意义:

- 0 关闭
- 1 作为客户端使用 Fast Open 功能
- 2 作为服务端使用 Fast Open 功能
- 3 无论作为客户端还是服务器，都可以使用 Fast Open 功能。**TCP Fast Open 功能需要客户端和服务端同时支持，才有效果。**

 <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/24.jpg" alt="三次握手优化策略" style="zoom:50%;" /> 

###   2、四次挥手的性能提升

客户端和服务端双方都可以主动断开连接，**通常先关闭连接的一方称为主动方，后关闭连接的一方称为被动方。**四次挥手过程只涉及了两种报文，分别是 **FIN 和 ACK**。

#### 2.1、主动方的优化

关闭连接的方式通常有两种，分别是 **RST 报文关闭**和 **FIN 报文关闭**。

如果进程**收到 RST 报文，就直接关闭连接**了，不需要走四次挥手流程，是一个**暴力关闭连接**的方式。

安全关闭连接的方式必须通过四次挥手，它由进程调用 `close` 和 `shutdown` 函数发起 FIN 报文。

> 调用 close 函数和 shutdown 函数有什么区别？
>
> 调用了 close 函数意味着完全断开连接，**完全断开不仅指无法传输数据，而且也不能发送数据。 此时，调用了 close 函数的一方的连接叫做「孤儿连接」，如果你用 netstat -p 命令，会发现连接对应的进程名为空。**
>
> 使用 close 函数关闭连接是不优雅的。于是，就出现了一种优雅关闭连接的 `shutdown` 函数，**它可以控制只关闭一个方向的连接**。

##### 2.1.1、FIN_WAIT 1状态优化

收不到对方的ACK报文时，调整FIN的重传次数。

##### 2.1.2、FIN_WAIT 2状态优化

FIN_WAIT 2状态等待对方发送 FIN 报文，关闭对方的发送通道。

这时，**如果连接是用 shutdown 函数关闭的，连接可以一直处于 FIN_WAIT2 状态，因为它可能还可以发送或接收数据。但对于 close 函数关闭的孤儿连接，由于无法再发送和接收数据，所以这个状态不可以持续太久，而 tcp_fin_timeout 控制了这个状态下连接的持续时长**，默认值是 60 秒。

它意味着对于孤儿连接（调用 close 关闭的连接），如果在 60 秒后还没有收到 FIN 报文，连接就会直接关闭。这个 60 秒不是随便决定的，**它与 TIME_WAIT 状态持续的时间是相同的，都是2MSL（报文在网络中的最长生存时间）**。

**因为这两个状态都需要保持 2MSL 时长。MSL 定义了一个报文在网络中的最长生存时间**（报文每经过一次路由器的转发，IP 头部的 TTL 字段就会减 1，减到 0 时报文就被丢弃，这就限制了报文的最长存活时间）。相当于**至少允许报文丢失一次** 。因此，**TIME_WAIT 和 FIN_WAIT2 状态**的最大时长都是 2 MSL，由于**在 Linux 系统中，MSL 的值固定为 30 秒，所以它们都是 60 秒。**

##### 2.1.3、TIME_WAIT状态的优化

TIME-WAIT 的状态尤其重要，主要是两个原因： 

**原因一：防止历史连接中的数据，被后面相同四元组的连接错误的接收**

**原因二：保证「被动关闭连接」的一方，能被正确的关闭**

##### 1、TIME_WAIT优化方式一：超过上限，直接关闭

Linux 提供了 tcp_max_tw_buckets 参数，当 **TIME_WAIT 的连接数量超过该参数**时，新关闭的连接就不再经历 TIME_WAIT 而**直接关闭**。 

当服务器的并发连接增多时，相应地，同时处于 TIME_WAIT 状态的连接数量也会变多，此时就应当调大 `tcp_max_tw_buckets` 参数，**减少不同连接间数据错乱的概率**。tcp_max_tw_buckets 也不是越大越好，毕竟系统资源是有限的。 

##### 2、TIME_WAIT优化方式二：复用TCP

在建立新连接时，复用处于 TIME_WAIT 状态的连接，那就是打开 tcp_tw_reuse 参数。**tcp_tw_reuse 只作用在 connect 函数，也就是客户端，跟服务端一毛关系的没有**。并且需要打开TCP时间戳才能使用。由于引入了时间戳，好处有：

-  2MSL（TIME_WAIT状态的持续时间） 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃；
-  同时，它还可以防止序列号绕回，也是因为重复的数据包会由于时间戳过期被自然丢弃；

##### 3、TIME_WAIT优化方式三：跳过挥手，直接关闭

设置socket选项，设置调用 close 关闭连接行为。**那么调用 close 后，会立该发送一个 RST 标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了 TIME_WAIT 状态，直接关闭。**

这种方式只推荐在客户端使用，服务端千万不要使用。因为服务端一调用 close，就发送 RST 报文的话，客户端就总是看到 TCP 连接错误 “connnection reset by peer”。

#### 2.2、被动方的优化

##### 2.2.1、**优化1：CLOSE_WAIT状态太多时检查是否正常关闭**

被动方收到 FIN 报文时，内核会自动回复 ACK，同时**连接处于 CLOSE_WAIT 状态**，它表示等待应用进程调用 close 函数关闭连接。 因为**内核不能替线程决定何时关闭连接**。

用 netstat 命令发现大量 CLOSE_WAIT 状态。就排查应用程序，因为可能因为应用程序出现了 Bug，没有调用 close 函数。

##### 2.2.2、**优化2：LAST_ACK状态调整重发次数**

处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文关闭发送通道，同时连接进入 LAST_ACK 状态，等待主动方返回 ACK 来确认连接关闭。 

如果迟迟收不到这个 ACK，内核就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与主动方重发 FIN 报文的优化策略一致。 

#### 2.3、连接双方同时关闭连接

由于TCP是全双工协议，可能会发生这种双方同时关闭的情况。

如果在发送出FIN之后，收到的不是对方的ACK，而是对方的FIN，就会认为是同时关闭。跳过原来的FIN_WAIT_1和FIN_WAIT_2阶段，进入一个新的Closing阶段。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/38.jpg" alt="同时关闭" style="zoom:50%;" /> 

Closing阶段只要接收到对方的确认自己FIN的ACK，就可以进入TIME_WAIT阶段，即将关闭连接。

上面都是TCP握手、挥手的优化，下面是TCP连接传输速度的优化。

#### 2.4、调整滑动窗口

TCP为了解决为每个数据包确认应答的速度受限的缺点， **并行批量发送报文，再批量确认报文即可。** **但是还得考虑接收方的处理能力。**当接收方硬件不如发送方，或者系统繁忙、资源紧张时，是无法瞬间处理这么多报文的。于是，这些报文只能被丢掉，使得网络效率非常低。**为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是滑动窗口的由来。**

##### 2.4.1、窗口扩大字段

接收窗口并不是恒定不变的，接收方会把当前可接收的大小放在 TCP 报文头部中的**窗口字段**，这样就可以起到窗口大小通知的作用。 

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/42.jpg" alt="TCP 头部" style="zoom: 50%;" />

从上图中可以看到，窗口字段只有 2 个字节，因此它最多能表达 65535 字节大小的窗口，也就是 64KB 大小。这个窗口大小最大值，在当今高速网络下，很明显是不够用的。

**扩充窗口的方法**：在 **TCP 选项字段定义了窗口扩大因子**，用于扩大 TCP 通告窗口，其值大小是 2^14，这样就使 TCP 的窗口大小从 16 位扩大为 30 位（2^16 \* 2^ 14 = 2^30），所以此时窗口的最大值可以达到 1GB。

但是并不是窗口越大越好：**因为网络的传输能力是有限的，当发送方依据发送窗口，发送超过网络处理能力的报文时，路由器会直接丢弃这些报文。因此，缓冲区的内存并不是越大越好。** 

##### 2.4.2、如何确定最大传输速度？

带宽是单位时间内的流量，表达是「速度」，比如常见的带宽 100 MB/s；缓冲区单位是字节，当网络速度乘以时间才能得到字节数；

**带宽时延积**：它决定**网络中飞行报文的大小**，它的计算方式：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/44.jpg" alt="img" style="zoom:50%;" />

如果飞行报文超过了带宽时延积，就会导致网络过载，容易丢包。**由于发送缓冲区大小决定了发送窗口的上限，而发送窗口又决定了「已发送未确认」的飞行报文的上限。因此，发送缓冲区不能超过「带宽时延积」。**

- 如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的网络传输，同时导致网络过载，容易丢包；
- 如果发送缓冲区「小于」带宽时延积，就不能很好的发挥出网络的传输效率。

所以，**发送缓冲区的大小最好是往带宽时延积靠近。**

#### 2.5、调整发送缓冲区范围

在 Linux 中发送缓冲区和接收缓冲都是可以用参数调节的。设置完后，Linux 会根据你设置的缓冲区进行**动态调节**。 它的范围通过` tcp_wmem `参数配置，共有三个参数控制（单位是字节），它们分别表示：

- 第一个数值是动态范围的最小值，4096 byte = 4K；
- 第二个数值是初始默认值，16384 byte ≈ 16K；
- 第三个数值是动态范围的最大值，4194304 byte = 4096K（4M）；

**发送缓冲区是自行调节的**，当发送方发送的数据被确认后，并且没有新的数据要发送，就会把发送缓冲区的内存释放掉。

#### 2.6、调整接收缓冲区范围

设置接收缓冲区范围的 tcp_rmem 参数，一样是三个参数控制（单位是字节）：

- 第一个数值是动态范围的最小值，表示即使在内存压力下也可以保证的最小接收缓冲区大小，4096 byte = 4K；
- 第二个数值是初始默认值，87380 byte ≈ 86K；
- 第三个数值是动态范围的最大值，6291456 byte = 6144K（6M）；

#### 2.7、Linux自动调整接收缓存区

接收缓冲区可以根据系统空闲内存的大小来调节接收窗口：

- 如果系统的空闲内存很多，就可以自动把缓冲区增大一些，这样传给对方的接收窗口也会变大，因而提升发送方发送的传输数据数量；
- 反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常工作；

发送缓冲区的调节功能是自动开启的，**而接收缓冲区则需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能**。

#### 2.8、调整TCP内存范围

接收缓冲区调节时，怎么知道当前内存是否紧张或充分呢？这是通过 tcp_mem 配置完成的：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/48.jpg" alt="img" style="zoom:50%;" />

上面三个数字单位不是字节，而是「页面大小」，1 页表示 4KB，它们分别表示：

- 当 TCP 内存小于第 1 个值时，不需要进行自动调节；
- 在第 1 和第 2 个值之间时，内核开始调节接收缓冲区的大小；
- 大于第 3 个值时，内核不再为 TCP 分配新内存，此时新连接是无法建立的；

一般情况下这些值是在系统启动时根据系统内存数量计算得到的。根据当前 tcp_mem 最大内存页面数是 177120，当内存为 (177120 * 4) / 1024K ≈ 692M 时，系统将无法为新的 TCP 连接分配内存，即 TCP 连接将被拒绝。

## 二十、TCP的缺陷

### 1、升级TCP的工作比较困难

TCP 协议是诞生在 1973 年，至今 TCP 协议依然还在实现更多的新特性。

但是 **TCP 协议是在内核中实现的，应用程序只能使用不能修改**，如果要**想升级 TCP 协议，那么只能升级内核**。而升级内核这个工作是很麻烦的事情，服务程序就需要回归测试是否兼容新的内核版本，所以服务器的内核升级也比较保守和缓慢。**很多 TCP 协议的新特性，都是需要客户端和服务端同时支持才能生效的**，比如 **TCP Fast Open** 这个特性，虽然在2013 年就被提出了，但是 Windows 很多系统版本依然不支持它，这是因为 PC 端的系统升级滞后很严重，Windows Xp 现在还有大量用户在使用，尽管它已经存在快 20 年。

所以，即使 TCP 有比较好的特性更新，也很难快速推广，用户往往要几年或者十年才能体验到。

### 2、TCP建立连接的延迟

基于 TCP 实现的应用协议，都是**需要先建立三次握手才能进行数据传输**，比如 HTTP 1.0/1.1、HTTP/2、HTTPS。现在大多数网站都是使用 HTTPS 的，这意味着在 TCP 三次握手之后，**还需要经过 TLS 四次握手后**，才能进行 HTTP 数据的传输，这在一定程序上增加了数据传输的延迟。

TCP 三次握手的延迟被 **TCP Fast Open （快速打开）**这个特性解决了，这个特性可以在「第二次建立连接」时减少 TCP 连接建立的时延。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/45.jpg" alt="常规 HTTP 请求 与 Fast  Open HTTP 请求" style="zoom:50%;" />

过程如下：

- 在第一次建立连接的时候，服务端在**第二次握手产生一个 `Cookie` （已加密）**并通过 SYN、ACK 包一起发给客户端，于是**客户端就会缓存这个 `Cookie`**，所以**第一次发起 HTTP Get 请求的时候，还是需要 2 个 RTT 的时延；**
- 在下次请求的时候，**客户端在 SYN 包带上 `Cookie` 发给服务端**，就提前可以跳过三次握手的过程，因为 `Cookie` 中维护了一些信息，服务端可以从 `Cookie` 获取 TCP 相关的信息，这时**发起的 HTTP GET 请求就只需要 1 个 RTT 的时延；**

### 3、TCP中存在的安全问题

针对 HTTPS 来说，**TLS 是在应用层实现的握手，而 TCP 是在内核实现的握手**，这两个握手过程是无法结合在一起的，总是得先完成 TCP 握手，才能进行 TLS 握手。因为**TCP 是在内核实现的，所以 TLS 是无法对 TCP 头部加密的**，这意味着 **TCP 的序列号都是明文传输**，所以就存安全的问题。

#### 攻击方式

<img src="https://cdn.xiaolincoding.com//mysql/other/A*po6LQIBU7zIAAAAAAAAAAAAAARQnAQ.png" alt="img" style="zoom:50%;" />

攻击者**伪造一个的 RST 报文强制关闭一条 TCP 连接**，而攻击成功的关键则是 **TCP 字段里的序列号位于接收方的滑动窗口内，该报文就是合法的。**

为此 TCP 也不得不进行三次握手来同步各自的序列号，而且初始化序列号时是采用随机的方式（不完全随机，而是随着时间流逝而线性增长，到了 2^32 尽头再回滚）来提升攻击者猜测序列号的难度，以增加安全性。这种方式**只能避免攻击者预测出合法的 RST 报文**，而无法避免攻击者截获客户端的报文，然后中途伪造出合法 RST 报文的攻击的方式。

### 4、TCP存在队头阻塞问题

TCP 是字节流协议，**TCP 层必须保证收到的字节数据是完整且有序的**，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据。只有这样做才能保证数据的有序性，但是带来了**队头阻塞**问题。

### 5、网络迁移需要重新建立TCP连接

基于 TCP 传输协议的 HTTP 协议，由于是通过**四元组（源 IP、源端口、目的 IP、目的端口）**确定一条 TCP 连接。

那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接**。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

## 二十一、如何基于UDP实现可靠传输？

基于 UDP 协议实现的可靠传输协议的成熟方案了，那就是 **QUIC 协议**。

### 1、QUIC实现可靠传输

要基于 UDP 实现的可靠传输协议，那么就要在应用层下功夫，也就是要**设计好协议的头部字段**。拿 HTTP/3 举例子，在 UDP 报文头部与 HTTP 消息之间，共有 3 层头部：

<img src="https://cdn.xiaolincoding.com//mysql/other/ab3283383013b707d1420b6b4cb8517c.png" alt="img" style="zoom:50%;" />

#### 1.1、Packet Header

Packet Header 首次建立连接时和日常传输数据时使用的 Header 是不同的。

<img src="https://cdn.xiaolincoding.com//mysql/other/bcf3ccb6a15c4cdebe1cd0527fdd9a5e.png" alt="Packet Header" style="zoom: 33%;" />

- Long Packet Header 用于首次建立连接。
- Short Packet Header 用于日常传输数据。

**QUIC 也是需要三次握手来建立连接的**，主要目的是为了协商连接 ID。协商出连接 ID 后，后续传输时，双方只需要固定住连接 ID，从而实现连接迁移功能。所以**日常传输数据的 Short Packet Header 不需要在传输 Source Connection ID 字段了，只需要传输 Destination Connection ID**。

#### 1.2、QUIC严格递增的编号的好处

Short Packet Header 中的 `Packet Number` 是每个报文独一无二的编号，它是**严格递增**的，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。

##### **1.2.1、优点1：解决了TCP计算RTT时重传的歧义性问题。**

在TCP连接中，发生超时重传后，**重传的报文和原始报文都是一样的序号**，这会导致**采样RTT（往返时延）的计算不准确。**重传时间RTO是根据RTT计算的，如果RTT计算的不准确，RTO也会计算的不准确，这可能会导致重传的概率事件增大。

而**QUIC的报文的Packet Number是严格递增的**，即便是重传报文也是递增的，这样RTT的计算就会很准确。 

##### 1.2.2、优点2：支持乱序确认，解决了队头阻塞问题，但是需要Stream配合

QUIC 使用的 Packet Number 单调递增的设计，可以让数据包不再像 TCP 那样必须有序确认，QUIC 支持**乱序确认**，当数据包Packet N 丢失后，**只要有新的已接收数据包确认，当前窗口就会继续向右滑动。**

QUIC会将重传的数据包放到发送队列，**重新编号**比如数据包Packet N+M 后重新发送给接收端。

#### 1.3、QUIC Frame Header

一个 Packet 报文中可以存放多个 QUIC Frame。<img src="https://cdn.xiaolincoding.com//mysql/other/6a94d41ef3d14cb6b7846e73da6c3104.png" alt="img" style="zoom:33%;" />

每一个 Frame 都有明确的类型，针对类型的不同，功能也不同，自然格式也不同。

##### 1.3.1、Stream类型的Frame格式

只关注Stream类型的Frame格式，这一形式来自于HTTP/2。Stream 可以认为就是一条 HTTP 请求，它长这样：

<img src="https://cdn.xiaolincoding.com//mysql/other/536298d2c54a43b699026bffe0f85010.png" alt="img" style="zoom:33%;" />

- Stream ID 作用：多个并发传输的 HTTP 消息，通过不同的 Stream ID 加以区别，类似于 HTTP2 的 Stream ID；
- Offset 作用：类似于 TCP 协议中的 Seq 序号，**保证数据的顺序性和可靠性**；
- Length 作用：指明了 Frame 数据的长度。

##### 1.3.2、Stream作用一：实现可靠传输

同一个Stream内的数据必须是有序的，从而实现可靠传输。通过Offset实现。

##### 1.3.3、Stream作用二：确认报文

重传的 Packet N+M 与丢失数据包的 Packet N 编号不一致，但是其中的Frame Header这一层中，**丢失的数据包和重传的数据包 Stream ID 与 Offset 都一致，说明这两个数据包的内容一致**。

##### 1.3.4、Stream作用三：配合Packet Number解决了队头阻塞问题，支持乱序确认

**QUIC 通过单向递增的 Packet Number，配合 Stream ID 与 Offset 字段信息，可以支持乱序确认而不影响数据包的正确组装**，摆脱了TCP 必须按顺序确认应答 ACK 的限制，解决了 TCP 因某个数据包重传而阻塞后续所有待发送数据包的问题。

同时，在QUCI的具体实现中，每个Stream都使用自己的滑动窗口，避免传输过程中发生了数据丢失，而滑动窗口又无法往前移动，导致阻塞住了所有的HTTP请求。

### 2、QUIC解决队头阻塞

#### 2.1、TCP的队头阻塞问题

因为**TCP设计的目的就是为了保证数据的有序性**。TCP 队头阻塞的问题，其实就是**接收窗口的队头阻塞问题**。

只有当接收窗口收到窗口内数据，并且收到有序数据时，接收窗口才能往前滑动，这之后那些已经被接收并且被确认的数据才能被读取。当接收窗口收到的数据不是有序的，比如收到第 33～40 字节的数据，由于第 32 字节数据没有收到， **接收窗口无法向前滑动**，那么即使先收到第 33～40 字节的数据，**这些数据也无法被应用层读取的**。

导致接收窗口的队头阻塞问题，是因为 **TCP 必须按序处理数据，也就是 TCP 层为了保证数据的有序性，只有在处理完有序的数据后，滑动窗口才能往前滑动，否则就停留**，停留「接收窗口」会使得应用层无法读取新的数据。

#### 2.2、HTTP中的队头阻塞问题

##### 2.2.1、HTTP1.1的队头阻塞问题-应用层的队头阻塞问题

HTTP1.1在浏览器中的同一域名的并发连接数有限，**如果连接数超过上限，排在后面的连接就需要等待前面的资源加载完成**。 过去常常出现的浏览器空白并且一直“转圈”就是因为这个问题。  

##### 2.2.2、HTTP2的队头阻塞问题-TCP的队头阻塞问题

HTTP/2中抽象出了**Stream**，通过流的多路复用，实现了**并发传输**。每个Stream都有一个自己的Stream ID，可以并行跑在一个TCP连接上面。****

- 不同Stream的帧可以乱序发送，因为每个帧的头部都有Stream ID信息，接收端可以通过Stream ID有序组装成HTTP消息。
- 同一Stream内部的帧必须严格有序。

**解决了应用层的队头阻塞，但是没有解决TCP的队头阻塞问题。**

但是 HTTP/2 多个 Stream 请求都是在一条 TCP 连接上传输，**共用同一个 TCP 滑动窗口**，那么当滑动窗口有一个位置的报文缺失，滑动窗口是无法往前移动的，此时就会阻塞住所有的 HTTP 请求，这属于 **TCP 层队头阻塞。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/quic/http2%E9%98%BB%E5%A1%9E.jpeg" alt="img" style="zoom:50%;" />

#### 2.3、没有队头阻塞的QUIC

QUIC 也借鉴 HTTP/2 里的 Stream 的概念，在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (Stream)。但是 **QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口**。

假如 Stream2 丢了一个 UDP 包，也只会影响 Stream2 的处理，不会影响其他 Stream，与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/quic/quic%E6%97%A0%E9%98%BB%E5%A1%9E.jpeg" alt="img" style="zoom:50%;" />

### 3、QUIC的流量控制

QUIC 是基于 UDP 传输的，**而 UDP 没有流量控制，因此 QUIC 实现了自己的流量控制机制**，QUIC 的滑动窗口滑动的条件跟 TCP 有一点差别，但是同一个 Stream 的数据也是要保证顺序的，不然无法实现可靠传输，因此同一个 Stream 的数据包丢失了，也会造成窗口无法滑动。

#### **3.1、TCP实现流量控制的方式**

让「接收方」告诉「发送方」，它（接收方）的接收窗口有多大，从而让「发送方」根据「接收方」的实际接收能力控制发送的数据量。

TCP 的接收窗口在收到有序的数据后，接收窗口才能往前滑动，否则停止滑动。

#### 3.2、QUIC 实现流量控制的方式

- 通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据。
- 发送端通过 STREAM_DATA_BLOCKED帧告诉对端由于流量控制被阻塞了，无法发送数据。

**QUIC 的 每个 Stream 都有各自的滑动窗口，不同 Stream 互相独立，队头的 Stream A 被阻塞后，不妨碍 StreamB、C的读取**。

##### **3.2.1、Stream 级别的流量控制**

Stream 可以认为就是一条 HTTP 请求，每个 Stream 都有独立的滑动窗口，所以每个 Stream 都可以做流量控制，防止单个 Stream 消耗连接（Connection）的全部接收缓冲。

##### 3.2.2、**Connection 流量控制**

限制连接中所有 Stream 相加起来的总字节数，防止发送方超过连接的缓冲容量

### 4、QUIC的拥塞控制-在应用层，灵活性高

QUIC 协议当前默认使用了 TCP 的 Cubic 拥塞控制算法（我们熟知的慢开始、拥塞避免、快重传、快恢复策略），也支持使用其他拥塞控制算法。

QUIC 是处于**应用层**的，应用程序层面就能实现不同的拥塞控制算法，**不需要操作系统，不需要内核支持**。TCP 拥塞控制算法迭代速度很慢。而 **QUIC 可以随浏览器更新，QUIC 的拥塞控制算法就可以有较快的迭代速度**。**可以针对不同的应用设置不同的拥塞控制算法**，这样灵活性就很高。

### 5、QUIC更快的连接建立

#### 5.1、**HTTP/1、2的连接建立：**

对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，**先 TCP 握手（1RTT），再 TLS 握手（2RTT），所以需要 3RTT 的延迟才能传输数据**，就算 Session 会话服用，也需要至少 2 个 RTT。

#### 5.2、QUCI连接建立

HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。

但是 **HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS**，它**在自己的帧会携带 TLS 里的“记录”**，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。

如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT（下图的右下角）：

<img src="https://cdn.xiaolincoding.com//mysql/other/4cad213f5125432693e0e2a512c2d1a1.png" alt="img" style="zoom: 67%;" />

### 6、QUIC迁移连接

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接**。而建立连接的过程包含 **TCP 三次握手**和 **TLS 四次握手**的时延，以及 **TCP 慢启动**的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

## 二十二、IP基础

IP 在 TCP/IP 参考模型中处于第三层，也就是**网络层**。网络层的主要作用是：**实现主机与主机之间的通信，也叫点对点（end to end）通信。**IP的作用是在复杂的网络环境中将数据包发送给最终目的主机。

### 1、IP网络层、MAC数据链路层的关系

一言以蔽之， **MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。** 计算机网络中也需要「数据链路层」和「网络层」这个分层才能实现向最终目标地址的通信。

在网络中数据包传输中也是如此，**源IP地址和目标IP地址在传输过程中是不会变化的（前提：没有使用 NAT 网络），只有源 MAC 地址和目标 MAC 一直在变化。** 

### 2、IP地址

IPv4 地址由 `32` 位正整数来表示，IP 地址在计算机是以二进制的方式处理的。 而人类为了方便记忆采用了**点分十进制**的标记方式 。 

**IP 地址最大值是：** <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/5.jpg" alt="img" style="zoom:50%;" /> 使用**NAT技术**可以使得地址最大数量超过上限。

### 3、IP地址的分类

早期地址充裕，分成了A-E五类地址。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/7.jpg" alt="IP 地址分类" style="zoom:50%;" /> 

#### 3.1、A、B、C类地址

A、B、C类地址分为**网络号和主机号**两个部分。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/8.jpg" alt="img" style="zoom:50%;" /> 

##### 最大主机数的计算方式<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/9.jpg" alt="img" style="zoom:50%;" />

-2的原因是因为两个IP地址是特殊的：

- **主机号全为 1** 指定某个网络下的所有主机，用于**广播**
- **主机号全为 0** 指定**网络地址**。

> 广播地址的作用：广播地址用于在**同一个链路中相互连接的主机之间发送数据包**。 当主机号全为 1 时，就表示该网络的广播地址。 
>
> 广播地址可以分为本地广播和直接广播两种。
>
> - **在本网络内广播的叫做本地广播**。例如网络地址为 192.168.0.0/24 的情况下，广播地址是192.168.0.255 。因为这个广播地址的 IP 包会被路由器屏蔽，所以不会到达 192.168.0.0/24 以外的其他链路上。
> - **在不同网络之间的广播叫做直接广播**。例如网络地址为 192.168.0.0/24 的主机向 192.168.1.255/24 的目标地址发送 IP 包。收到这个包的路由器，将数据转发给 192.168.1.0/24，从而使得所有 192.168.1.1~192.168.1.254 的主机都能收到这个包（**由于直接广播有一定的安全问题，多数情况下会在路由器上设置为不转发**。） 。

#### 3.2、D、E类地址

而 D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于**多播**，E 类是预留的分类，暂时未使用。多播用于**将包发送给特定组内的所有主机。** 

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/13.jpg" alt="单播、广播、多播通信" style="zoom:50%;" /> 

#### 3.3、IP分类的优缺点

##### 3.3.1、优点：简单明了，选址简单

通过IP地址前几位判断，可以快速确认是哪类地址：第一位是0的是A类地址，第二位是0的是B类地址……

##### **3.3.2、缺点一：地址不灵活，不能划分层次**

**同一网络下没有地址层次**，比如一个公司里用了 B 类地址，但是可能需要根据生产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就**缺少地址的灵活性**。 

**3.3.3、缺点二：不能很好地与现实网络匹配**

- C 类地址能包含的最大主机数量实在太少了，只有 254 个，一个网吧都不够用。
- 而 B 类地址能包含的最大主机数量又太多了，6 万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。

这两个缺点，都可以在 **`CIDR` 无分类地址**解决。 

### 4、无分类地址CIDR

这种方式不再有分类地址的概念，32 比特的 IP 地址被划分为两部分，前面是**网络号**，后面是**主机号**。 表示形式：`a.b.c.d/x`，其中 `/x` 表示前 x 位属于**网络号**， x 的范围是 `0 ~ 32`，这就使得 IP 地址更加具有灵活性。 

子网掩码：**将子网掩码和 IP 地址按位计算 AND，就可得到网络号。**

#### 4.1、为什么要划分网络号、主机号

两台主机通信首先需要判断**是否在同一个广播域**内。如果是就把数据包直接发送到目标主机。如果不是就需要路由器寻址发到对应网络上。

#### 4.2、如何进行子网划分

**子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址**。形式如下：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/18.jpg" alt="img" style="zoom:50%;" />

- 未做子网划分的 ip 地址：网络地址＋主机地址
- 做子网划分后的 ip 地址：网络地址＋（子网网络地址＋子网主机地址）

> 假设对 C 类地址进行子网划分，网络地址 192.168.1.0，使用子网掩码 255.255.255.192 对其进行子网划分。C 类地址中前 24 位是网络号，最后 8 位是主机号，根据子网掩码可知**从 8 位主机号中借用 2 位作为子网号**。
>
> <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/19.jpg" alt="img" style="zoom:50%;" /> 
>
> 由于子网网络地址被划分成 2 位，那么子网地址就有 4 个，分别是 00、01、10、11 

### 5、公有IP与私有IP

在 A、B、C 分类地址，实际上有分公有 IP 地址和私有 IP 地址。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/22.jpg" alt="img" style="zoom:50%;" />

私有IP可以由组织人员自行分配。但是如果是一个所有人都能访问的网站，则必须注册一个**公有IP**。

#### 5.1、公有IP由谁管理？

私有 IP 地址通常是内部的 IT 人员管理，公有 IP 地址是由 **`ICANN` 组织**管理，中文叫**「互联网名称与数字地址分配机构」**。IANA 是 ICANN 的其中一个机构，它负责分配互联网 IP 地址，是按州的方式层层分配。

其中，在中国是由 **CNNIC** 的机构进行管理，它是中国国内唯一指定的全局 IP 地址管理的组织。

### 6、IP地址和路由控制

#### 6.1、路由表中的最长匹配原则

IP地址中网络地址这部分用于**路由控制**。如果路由控制表中存在多条相同网络地址的记录，就选**择相同位数最多的网络地址，也就是最长匹配。**

在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有**相同网络地址**的记录，根据该记录将 IP 包转发给相应的下一个路由器。

> <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/25.jpg" alt="IP 地址与路由控制" style="zoom:50%;" /> 
>
> 1. 主机 A 要发送一个 IP 包，其源地址是 `10.1.1.30` 和目标地址是 `10.1.2.10`，由于没有在主机 A 的路由表找到与目标地址 `10.1.2.10` 相同的网络地址，于是包被转发到默认路由（路由器 `1` ）；
> 2. 路由器 `1` 收到 IP 包后，也在路由器 `1` 的路由表匹配与目标地址相同的网络地址记录，发现匹配到了，于是就把 IP 数据包转发到了 `10.1.0.2` 这台路由器 `2`；
> 3. 路由器 `2` 收到后，同样对比自身的路由表，发现匹配到了，于是把 IP 包从路由器 `2` 的 `10.1.2.1` 这个接口出去，最终经过交换机把 IP 数据包转发到了目标主机；

#### 6.2、环回地址不会流向网络

环回地址是在同一台计算机上的程序之间进行网络通信时所使用的一个默认地址。**指向的是自己的地址**。计算机使用一个特殊的 IP 地址 **127.0.0.1 作为环回地址**。与该地址具有相同意义的是一个叫做 `localhost` 的主机名。使用这个 IP 或主机名时，数据包不会流向网络。

### 7、IP分片与重组（尽量不由IP分片）

每种**数据链路的最大传输单元 `MTU`** 都是不相同的，以太网的 MTU 是 1500 字节等。

当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片。经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，**路由器是不会进行重组**的。

> 假设发送方发送一个 4000 字节的大数据报，若要传输在以太网链路，则需要把数据报分片成 3 个小数据报进行传输，再交由接收方重组成大数据报。
>
> <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/26.jpg" alt="分片与重组" style="zoom:50%;" />

在分片传输中，**一旦某个分片丢失，则会造成整个 IP 数据报作废**，所以 TCP 引入了 **最大报文段长度`MSS`** 也就是**在 TCP 层进行分片不由 IP 层分片**，那么**对于 UDP 我们尽量不要发送一个大于 `MTU` 的数据报文**。

### 8、IPv6

IPv4 的地址是 32 位的，IPv6 的地址是 `128` 位的 。

#### 8.1、IPv6的优点-自动配置、简化首部、安全提高

- IPv6 可**自动配置**，即使没有 DHCP 服务器也可以实现自动分配IP地址。
- IPv6 包头包首部长度采用固定的值 `40` 字节，**去掉了包头校验和**，**简化了首部结构**，减轻了路由器负荷，大大**提高了传输的性能**。
- IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大**提升了安全性**。

#### 8.2、IPv6的标识方法

- IPv4 地址长度共 32 位，是以**每 8 位作为一组**，并用**点分十进制**的表示方式。


- IPv6 地址长度是 128 位，是以**每 16 位作为一组**，每组用**冒号 「:」** 隔开。

  **如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号 「::」隔开。**但是，一个 IP 地址中只允许出现**一次**两个连续的冒号。 

#### 8.3、IPv4 首部与 IPv6 首部

![IPv4 首部与 IPv6 首部的差异](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/31.jpg)

IPv6 相比 IPv4 的首部改进：

- **取消了首部校验和字段。** 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。
- **取消了分片/重新组装相关字段。** 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提高了路由器转发的速度。
- **取消选项字段。** 选项字段不再是标准 IP 首部的一部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上。删除该选项字段使的 IPv6 的首部成为**固定长度的 `40` 字节**。

## 二十三、IP协议相关技术

### 1、DNS域名解析

DNS 可以将域名网址自动转换为具体的 IP 地址。 DNS 中的域名都是用**句点**来分隔的，比如 `www.server.com`，这里的句点代表了不同层次之间的**界限**。在域名中，**越靠右**的位置表示其层级**越高**。

### 2、ARP地址解析协议

ARP通过**广播**的形式，是借助 **ARP 请求与 ARP 响应**两种类型的包确定 MAC 地址的，并且会用ARP缓存保存对应IP地址的MAC地址。

#### 2.1、RARP协议

RARP 协议正好相反，它是**已知 MAC 地址求 IP 地址**。例如将**打印机服务器等小型嵌入式设备接入到网络时**就经常会用得到。 通常这需要架设一台 `RARP` 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接入到网络，接着：

- 该设备会发送一条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息。
- RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备。最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址。

### 3、DHCP动态获取IP地址协议

可以省去固定分配IP地址的繁琐。DHCP 交互中，**全程都是使用 UDP 广播通信**。

#### 3.1、分配流程：发现 - 提供 - 请求 - ACK

- 客户端首先发起 **DHCP 发现报文 的 IP 数据报。**

  由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP **广播**通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。

- DHCP 服务器收到 DHCP 发现报文时，用 **DHCP 提供报文 向客户端做出响应。**

  **该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 **IP 地址租用期。

- 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 **DHCP 请求报文**进行响应。

- 最后，服务端用 **DHCP ACK 报文**对 DHCP 请求报文进行响应，应答所要求的参数。

#### 3.2、租约到期：请求-ACK

如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：

- 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。
- 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址。

#### 3.3、DHCP中继代理

由于使用的是广播，如果DHCP服务器和客户端不在一个局域网内，由于**路由器不会转发广播包**，这导致DHCP失效。有了 **DHCP 中继代理**以后，**对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。** 

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/37.jpg" alt=" DHCP 中继代理" style="zoom:50%;" />

- **DHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包**，而 DHCP 中继代理在收到这个广播包以后，再以**单播**的形式发给 DHCP 服务器。
- 服务器端收到该包以后再**向 DHCP 中继代理返回应答**，并由 **DHCP 中继代理将此包广播给 DHCP 客户端** 。

因此，**DHCP 服务器即使不在同一个链路上也可以实现统一分配和管理IP地址。** 

### 4、NAT网络地址转换

NAT网络地址转换**缓解**了IPv4网络地址耗尽的问题。NAT 就是同个公司、家庭、教室内的主机对外部通信时，把**私有 IP 地址转换成公有 IP 地址**。普通的NAT只是IP地址转化，意义不大。

进一步，可以把**IP地址+端口号一起进行转换**。就用一个全球 IP 地址就可以了，这种转换技术就叫**网络地址与端口转换 NAPT。** 

> <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/39.jpg" alt="NAPT" style="zoom:50%;" />
>
> 图中有两个客户端 192.168.1.10 和 192.168.1.11 同时与服务器 183.232.231.172 进行通信，并且这两个客户端的本地端口都是 1025。此时，**两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端口号作为区分。**

#### 4.1、NAT的缺点

由于 NAT/NAPT 都依赖于自己的转换表，所以：

- **外部无法主动**与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。
- 转换表的生成与转换操作都会产生**性能开销**。
- 通信过程中，如果 NAT 路由器重启了，**所有的 TCP 连接都将被重置**。

#### 4.2、解决NAT的问题

##### 4.2.1、改用IPv6

用更大的地址直接解决这个问题。但是IPv6尚未完全普及。

##### 4.2.2、NAT穿透技术

**应用程序主动**发现自己位于NAT设备，主动地获取公有IP，主动在NAT转换表中生成映射。不需要NAT设备来进行转换。

### 5、ICMP控制报文协议

 ICMP 全称是 **Internet Control Message Protocol**，也就是**互联网控制报文协议**。 在网络包遇到问题时反馈信息。

#### 5.1、ICMP功能

 `ICMP` 主要的功能包括：**确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。** 在 `IP` 通信中如果某个 `IP` 包因为某种原因未能达到目标地址，那么这个具体的原因将**由 ICMP 负责通知**。

> <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/40.jpg" alt="ICMP 目标不可达消息" style="zoom:50%;" />
>
> 如上图例子，主机 `A` 向主机 `B` 发送了数据包，由于某种原因，途中的路由器 `2` 未能发现主机 `B` 的存在，这时，路由器 `2` 就会向主机 `A` 发送一个 `ICMP` 目标不可达数据包，说明发往主机 `B` 的包未能成功。

ICMP 的这种通知消息会**使用 `IP` 进行发送** 。

#### 5.2、ICMP类型

ICMP 大致可以分为两大类：

- 一类是用于诊断的查询消息，也就是「**查询报文类型**」
- 另一类是通知出错原因的错误消息，也就是「**差错报文类型**」

### 6、IGMP因特网组管理协议

IGMP在组播中管理主机是否在一组中。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/42.jpg" alt="组播模型" style="zoom:50%;" />

**IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间**，如上图中的蓝色部分。

- IGMP 报文**向路由器申请加入和退出组播组**，默认情况下路由器是不会转发组播包到连接中的主机，除非主机通过 IGMP 加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转发组播包到对应的主机了。

#### 6.1、常规查询与响应工作机制 - 维持组播组关系

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/43.jpg" alt=" IGMP 常规查询与响应工作机制" style="zoom:50%;" />

1. 路由器会周期性发送目的地址为 `224.0.0.1`（表示同一网段内所有主机和路由器） **IGMP 常规查询报文**。
2. 主机1 和 主机 3 收到这个查询，随后会启动「报告延迟计时器」，计时器的时间是随机的，通常是 0~10 秒，计时器超时后主机就会发送 **IGMP 成员关系报告报文**（源 IP 地址为自己主机的 IP 地址，目的 IP 地址为组播地址）。如果在定时器超时之前，收到同一个组内的其他主机发送的成员关系报告报文，则自己不再发送，这样可以**减少网络中多余的 IGMP 报文数量**。
3. 路由器收到主机的成员关系报文后，就会在 **IGMP 路由表中加入该组播组**，后续网络中一旦该组播地址的数据到达路由器，它会把数据包转发出去。

#### 6.2、离开组播组工作机制 - 退出组播组

1. 主机 1 要离开组 224.1.1.1，发送 **IGMP离组报文**，报文的目的地址是 224.0.0.2（表示发向网段内的所有路由器）

2. 路由器 收到该报文后，以 1 秒为间隔连续发送 **IGMP 特定组查询报文**（共计发送 2 个），以便确认该网络是否还有 224.1.1.1 组的其他成员。

3. 按照组播组是否存在分为两种情况：

   - 如果该组已经没有主机了，没有主机响应这个查询：一定时间后，路由器认为该网段中**已经没有** 224.1.1.1 组播组成员了，将**不会再向这个网段转发该组播地址的数据包**。

   - 如果该组还有主机：主机 3 仍然是组 224.1.1.1 的成员，因此它**立即响应**这个特定组查询。路由器知道该网络中**仍然存在该组播组的成员，于是继续向该网络转发** 224.1.1.1 的组播数据包。

## 二十四、ping的工作原理

### 1、ping的助手-ICMP

ICMP **互联网控制报文协议** 用于在网络出问题时报告问题。`ICMP` 主要的功能包括：**确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。**

在 `IP` 通信中如果某个 `IP` 包因为某种原因未能达到目标地址，那么这个具体的原因将**由 ICMP 负责通知**。

### 2、ICMP报头格式

ICMP 报文是封装在 IP 包里面，它工作在网络层，是 IP 协议的助手。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/5.jpg" alt="ICMP 报文" style="zoom:50%;" />

ICMP 包头的**类型**字段，大致可以分为两大类：

- 一类是用于诊断的查询消息，也就是「**查询报文类型**」
- 另一类是通知出错原因的错误消息，也就是「**差错报文类型**」

### 3、查询报文类型-回送消息

**回送消息**用于进行通信的主机或路由器之间，判断所发送的数据包**是否已经成功到达对端**的一种消息，`ping` 命令就是利用这个消息实现的。

可以向对端主机发送**回送请求**的消息（`ICMP Echo Request Message`，类型 `8`），也可以接收对端主机发回来的**回送应答**消息（`ICMP Echo Reply Message`，类型 `0`）。

![ICMP 回送请求和回送应答报文](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/8.jpg)

相比原生的 ICMP，这里多了两个字段：

- **标识符**：用以区分是哪个应用程序发 ICMP 包，比如用进程 `PID` 作为标识符；
- **序号**：序列号从 `0` 开始，每发送一次新的回送请求就会加 `1`， 可以用来确认网络包是否有丢失。

在**选项数据**中，`ping` 还会存放发送请求的时间值，来计算往返时间，说明路程的长短。

### 4、差错报文信息

#### 4.1、目标不可达消息 ——类型 为 `3`

IP 路由器无法将 IP 数据包发送给目标地址时，会给发送端主机返回一个**目标不可达**的 ICMP 消息，并在这个消息中显示**不可达的具体原因**，原因记录在 ICMP 包头的**代码**字段。

6 种常见的目标不可达类型的**代码**：

- 网络不可达代码为 `0`，没有目标网络，网络不再分类后，这种不可达就很少。

- 主机不可达代码为 `1`，找到了网络，但是没有目标主机。

- 协议不可达代码为 `2`，找到主机后，发现对方有防火墙限制。不接受TCP协议。

- 端口不可达代码为 `3`，可以接收协议，但是目标端口对方服务器不监听。

- 需要进行分片但设置了不分片位代码为 `4`，发送端主机发送 IP 数据报时，将 IP 首部的**分片禁止标志位**设置为`1`。根据这个标志位，途中的路由器遇到超过 MTU 大小的数据包时，不会进行分片，而是直接抛弃。


#### 4.2、原点抑制消息—— 类型 `4`

当路由器向低速线路发送数据时，其发送队列的缓存变为零而无法发送出去时，可以向 IP 包的源地址发送一个 ICMP **原点抑制消息**。收到这个消息的主机借此了解在整个线路的某一处发生了拥堵的情况，从而增大 IP 包的传输间隔，减少网络拥堵的情况。

然而，由于这种 ICMP 可能会引起不公平的网络通信，一般不被使用。

#### 4.3、重定向消息—— 类型 `5`

如果路由器发现发送端主机使用了「不是最优」的路径发送数据，那么它会返回一个 ICMP **重定向消息**给这个主机。在这个消息中包含了**最合适的路由信息和源数据**。这主要发生在路由器持有更好的路由信息的情况下。路由器会通过这样的 ICMP 消息告知发送端，让它下次发给另外一个路由器。

#### 4.4、超时消息—— 类型 `11`

IP 包中有一个字段叫做 `TTL` （`Time To Live`，生存周期），它的**值随着每经过一次路由器就会减 1，直到减到 0 时该 IP 包会被丢弃。**此时，路由器将会发送一个 ICMP **超时消息**给发送端主机，并通知该包已被丢弃，避免在网路中无休止的转发。

### 5、ping的发送和接收 - 使用查询报文

#### 5.1、发送

1. 源主机首先会构建一个 **ICMP 回送请求消息**数据包。
2. ICMP 协议将这个数据包连同**目标地址**一起交给 IP 层。IP 层将以本机 IP 地址作为**源地址**，**协议**字段设置为 `1` 表示是 `ICMP` 协议，再加上一些其他控制信息，构建一个 **`IP` 数据包**。
3. 接下来，需要加入 `MAC` 头。如果在本地 ARP 映射表中查找出 IP 地址 192.168.1.2 所对应的 **MAC 地址**，则可以直接使用；如果没有，则需要发送 `ARP` 协议查询 MAC 地址。
4. 由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。

#### 5.2、接收

1. 主机 `B` 收到这个数据帧后，先**检查它的目的 MAC 地址**，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。
2. 将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。
3. 主机 `B` 会构建一个 **ICMP 回送响应消息**数据包，再发送出去给主机 A。

在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明**目标主机不可达**；如果接收到了 ICMP 回送响应消息，则说明**目标主机可达**。

源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 **ICMP 数据包的时间延迟**。

### 6、traceroute - 使用差错报文

#### 6.1、traceroute 作用一：追踪沿途路由器

traceroute 的第一个作用就是**故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。**traceroute 的参数指向某个**目的 IP 地址**。

##### 6.1.1、工作原理：设置递增的TTL

IP 包的**生存期限** 从 `1` 开始按照顺序递增的同时发送 **UDP 包**，强制接收 **ICMP 超时消息**。

比如，将 TTL 设置 为 `1`，则遇到第一个路由器，就牺牲了，接着返回 **ICMP 差错报文**网络包，类型是**时间超时**。接下来将 TTL 设置为 `2`，第一个路由器过了，遇到第二个路由器也牺牲了，也同时返回了 ICMP 差错报文数据包，如此往复，**直到到达目的主机。**

##### 6.1.2、如何直到到达目的主机

发送UDP包时，选择一个不可能的端口号作为目标。如果到了目标主机，返回的报文就不是超时报文，而是**端口不可达报文。**

#### 6.2、traceroute 作用二：**路径MTU发现**

有的时候我们并不知道路由器的 `MTU` 大小，以太网的数据链路上的 `MTU` 通常是 `1500` 字节，但是非以太网的 `MTU` 值就不一样了，所以我们要知道 `MTU` 的大小，从而控制发送的包大小。

##### 6.2.1、工作原理：禁止分片，不断尝试

在发送端主机发送 `IP` 数据报时，将 `IP` 包首部的**分片禁止标志位设置为 1**。根据这个标志位，途中的路由器不会对大数据包进行分片，而是将包丢弃。随后，通过一个 ICMP 的不可达消息将**数据链路上 MTU 的值**一起给发送主机，不可达消息的类型为「**需要进行分片但设置了不分片位**」。

发送主机端每次收到 ICMP 差错报文时就**减少**包的大小，以此来定位一个合适的 `MTU` 值，以便能到达目标主机。

### 7、断网了还能ping吗？

还能ping127.0.0.1、localhost。

#### 7.1、127.0.0.1 

**127 开头的都属于回环地址**，是 `IPV4` 的特殊地址。

#### 7.2、TCP发包和ping

ping和其他应用层软件都属于**应用层**。

正常TCP发包流程：创建Socket；进入传输层带上TCP头；网络层带上IP头；数据链路层带上MAC头；进入网卡的**发送队列 ring buffer** ，顺着网卡就发出去了。ping的流程和TCP包基本是一样的，ping会自己组建一个ICMP的数据包，把正常数据走的路走一遍。

#### 7.3、断网了还能ping127.0.0.1

到了网络层，系统会根据目的IP，在路由表中获取对应的**路由信息**，而这其中就包含选择**哪个网卡**把消息发出。

- 当发现**目标IP是外网IP**时，会从"真网卡"发出。


- 当发现**目标IP是回环地址**时，就会选择**本地网卡**。没有`ring buffer`，会把数据推到一个叫 `input_pkt_queue` 的链表中。这个链表，其实是所有网卡共享的，上面挂着发给本机的各种消息。

  消息被发送到这个链表后，会再触发一个**软中断**。专门处理软中断的内核线程**"ksoftirqd"** ，它在收到软中断后就会立马去链表里把消息取出，然后顺着数据链路层、网络层等层层往上传递最后给到应用程序。

ping 回环地址和**通过TCP等各种协议发送数据到回环地址**都是走这条路径。整条路径从发到收，都没有经过"真网卡"。所以断网了还能ping通127.0.0.1。

#### 7.4、断网ping本机地址

ping 本机IP 跟 ping 回环地址一样，都是走的**本地网卡**。**localhost 是一个域名，默认会被解析为127.0.0.1**。默认情况下，使用 `localhost` 跟使用 `127.0.0.1` 是没区别的。

#### 7.5、0.0.0.0网络地址

0.0.0.0的功能需要区分**连接、监听**两个场景。

**连接**：在`IPV4`中，0.0.0.0表示的是无效的**目标地址**。执行 ping 0.0.0.0 ，是会失败的。 客户端 `connect` 时，不能使用 `0.0.0.0` 。必须指明要连接哪个服务器IP。

**监听**：启动服务器的时候，一般会 `listen` 一个 IP 和端口，等待客户端的连接。此时 `listen` 的是本机的 `0.0.0.0` , 那么它表示本机上的**所有IPV4地址**。如果服务器 `listen` 的是 `0.0.0.0`，那么此时用`127.0.0.1`和本机地址**都可以**访问到服务。