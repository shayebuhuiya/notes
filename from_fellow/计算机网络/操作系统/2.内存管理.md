## 一、内存管理

### 1、虚拟内存

程序使用的内存地址是**虚拟内存地址**，存在硬件里的内存地址是**物理内存地址**。

**转换方式**：操作系统通过CPU中的内存管理单元MMU将虚拟地址转换为物理地址，再通过物理地址访问内存。

#### 1.1、虚拟内存的作用

1. 使得**进程的运行内存超出物理内存**，根据局部性原理，可以把没有被经常使用的内存换到硬盘的Swap区域。
2. 使得每个进程的虚拟内存**空间独立**，解决了**多进程的地址冲突**。
3. 页表的页表项中加了**页的读写权限**，**内存访问更安全**。

### 2、内存分段

最早产生了内存分段，按照代码、数据的逻辑划分段。

#### 2.1、地址结构和映射方法、段表

**地址结构：段选择因子（高位地址）**和**段内偏移量（低位地址）**组成。

**地址映射方法**：

- 段选择子里面最重要的是**段号**，用作段表的索引。**段表**里面保存的是这个**段的基地址、段的界限和特权等级**等。
- **段内偏移量**位于 0 和段界限之间。

**段表**：通过段表完成地址映射，**段表在内存中，属于是进程现场信息**。通过段选择因子的段号找到基地址，再加上偏移量找到物理地址。

#### 2.2、分段性能

- **外部碎片问题**。分段可以根据实际需求分配内存，不会有内部碎片。但是多个段未必能恰好使用内存空间，容易导致外部碎片。
- **内存交换效率低**。分段很容易产生外部碎片，就需要重新Swap整段内存区域，磁盘访问速度很慢。

### 3、内存分页

分段会出现内存交换效率低的问题，就有了内存分页。把整个**虚拟和物理内存空间切成一块块固定内存的大小**，称为页，Linux中每一页4KB。

#### 3.1、地址结构和映射方法、页表

**地址映射方法**：

- 页号，页表的索引，通过页号在页表找到页在物理地址的基地址。
- 页内偏移：基地址加上偏移量就是物理地址。

**页表**：通过页表完成地址映射，页表放在**内存**中，当进程访问的虚拟地址在页表中查不到时，会引发**缺页异常**。

#### 3.2、分页性能

- **内部碎片问题**：分页的页之间是紧密排列的，不会有外部碎片。但是因为程序占不满一页，也会分配一页的内存，产生**内部碎片**。
- **内存交换效率高**：有多种页面置换算法，正在运行的进程中的最近未使用的页面释放掉，换出到硬盘上，需要时再换入内存，**一次只换几个页**，交换效率高。

#### 3.3、多级页表

##### 3.3.1、简单分页的缺陷

32位系统的虚拟地址空间4GB，一个页4KB，需要100多万个页，每个页表项需要4个字节大小，这需要4MB的页表。（不能减小页表项的数量，页表一定要覆盖全部虚拟地址空间，否则一旦在虚拟地址找不到对应的页表项，就没法工作了）

但是**每个进程都有自己的虚拟地址空间，都有自己的页表**，导致100个进程就需要400MB的页表。

##### 3.3.2、二级分页

将100多万个页分成1024个一级页表，每个一级页表分为1024个二级页表，这共需要4KB存储一级页表，4MB存储二级页表。由于大多数程序并不真的占据这么大的虚拟空间，所以**只创建较小的一级页表覆盖全部虚拟地址**，真的使用更大空间时，才创建二级页表，使得页表占据空间大大减小。

64位系统中采用更多的四级目录。

#### 3.4、TLB

多级页表解决了空间的问题，但是虚拟地址到物理地址转换工序多，时间开销大。

根据局部性原理，在CPU中加入一个专门存放最常访问的页表项的Cache——TLB，寻址时，先查TLB，没找到才找常规的页表。

### 4、段页式内存管理

先将程序分为多个有逻辑意义的段，再把每个段分成固定大小的页。

**地址结构**：段号、段内页号和页内位移三部分组成。

**地址映射方法**：经过三次内存访问：

- 第一次**访问段表**，得到**页表起始地址**；
- 第二次**访问页表**，得到**物理页号**；
- 第三次将**物理页号与页内位移**组合，得到**物理地址**。

这样做提高了地址转换的硬件成本，系统开销，但是**提高了内存的利用率**。

### 5、Linux 使用的内存布局

#### 5.1、Linux的内存管理方式

Linux主要采用页式内存管理，但是不可避免的使用了段机制。使用段机制是因为**Intel X86 的CPU**一律会对程序使用段式映射，再进行页式映射，Linux也只好这样做。

但实际上来说，Linux每个段都是从0地址开始到4GB虚拟空间，实际上操作中面对的地址全是页式映射。段起到的作用仅仅是访问控制和内存保护。

#### 5.2、Linux的虚拟地址空间

 <img src="https://cdn.xiaolincoding.com//mysql/other/3a6cb4e3f27241d3b09b4766bb0b1124-20230309234553726.png" alt="img" style="zoom:50%;" />

- `32` 位系统的内核空间占用 `1G`，位于最高处，剩下的 `3G` 是用户空间；
- `64` 位系统的内核空间和用户空间都是 `128T`，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。

进程在用户态时，只能访问用户空间内存；只有进入内核态后，才可以访问内核空间的内存； **每个虚拟内存中的内核地址，其实关联的都是相同的物理内存**。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。 

 <img src="https://cdn.xiaolincoding.com//mysql/other/48403193b7354e618bf336892886bcff.png" alt="img" style="zoom:50%;" /> 

#### 5.3、用户空间分布

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/32%E4%BD%8D%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80.png" alt="虚拟内存空间划分" style="zoom: 33%;" />

，用户空间内存，从**低到高**分别是 6 种不同的内存段：

- **代码段**，包括二进制可执行代码，代码段和数据段分开有3个原因：指令往往是只读的，**防止指令被改写**；指令、数据分开也能**提高缓存命中率**；多个进程可能使用同一段指令，可以**共享访问代码段**；
- **数据段**，包括**已初始化**的静态常量和全局变量（已初始化但是也不能为0，为0就会在BSS段中保存），data段会增加可执行文件的大小，BSS段则不会；
- **BSS 段**，包括未初始化的静态变量和全局变量，BSS段在可执行文件中不存在。在**文件加载运行**时才分配空间并初始化，BSS段只保存未初始化变量的名称、大小；
- 堆段，包括动态分配的内存，从低地址开始向上增长；
- **堆段**，包括动态分配的内存，从低地址开始向上增长；
- **文件映射段**，包括**动态库、共享内存**等，从低地址开始向上增长；
- **栈段**，包括**局部变量和函数调用的上下文**等。栈的大小是固定的，一般是 `8 MB`。

##### 5.3.1、用户空间最底层的保留区

C语言的NULL就会指向0地址，认为是一个空指针。因为如果不把空指针初始化，而是随机指向，会导致不可控的结果，就让最低位的地址认为是无效指针的指向。

### 6、malloc

#### 6.1、malloc的应用场景

在 Linux 操作系统中，虚拟地址空间的内部又被分为**内核空间和用户空间**两部分。其中用户空间的**堆和文件映射段**是**动态分配**的，使用malloc。

#### 6.2、申请堆内存

malloc()是**C库的函数**，不是系统调用，会向操作系统申请堆内存。

##### 6.2.1、通过brk()系统调用从堆分配内存

将堆顶指针向高地址移动，获取新内存，分配的内存小于128KB，使用brk()。申请的内存不会还给操作系统，而是留在malloc的内存池中。并且brk申请内存并不严格按照请求数量，而是预分配更大的空间以备用。

##### 6.2.2、通过mmap()系统调用在文件映射区分配内存

通过mmap()系统调用，采用私有匿名映射的方式，从文件映射区偷取内存，分配的内存大于128KB，使用mmap()。mmap申请的内存在释放后会直接还给操作系统。

#### 6.3、malloc分配内存、free回收内存

1. **malloc分配的是虚拟内存**。分配的虚拟内存没有被访问的话，就不会映射到物理内存占用空间。只有在访问时发生缺页中断，才会建立虚拟内存和物理内存的关系。

2. **brk()实际申请数量更大**。brk并不完全按照申请数量分配，会预分配更大的空间。

3. **free归还内存给malloc的内存池**。brk()申请的内存：free并不会直接将内存还给系统，而是放在了malloc的内存池里，方便再次申请。mmap()申请的内存free后，会直接还给操作系统。

4. **不全用mmap分配内存**：申请空间需要进入内核态，并且释放后会直接还给操作系统，这导致可能需要频繁进入内核态，CPU消耗大。

5. **不全用brk分配内存**：**brk申请的内存不会还给操作系统**，而是留在malloc的内存池中，申请次数过多后，会导致大量用不上的小碎片，此时再申请大空间，这些小内存块是用不上的，又不得不再次请求系统分配大块内存。

   因此，小于128KB的小内存用brk，大于128KB的大内存用mmap。

6. **free函数只传入地址，如何知道释放内存的大小**：malloc返回给用户的内存多了16字节的内存块头信息，记录了内存块的描述信息。free会在堆区的地址自动向左偏移16字节，读出释放的内存块大小。

### 7、内存回收

#### 7.1、内存分配过程

1. malloc申请虚拟内存。
2. 应用程序读取这块虚拟内存，会发现没有映射到物理内存，发生**缺页中断**，进程从用户态切换到内核态，缺页中断交给内核的缺页中断函数处理。
3. 如果有空闲的物理内存，会直接分配，并建立虚拟内存和物理内存的映射关系。
4. **（如果内存已经满了会怎么样？）**如果没有空闲的物理内存，就会**回收内存**：
   
   - 后台内存回收。唤醒kswapd内核线程回收内存，是异步的，不会阻塞进程。在物理内存紧张时进行。
   - 直接内存回收。异步回收跟不上内存申请速度，会开始直接回收，是同步的，会阻塞进程。
   5. 直接内存回收仍不能满足物理内存的申请，就会触发**OOM机制**。OOM Killer 机制会选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，直到释放足够的内存。

#### 7.2、哪些内存可以回收

**文件页**：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存。

**匿名页**：没有实际载体，也例如堆、栈这些没有文件背景的页面，很可能会再次访问，不能直接释放内存，通过Linux的Swap机制回收。

文件页和匿名页都是基于LRU算法回收，维护**两个双向链表**：

- active_list：活跃内存页链表，存放最近被访问的活跃内存页。
- inactive_list：不活跃内存页链表，存放非活跃的内存页。

越靠近链表尾部，内存页越不常访问，回收内存是优先回收不活跃的内存。

#### 7.3、回收内存的性能

后台内存回收是异步的，不会阻塞进程；直接内存回收是同步回收的，会阻塞进程，导致长时间的延迟，系统CPU利用率升高。

文件页中干净页回收是直接释放内存，不影响性能，脏页回收会发生磁盘IO影响系统性能；匿名页回收时靠Swap机制实现，会发生磁盘IO。

##### 7.3.1、调整文件页和匿名页的回收倾向

文件页的回收操作比匿名页性能好，因为文件页的干净页回收不会有IO，而匿名页的 Swap 换入换出这两个操作都会发生磁盘 I/O。Linux 提供了`/proc/sys/vm/swappiness` 选项，用来调整文件页和匿名页的回收倾向，数值越大，越积极使用Swap。

可以把swappiness设置为0，回收时倾向于回收文件页。

##### 7.3.2、尽早触发kswapd内核线程异步回收

如果系统时不时发生抖动，大概率是因为直接内存回收导致的，可以调大页最小阈值，尽快触发异步回收。

<img src="https://cdn.xiaolincoding.com//mysql/other/166bc9f5b7c545d89f1e36ab8dd772cf.png" alt="img" style="zoom: 67%;" />

内存在页最小阈值和页低阈值之间时，会触发异步回收。内存小于最小阈值后，就会触发直接内存回收。

#### 7.4、NUMA架构

SMP 指的是一种**多个 CPU 处理器共享资源**的电脑硬件架构，每个CPU地位平等，是一种**一致存储访问结构UMA**。但是SMP多个CPU都通过一个总线访问，总线的带宽压力会越来越大，每个CPU的可用带宽会减少。

NUMA是非一致存储访问结构，将每个CPU都分组，一组CPU是一个Node。**每个Node有自己独立的内存**、IO。每个Node通过互联模块总线通信，访问远端Node比本地内存耗时。

在某个Node内存不足时，**从其他Node寻找空闲内存**。虽然远端访问更耗时，但是比内存回收性能好。

#### 7.5、保护进程不被OOM杀死

**直接内存回收都无法回收出足够大的空闲内存，那么就会触发 OOM 机制**，内核就会根据算法选择一个进程杀掉。Linux 内核里有一个 `oom_badness()` 函数，它会把系统中可以被杀掉的进程扫描一遍，并对每个进程打分，得分最高的进程就会被首先杀掉。

进程得分的结果受下面这两个方面影响：**进程已经使用的物理内存页面数**；**每个进程的 OOM 校准值** oom_score_adj，可以手动调节。

用「系统总的可用页面数」乘以 「OOM 校准值 oom_score_adj」再除以 1000，最后再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大。

- 可以调低进程的 oom_score_adj，从而改变这个进程的得分结果，降低该进程被 OOM 杀死的概率。
- 如果某个进程无论如何都不能被杀掉，那可以将 oom_score_adj 配置为 -1000。例如sshd这些重要的系统服务可以设为-1000。

### 8、4GB物理内存的机器上申请8GB内存会怎样

取决于系统位数、是否开启Swap机制。

#### 8.1、32位系统最多只能申请3GB大小的虚拟内存空间

因为32位系统最多只能表示4GB虚拟内存地址，其中1GB是内核空间，3GB是用户空间的。而64位系统虚拟空间很大，128TB的用户空间，128TB的内核空间。

#### 8.2、64位系统取决于物理内存大小、是否开启Swap机制

没有开启Swap机制：**可以顺利申请到8GB内存**，因为此时并不会做物理内存的映射。但是真的访问并使用内存后，就会和物理内存建立映射，**不能真的使用8GB的内存**。

开启了Swap机制：可以顺利申请到，并且还**能真的使用8GB的物理内存**，因为Swap机制会进行换入换出。

> 那开启了Swap机制，64位系统下一定能申请128TB的虚拟内存吗？
>
> 并不一定，申请虚拟内存过程中，会用到了一些**保存虚拟内存的数据结构，会占用一些数据结构**，这带来了物理内存的开销，因此物理内存也要足够大，才能顺利申请到128TB的虚拟内存。

#### 8.3、Swap机制

当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用；当内存使用存在压力的时候，会开始触发内存回收行为，会把这些不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。

Swap 就是**把一块磁盘空间或者本地文件，当成内存来使用**，它包含换出和换入两个过程：

- **换出（Swap Out）** ，把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存；
- **换入（Swap In）**，在进程再次访问这些内存的时候，把它们从磁盘读到内存中来；

##### 8.3.1、Swap触发场景

- **内存不足**：内存不足时的内存回收的过程是强制的直接内存回收，是**同步**的过程，**阻塞**当前申请内存的进程。

- **内存闲置**：应用程序在启动阶段使用的大量内存在启动后往往都不会使用，通过后台运行的**守护进程（kSwapd）**，可以将这部分**只使用一次的内存交换到磁盘上**为其他内存的申请预留空间。kSwapd 是 Linux 负责页面置换（Page replacement）的守护进程，它也是负责交换闲置内存的主要进程，它会在空闲内存低于一定水位时，回收内存页中的空闲内存，保证系统中的其他进程可以尽快获得申请的内存。

  kSwapd 是后台进程，所以回收内存的过程是**异步**的，**不会阻塞**当前申请内存的进程。

##### 8.3.2、Swap换入换出的内存类型

对于文件页，在磁盘中有对应的磁盘文件，**回收时直接写入到对应的文件**。

对于匿名页，例如堆、栈，很可能要被再次访问，不能直接释放，**会保存在磁盘的Swap分区中**。

##### 8.3.3、Swap的功能

**应用程序实际可以使用的内存空间，远远大于系统的物理内存**，因为磁盘价格低于内存，这样做很经济。

### 9、预读失效和缓存污染

Linux操作系统的缓存、MySQL中的Buffer Pool都有这样的问题，这是**LRU算法的缺陷**引起的，两者的解决方案也基本一样。

#### 9.1、预读失效

缓存在读入数据时，出于局部性原理，会选中这附近的一片数据，全读入缓存。但是如果这些被提前加载进来的页，没有被访问，就是预读失效。甚至传统LRU算法，还会把失效的预读页放在LRU链表头部，内存不够时还会淘汰末尾的页，这可能会淘汰热点数据，大大降低了缓存命中率。

- Linux 操作系统实现两个了 LRU 链表：**活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）**；
- MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：**young 区域 和 old 区域**。

**都是将数据分为了冷数据和热数据，然后分别进行 LRU 算法**。

##### 9.1.1、Linux解决预读失效 - 分活跃、不活跃两个链表

- **active list** 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；
- **inactive list** 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；

有了这两个 LRU 链表后，**预读页就只需要加入到 inactive list 区域的头部，当页被真正访问的时候，才将页插入 active list 的头部**。如果预读的页一直没有被访问，就会从 inactive list 移除，这样就不会影响 active list 中的热点数据。

使得**失效的预读页不会真的占据active list**的位置，还会更容易被淘汰出去。

#### 9.2、缓存污染

批量读取数据时，数据只访问了一次，却全部加入了缓存中，**将之前的热数据全部淘汰**。SQL中即便查询结果很小，也会因为遍历数据而导致污染。

如果新进来的大量数据很长时间不会访问，但又丢失了热数据，就是缓存污染，缓存命中率极具下降，产生大量磁盘IO。

##### 9.2.1、解决缓存污染 - 提高进入活跃链表的门槛

**提高进入到活跃 LRU 链表（或者 young 区域）的门槛，就能有效地保证活跃 LRU 链表（或者 young 区域）里的热点数据不会被轻易替换掉**。

- **Linux 操作系统**：在内存页被访问**第二次**的时候，才将页从 inactive list 升级到 active list 里。
- MySQL Innodb：在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断：
  - 如果第二次的访问时间与第一次访问的时间**在 1 秒内**（默认值），那么该页就**不会**被从 old 区域升级到 young 区域；
  - 如果第二次的访问时间与第一次访问的时间**超过 1 秒**，那么该页就**会**从 old 区域升级到 young 区域；

提高了进入活跃 LRU 链表（或者 young 区域）的门槛后，就很好了避免缓存污染带来的影响。

在批量读取数据时候，**如果这些大量数据只会被访问一次，那么它们就不会进入到活跃 LRU 链表（或者 young 区域）**，也就不会把热点数据淘汰，只会待在非活跃 LRU 链表（或者 old 区域）中，后续很快也会被淘汰。

### 10、虚拟内存

程序使用的内存地址是**虚拟内存地址**，存在硬件里的内存地址是**物理内存地址**。操作系统通过CPU中的内存管理单元MMU将虚拟地址转换为物理地址，再通过物理地址访问内存。

#### 10.1、虚拟内存的作用

1. 使得进程的**运行内存超出物理内存**，由于局部性原理，CPU访问内存有明显的重复访问的倾向。
2. 使得每个进程的虚拟内存空间独立，**解决了多进程的地址冲突**。
3. 页表的页表项中加了页的读写权限，**内存访问更安全**。

#### 10.2、进程虚拟内存

##### 10.2.1、Linux的进程描述符task_struct

```c
struct task_struct {
	    pid_t				pid;// 进程id
	    pid_t				tgid; // 用于标识线程所属的进程 pid
        struct files_struct		*files; // 进程打开的文件信息
        struct mm_struct		*mm; // 内存描述符表示进程虚拟地址空间
}
```

##### 10.2.2、进程内存描述符mm_struct

- 每个进程都有唯一的 mm_struct 结构体，每个进程的虚拟地址空间都独立。

- 通过 **fork() 函数**创建出的子进程，它的**虚拟内存空间以及相关页表**相当于父进程虚拟内存空间的**一份拷贝**，直接从父进程中拷贝到子进程中。

- 通过 vfork 或者 clone 系统调用创建出的子进程。会将父进程的虚拟内存空间以及相关页表**直接赋值给子进程**。这样一来父进程和子进程的虚拟内存空间就变成**共享**的了。也就是说父子进程之间使用的虚拟内存空间是一样的，并不是一份拷贝。

  子进程共享了父进程的虚拟空间，这个子进程就是**线程**，**是否共享地址空间就是进程和线程的本质区别**。


- 内核线程和用户态线程的区别就是内核线程没有相关的内存描述符 mm_struct ，内核线程对应的 task_struct 结构中的 mm 域指向 Null，所以内核线程之间调度是不涉及地址空间切换的。当一个内核线程被调度时，它会发现自己的虚拟地址空间为 Null，会将调度前一个的用户进程的mm_struct拿来用，避免了切换地址空间的开销。


父进程与子进程的区别，进程与线程的区别，以及内核线程与用户态线程的区别其实都是围绕着 mm_struct 展开的。
