## 一、文件系统

### 1、文件系统的组成

**Linux中一切皆文件**，普通的文件、目录、设备、管道、socket都是统一交给文件系统管理的。目录也是文件，也是用索引节点唯一标识。普通文件保存文件数据，**目录文件在磁盘中保存子目录和文件。**

Linux为每个文件分配两个数据结构：索引节点、目录项。

- 索引节点（index node），用来**记录文件的元信息**，包括inode编号，文件大小，访问权限，创建、修改时间，数据在磁盘的位置。

  **索引节点是文件的唯一标识**，**保存在磁盘中**，为了加速文件访问，**通常在文件被访问时，将索引节点加载到内存**。

- 目录项（dentry），记录**文件的名字、索引节点指针以及与其他目录项的层级关联关系**。多个目录项关联起来，就形成目录结构。

  目录项是内核维护的一个数据结构，不放在磁盘，**缓存在内存**。

**目录项和索引节点是多对一**：索引节点唯一标识一个文件，而目录项记录着文件的名字，一个文件可以有多个别名。硬链接的实现就是把**多个目录项中索引节点指向同一个文件**。

#### 1.1、目录项和目录

**目录是个文件**，持久化在磁盘，目录项是内核的一个数据结构，缓存在内存。目录项既可以表示文件，也可以表示目录文件。

内核会把**读过的目录用目录项缓存在内存**，下次读相同目录时，就可以从内存读，提高文件系统的效率。

#### 1.2、文件保存

**磁盘读写的最小单位是扇区**，扇区大小512B。文件系统把多个扇区组成一个逻辑块，**文件系统读写的最小单位是逻辑块（数据块）**，Linux中逻辑块大小是4KB。

<img src="C:\Users\absol\Desktop\面试知识\操作系统\5.文件系统.assets\目录项和索引关系图.png" alt="img" style="zoom:50%;" />

磁盘进行格式化时，会划分成三个区域：

- 超级块，用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。
- 索引节点区，用来存储索引节点；
- 数据块区，用来存储文件或目录数据；

超级块会在文件系统挂载时进入内存，索引节点会在文件被访问时进入内存。

#### 1.3、文件系统的作用

##### 1.3.1、屏蔽用户与操作系统读取数据的差异

**文件系统负责屏蔽掉用户、系统读写数据方式的不同，文件系统的基本操作单位是数据块**，用户习惯以**字节**的方式读写文件，操作系统则是以数据块来读写。

文件系统在用户读取1字节数据时，获取字节所在的数据块，再返回数据块对应的用户进程的数据部分；用户进程把1字节写入文件中时，文件系统找到对应数据块，修改对应部分，再把数据块写回磁盘。

### 2、文件使用

#### 2.1、系统调用打开文件 - 返回文件描述符

用 `open` 系统调用打开文件，`open` 的参数中包含文件的路径名和文件名，并且返回一个文件描述符fd。之后使用 `write` 写数据，使用完文件后，要用 `close` 系统调用关闭文件，都是使用 `open` 所返回的**文件描述符**，并不使用文件名作为参数。

#### 2.2、打开文件表

操作系统在**打开文件表**中维护着打开文件的状态和信息：

- **文件指针**：系统跟踪**上次读写位置**作为**当前文件位置指针**，这种指针对打开文件的某个进程来说是唯一的；
- **文件打开计数器**：多个进程可能打开同一个文件，所以系统在删除打开文件条目之前，必须等待最后一个进程关闭文件，当该计数为 0 时，系统关闭文件，删除该条目；重用打开文件表条目，避免表内空间不够用。
- **文件磁盘位置**：绝大多数文件操作都要求系统修改文件数据，该信息保存在内存中，以免每个操作都从磁盘中读取；
- **访问权限**：每个进程打开文件都需要有一个访问模式（创建、只读、读写、添加等），该信息保存在进程的打开文件表中，以便操作系统能允许或拒绝之后的 I/O 请求。

### 3、文件存储

#### 3.1、连续空间存放方式

文件的数据在磁盘中紧密相连，**必须先知道文件的大小**，文件系统根据文件大小在磁盘找到一块连续空间分给文件。

**优点：**读写效率很高，一次磁盘寻道就能读取很多文件。

**缺点：**删除文件时产生磁盘空间碎片，文件长度不易拓展。

#### 3.2、非连续空间存放方式

##### 3.2.1、链表方式 - 消除碎片、便于拓展

**隐式链表**：文件头保存第一块、最后一块的位置。**每个数据块中预留指针空间，存放下一个数据块**的位置。

**优点**：消除磁盘碎片，磁盘利用率高，文件长度可以动态拓展。

**缺点**：隐式链表**无法直接访问数据块**，只能顺序访问文件；数据块**指针消耗存储空间**；**稳定性差**，运行过程中由于软件或硬件错误丢失指针，就会导致文件数据丢失。

**显式链接**：把用于链接文件各个数据块的指针，显式的存放在内存的**文件分配表FAT**（注意虽然像索引的组织形式，但本质还是在保存链表节点，是链式存储）中，整个磁盘仅设置一张，**每个表项中存放指向下一个数据块号的链接指针**，访问到特殊标记例如-1就代表结束。

**优点**：**顺序访问时，只需要访问FAT表项，比真的查找数据块要快，并且访问内存比磁盘更快，提高了检索速度**，减少了访问磁盘的次数。

**缺点**：整个表都存放在内存，**不适用于大磁盘**。例如200GB磁盘，1KB大小的块，有2亿个块，如果FAT表每项占4字节，这张表800MB内存。

##### 3.2.2、索引方式 - 支持直接访问

链表只解决了磁盘碎片、文件动态拓展的问题，但是**不支持直接访问**。

- 索引方式就是**为每个文件创建一个索引数据块**，存放指向文件数据块的指针列表。

- 文件头包含指向索引数据块的指针。通过文件头找到索引数据块，通过索引数据块的索引信息找到数据块。

**优点**：文件创建、增改很方便；没有碎片问题，支持顺序读写、随机读写。

**缺点**：需要额外磁盘空间存放索引数据，**文件太大时，一个索引数据块存不下所有索引信息。**

为了解决大文件的索引存放问题，采用两种方案改进：

- **链式索引块**：索引+指针。在索引数据块留出一个存放下一个索引数据块的指针，一个索引数据块的索引信息用完，可以通过索引块中的指针找到下一个索引数据块。**解决了大文件的索引存放问题**，但是也带来了链表中指针损坏，文件就会丢失的问题。
- **多级索引块**：索引+索引。通过一个索引块存放多个索引数据块，也解决了大文件的索引问题。

#### 3.3、Unix文件方式

##### 3.3.1、文件实现方式对比

- 顺序分配：访问磁盘1次。存取速度快，文件是定长时可以根据文件起始地址和记录长度进行随机访问。**要求连续的存储空间**，**会产生外部碎片**，**不利于文件动态拓展**。
- 链表分配：访问磁盘N次。**无外部碎片**，磁盘利用率高，**便于动态拓展**。但是**查找效率低**，不支持随机访问。
- 索引分配：M级索引需要访问磁盘M+1次（1次访问找到索引数据块，再访问M级索引）。可以随机访问，便于增删改。但是**索引表增加了存储开销**，索引表的查找策略对文件系统效率影响大。

##### 3.3.2、Linux Ext2/3文件系统

采用**直接查找+多级索引**的方式，综合解决小文件访问速度、大文件的存储问题。

- 文件需要的数据块**小于10块**，采用**直接查找**的方式，文件头中不包含索引数据块，直接存储文件数据块的指针。
- 文件需要的数据块大于10块，采用**一级间接索引**，文件头存放索引数据块。
- 一级间接索引不够存放大文件，采用**二级间接索引**。
- 二级索引也不够，采用**三级间接索引**。

这要求文件头Inode存放13个指针：

- 10 个指向数据块的指针；
- 第 11 个指向索引块的指针；
- 第 12 个指向二级索引块的指针；
- 第 13 个指向三级索引块的指针；

对于不同大小的文件采用不同的存取方式：

- 对于**小文件使用直接查找**的方式可减少索引数据块的开销；
- 对于**大文件则以多级索引**的方式来支持，所以大文件在访问数据块时需要大量查询；

解决了大文件的存储，但是大文件访问需要大量查询，效率低。

### 4、空闲空间管理

#### 4.1、空闲表法

为所有空闲空间建立一张表，表内容包含空闲区的**第一个块号、该空闲区的块个数。**

**分配方式**：系统依次扫描空闲表中的内容，直到找到一个合适的空闲区域。

**回收方式**：依次扫描空闲表，找到一个能容纳释放空间的空闲表条目，释放空间的第一个物理块号，将占用的块数填到这个条目中。

仅在空闲区很少时效果才好，如果存储空间**有大量小空闲区，空闲表变大，查询效率低。**

#### 4.2、空闲链表法

**每一个空闲块**里有指向下一个空闲块的**指针**。

**分配方式：**从链表头部依次取下几块。

**回收方式：**将空闲块接到链表头部。

只在内存保存一个指针，指向第一个空闲块。实现简单，但是不能随机访问，在链表上增加移动空闲块不方便，数据块的指针消耗存储空间，同样不适合大文件。

#### 4.3、位图法

使用二进制的一位表示磁盘中一个盘块的使用情况。0表示盘块空闲，1表示盘块已分配。**Linux就是使用位图管理数据空闲块、inode空闲块**。

Linux 使用位图管理空闲空间。新建文件时，通过inode的位图找到空闲的inode进行分配；存储数据时，通过块的位图找到空闲的块。

### 5、文件系统结构 - 块组

Linux只使用块的位图 + 块的形式，一个块大小（4KB）的位图能表示的空间很有限，因此需要把**位图 + 块组织成一个块组**，系统中保存很多块组。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E5%9D%97%E7%BB%84.png" alt="img" style="zoom:50%;" />

文件系统最前面是一个引导块，系统启动时用于引导。后面是一个个连续的块组。块组内容有：

- 超级块。存储文件系统信息，inode个数，块总个数，每个块组的inode个数，每个块组的块个数。
- 块组描述符。块组中空闲块和inode的数目，每个块组都包含所有块组的描述符信息。
- 数据位图和inode位图。表示对应的数据块或inode是空闲还是使用。
- inode列表。包含块组中所有的inode，用于保存文件系统中所有文件和目录相关的所有元数据。
- 数据块。包含文件数据。

#### 5.1、块组的冗余特性

**每个块组中有很多重复信息：超级块和块组描述符，都是全局信息**。可以在系统崩溃丢失超级块或块组描述符时，可以保留冗余副本，信息可恢复；使得文件和管理数据尽可能接近，减少磁头寻道和旋转，提高文件系统性能。

Ext2后采用了稀疏技术，只在块组0、1和其他可以表示为3、5、7的幂的块组中。

### 6、目录的存储

目录也是一个文件，目录的块种存储的是目录里一项项的文件信息。目录文件的块中，保存**该目录下文件的文件名和对应的inode。**

通常，目录中第一项是「`.`」，表示当前目录，第二项是「`..`」，表示上一级目录，接下来就是一项一项的文件名和 inode。

#### 6.1、目录中的文件保存形式-哈希表

一个目录中文件很多时，一项一项查找效率不高。

**哈希表**：对**文件名进行哈希运算**保存哈希值，查找时也是对名称取哈希进行匹配，提高目录中文件的查找效率，但是需要采取一些措施避免哈希冲突。

**加快目录查询效率**：为了减少磁盘IO次数，把当前使用的目录缓存在内存中，提高文件系统的访问速度。

### 8、软链接和硬链接

通过硬链接和软链接给文件起别名，软硬链接都是特殊的文件。

#### 8.1、硬链接

- 硬链接是**多个目录项中索引节点指向一个文件**，也就是指向同一个inode。

- 多个目录项指向一个inode，只有**删除文件的所有硬链接和源文件时，系统才会彻底删除该文件**。

- **inode不可能跨越系统**，所以**硬链接不可用于跨文件系统**。

#### 8.2、软链接

- 软链接相当于**重建文件**，每个文件有独有的inode，但这个**新文件的内容是另一个文件的路径**。
- 访问软链接时，**相当于访问到另一个文件**，软链接**可以跨文件系统**。
- 目标文件被删除了，链接文件还是在的，只是指向的文件找不到了。

### 9、文件I/O

#### 9.1、缓冲与非缓冲I/O

按照**是否利用标准库缓存**划分。

- **缓冲 I/O**，利用的是标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件。
- **非缓冲 I/O**，直接通过系统调用访问文件，不经过标准库缓存。

很多程序遇到换行时才真正输出，而换行前的内容，其实就是被标准库暂时缓存（缓冲）了起来，**减少系统调用的次数**，减少 CPU 上下文切换的开销。

#### 9.2、直接与非直接I/O

按照**是否利用操作系统的缓存**划分。系统调用后，操作系统把用户数据拷贝到内核中的「页缓存」缓存起来，当**缓存满足某些条件时，才会发起I/O请求，减少磁盘I/O的次数**。

- 直接 I/O，不会发生内核缓存和用户程序之间数据复制，而是**直接经过文件系统访问磁盘**。
- 非直接 I/O，读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写入数据到磁盘。

默认使用的是非直接 I/O，文件操作类的系统调用函数时，指定了 `O_DIRECT` 标志，则表示使用直接 I/O。

##### 9.2.1、非直接I/O把缓存写入磁盘的时机

- 在调用 `write` 的最后，当发现内核缓存的**数据太多**的时候，内核会把数据写到磁盘上；
- 用户**主动调用 `sync`**，内核缓存会刷到磁盘上；
- 当**内存十分紧张**，无法再分配页面时，也会把内核缓存的数据刷到磁盘上；
- 内核缓存的数据的缓存时间**超过某个时间时**，也会把数据刷到磁盘上；

#### 9.3、阻塞/非阻塞I/O、同步/异步I/O

I/O分为「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程。

阻塞I/O会阻塞在过程1、2，非阻塞I/O和基于非阻塞I/O的多路复用只会阻塞在过程2，这三个都是同步I/O。异步I/O过程1、2都不会阻塞。

##### 9.3.1、阻塞/非阻塞I/O

- **阻塞IO**：当用户程序执行 `read` ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，`read` 才会返回。阻塞会等待**「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程**。
- **非阻塞IO**：read请求会在数据未准备好的情况下立即返回。应用程序**不断轮询内核**，直到数据准备好，内核将数据拷贝到应用程序缓冲区，read调用才会得到结果。

##### 9.3.2、I/O多路复用（属于网络I/O，不是文件I/O，在网络I/O环节在关注多路复用）

应用程序每次轮询内核的I/O，轮询过程中程序会停滞，效率很低。因此有了**I/O 多路复用**技术，如 select、poll，它是通过 I/O 事件分发，当**内核数据准备好时，再以事件通知应用程序进行操作。**

**I/O多路复用流程**： 调用了 I/O 多路复用接口，如果没有事件发生，那么当前线程就会发生阻塞，这时 CPU 会切换其他线程执行任务，等内核发现有事件到来的时候，会唤醒阻塞在 I/O 多路复用接口的线程，然后用户可以进行后续的事件处理。

**I/O 多路复用接口最大的优势在于，用户可以在一个线程内同时处理多个 socket 的 IO 请求。**用户可以注册多个 socket，然后**不断地调用 I/O 多路复用接口读取被激活的 socket**，即可达到在同一个线程内同时处理多个 I/O 请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。

##### 9.3.3、同步与异步

无论是阻塞 I/O、非阻塞 I/O，还是基于非阻塞 I/O 的多路复用**都是同步调用**。因为它们**在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，过程都是需要等待的**，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。真正的**异步 I/O** 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程**都不用等待**。

**异步I/O方式**：当发起 `aio_read` 之后，就立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样是异步的，内核自动完成的，应用程序并不需要主动发起拷贝动作。

### 10、Page Cache 磁盘高速缓存

#### 10.1、Page Cache的功能 - 在内核缓存文件系统的数据

**进程用带缓冲的写文件，中途崩溃，已经写入的数据是否还存在？**

进程在执行 write （**缓冲 IO**）系统调用的时候，实际上是写到了**内核的 page cache**，它是文件系统中用于**缓存文件数据的缓冲**，所以即使进程崩溃了，**文件数据还是保留在内核的 page cache**，我们读数据的时候，也是从内核的 page cache 读取，因此**还是读的进程崩溃前写入的数据**。

内核会找个合适的时机，将 page cache 中的数据持久化到磁盘。但是如果 page cache 里的文件数据，在持久化到磁盘化到磁盘之前，系统发生了崩溃，那这部分数据就会丢失了。可以在程序里调用 fsync 函数，在写文件的时候，立刻将文件数据持久化到磁盘，避免丢失问题。

#### 10.2、page

page是内存管理分配的基本单位。

**Page Cache是Linux内核管理的一块内存，Page Cache由多个page构成**。一个page在操作系统中通常为4KB大小，Page Cache大小是4KB的整数倍。

#### 10.3、Swap与缺页中断

**Swap机制**：当物理内存不够时，内存管理单元MMU提供调度算法回收内存空间。因为Linux提供了虚拟内存管理机制，**每个进程都认为自己独占内存，导致所有进程的内存空间之和大于物理内存**，超出物理内存的部分就需要**交换到磁盘**上。

**缺页中断**：进程发现需要访问的数据不在内存时，会发生缺页中断，通过系统调用将page再次读到内存中。

#### 10.4、Page Cache 与 buffer cache

Page Cache 与 buffer cache共同目的都是加速数据I/O。**Page Cache 用于缓存文件的页数据，buffer cache 用于缓存块设备（如磁盘）的块数据。**

- 页是逻辑上的概念，因此 Page Cache 是与文件系统同级的；
- 块是物理上的概念，因此 buffer cache 是与块设备驱动程序同级的。

在Linux 2.4之前，Page Cache和buffer cache是分开的，但是块设备大多是磁盘，磁盘上数据又通过文件系统组织，这**导致了很多数据缓存了两次**。

因此Linux 2.4之后两块缓存近似地融合在一起，如果一个文件的页加载到了Page Cache，那么同时**buffer cache只需要维护块指向页的指针**就可以。只有那些没有文件表示的块，或者是绕过了文件系统直接操作的块，才会放在buffer cache里。所以提起page cache，基本都是同时指page cache 和 buffer chace两者。

#### 10.5、Page Cache 与 预读

操作系统为基于 Page Cache 的读缓存机制提供**预读机制**。操作系统在读取页时，会将邻近的几个页都读入。

#### 10.6、文件持久化的一致性、可靠性

任何引入缓存的系统，都会有内存与磁盘中数据不一致的问题，例如后端架构的Redis缓存和MySQL数据库的一致性问题。

**文件一致性**：文件=数据+元数据，因此文件一致性需要数据一致，并且元数据一致。

> 元数据描述文件的各种属性，文件的元数据包括：文件大小、创建时间、访问时间、属主属组等信息。

##### 10.6.1、Linux实现一致性的方式

- **写穿Write Through**：向用户层提供特定接口，应用程序可主动调用接口来保证文件一致性；牺牲了系统I/O吞吐量，向上层应用保证一旦写入，数据就已经落盘。
- **写回Write back**：系统中存在定期任务（表现形式为内核线程），周期性地同步文件系统中文件脏数据块，这是默认的 Linux 一致性方案。系统发生宕机时无法确保数据已经落盘，存在数据丢失问题。

这两种方案依赖于3种系统调用：

- fsync(int fd)：将fd代表的文件的脏数据、脏元数据全部刷新到磁盘；
- fdatasync(int fd)：将fd代表的文件的脏数据刷新到磁盘，只对接下来访问文件有关键作用的信息刷盘，如文件大小，其他的文件修改时间的不必要信息不刷盘。
- sync()：对系统中所有的脏数据、脏元数据全部刷新到磁盘。

#### 10.7、Page Cache的优劣

##### 10.7.1、优势

- **加快数据访问**，访问内存比访问磁盘快的多。
- **减少I/O次数**，因为Page Cache的**缓存、预读**能力，提高系统磁盘I/O吞吐量。

##### 10.7.2、劣势

- 占据物理内存，物理内存紧张时还会**导致频繁的swap操作**，导致磁盘I/O负载上升。
- 对应用层没有提供很好的管理API，应用层难以优化Page Cache的使用策略。一些应用选择在用户空间实现自己的page管理，例如MySQL 的 InnoDB存储引擎就是以16KB的页进行管理。
- 在使用DMA技术的情况下，用户空间直接与磁盘、网卡进行数据交互。Page Cache比直接I/O（不用中间层Page Cache，读是直接从磁盘读取，写是直接落盘），多一次磁盘读I/O以及磁盘写I/O。
