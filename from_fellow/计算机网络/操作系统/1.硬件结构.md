## 一、CPU

### 1、中央处理器

#### 1.1、冯诺伊曼模型

计算机基本结构为 5 个部分，分别是**运算器、控制器、存储器、输入设备、输出设备**，这 5 个部分也被称为**冯诺依曼模型**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/%E5%86%AF%E8%AF%BA%E4%BE%9D%E6%9B%BC%E6%A8%A1%E5%9E%8B.png" alt="img" style="zoom: 80%;" />

- **内存**：程序和数据都存储在内存中。存储的基本单位是**字节**，1字节等于8位。

- **中央处理器**：有不同CPU位宽的区别：32位和64位CPU区别在于**一次可以计算多少字节数据**：32位CPU一次可以计算4个字节；64位CPU一次可以计算8个字节。

  CPU 内部还有一些组件，常见的有**寄存器、控制单元和逻辑运算单元**等。其中，控制单元负责控制 CPU 工作，逻辑运算单元负责计算，而每种寄存器的功能又不尽相同：

  - **通用寄存器**：存放需要进行运算的数据。
  - **程序计数器**：用来存储CPU要执行的**下一条指令所在的内存地址**（此时指令还在内存中）。
  - **指令寄存器**：用来存放正在执行的**指令**。
- **总线**：总线是用于CPU和内存以及其他设备之间的通信，CPU读写内存数据

  - **地址总线**：用来指定CPU将要操作的内存地址。
  - **数据总线**：用于读写内存的数据。
  - **控制总线**：发送和接收信号，比如中断、设备复位等信号。

#### 1.2、线路位宽与CPU位宽

##### 1.2.1、线路位宽

- 为了避免低效率的串行传输（下一个 bit 必须等待上一个 bit 传输完成才能进行传输）的方式，线路的位宽最好一次就能访问到所有的内存地址，实现并行传输。
- 地址总线有n条，CPU能操作的内存地址最大数量为$2^n$个。

##### 1.2.2、CPU位宽

- 如果计算的数额不超过 32 位数字的情况下，32 位和 64 位 CPU 之间没什么区别的，只有当计算超过 32 位数字的情况下，64 位的优势才能体现出来。
- **32 位 CPU 最大只能操作 4GB 内存**，就算装了 8 GB 内存条，也没用。而 64 位 CPU 寻址范围则很大，理论最大的寻址空间为 `2^64`。

### 2、程序的执行过程

#### 2.1、CPU的指令周期（CPU的4级流水线）

1. **取指令Fetch**：

   - CPU读取”**程序计数器**”PC的数值，这是指令的内存地址；

   - CPU的“**控制单元**”操作“**地址总线**”，指向需要访问的内存地址。


   - 通知内存设备准备数据，将数据通过“**数据总线**”将指令数据传给CPU。


   - CPU接收到指令数据后，将指令数据存入到“**指令寄存器**”。


   - “**程序计数器**”的数值自增，表示指向下一条指令。**自增的大小由CPU位宽决定**，如果是32位的CPU，指令是4个字节，需要4个内存地址存放，“**程序计数器**”会自增4。

2. **指令译码Decode**：CPU分析“**指令寄存器**”中的指令，将指令解析成不同的操作信号、操作数、地址。

3. **执行Execution**：计算类型的指令交给“**逻辑运算单元**”进行运算，存储类型的指令交给”**控制单元**”进行。

4. **数据回写Store**：操作结果写回内存。

CPU**取指令、指令译码、执行、数据回写、再到下一条指令**，这个过程不断循环，直到程序执行结束，这个不断循环的过程被称为**CPU的指令周期**。

#### 2.2、指令

程序语言需要先翻译成**汇编语言**，汇编语言用汇编器翻译成01组成的**机器码**，之后才能执行。MIPS的指令分为三类：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/MIPS%E6%8C%87%E4%BB%A4%E9%9B%86.png" alt="img" style="zoom: 67%;" />

- R指令：用于**算术和逻辑操作**，有读取和写入数据的寄存器地址。位移量用于逻辑移位操作，功能码作用是是拓展操作码，在前6位操作码不够用时补充具体指令。
- I指令：用于**数据传输，条件分支**，只有两个寄存器、地址或立即数。没有了第三个寄存器、位移量和功能码。
- J指令：用于跳转，只有一个目标地址。

##### 2.2.1、指令的功能类型

指令从功能角度划分，分为五大类：

- 数据传输指令：store/load用于寄存器与内存间传输数据，mov将一个内存地址的数据移动到另一个内存地址。
- 运算指令：加减乘除、位运算、比较大小。
- 跳转指令：通过修改程序计数器的数值达到跳转执行指令的目的。实现编程中的if-else等语句。
- 信号指令：例如中断指令trap。
- 闲置指令：例如nop，执行后CPU会空转一个周期。

#### 2.3、指令的执行速度

**CPU主频**：CPU在1秒内会产生的脉冲信号次数。CPU在一个时钟周期内仅能完成一个最基本的动作，但一个时钟周期不一定能执行完一条指令。

**程序的执行时间 = CPU时钟周期数*时钟周期时间**。如果需要程序执行的更快，可以有三个方式：

- 加快CPU主频，减少时钟周期时间。

- 减少指令数，靠编译器优化。

- 减少每条指令的平均时钟周期数CPI，使用流水线技术。

#### 2.4、64 位相比 32 位 CPU 的优势

- **大数字计算效率优势**：32 位 CPU 如果要计算超过 32 位的数字，要分多步骤进行计算，而64位CPU可以一次完成运算。只有运算大数字的时候，64 位 CPU 的优势才能体现出来。
- **寻址更大的内存空间**：32 位 CPU 最大的寻址地址是 4G，即使加了 8G 大小的内存，也还是只能寻址到 4G，而 64 位 CPU 最大寻址地址是 `2^64`。

##### 2.4.1、64位和32位软件的兼容性

- 如果32位指令在64位机器上执行，需要一套兼容机制，可以兼容运行。
- 64位指令在32位机器上执行比较困难，32位寄存器存不下64位指令。

### 3、优化CPU性能

1. 提升**数据缓存**命中率：遍历数组的情况时，按照内存布局顺序访问，有效利用CPU Cache，尽可能连续访问一个Cache缓存块里的数据。

2. 提升**指令缓存**命中率：利用CPU的分支预测器（CPU预测 if 和 else 哪个分支的指令，将指令提前放入缓存）。例如可以优先进行数组排序，提高预测准确度。

3. 由于CPU的时间片机制，线程可能在不同CPU核心之间切换，由于L1、L2 Cache是每个核心独有的，如果一个线程在不同核心不断切换，核心的缓存命中率就会下降。

   Linux中可以使用`sched_setaffinity`方法绑定线程到某个CPU核心。

### 4、CPU缓存一致性

缓存一致性问题：数据写入Cpu Cache 后，还需要把数据写入内存，要保证Cache 的数据与内存一致。写直达、写回法都是在解决单核心CPU的缓存一致性问题。

#### 4.1、写直达

无论数据在不在Cache里，**每次写操作都写回内存**，性能很低。

- 如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；
- 如果数据没有在 Cache 里面，就直接把数据更新到内存里面。

#### 4.2、写回法

修改的数据只写入Cache Line，修改过的Cache Line被替换时才写入内存，减少了写内存的频率，性能提高。写入数据的流程：

- Cache命中，将数据更新到Cache中，同时将这个Cache Line的有效位标记为0。
- Cache未命中，检查对应Cache Line的数据有效位。
  - 如果是脏数据，把这个缓存块数据写入内存。
  - 不是脏数据，把当前写入数据写入Cache，并把有效位标记为0。

写回法只会在缓存未命中，同时对应的Cache Line是脏数据的情况下才会写内存。

#### 4.3、多核心CPU缓存一致性

多核心的CPU可能会出现不同核心缓存不一致的问题，通过做到以下两点解决：

- 写传播：某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache。通过**总线嗅探**实现。
- 事务串行化：某个 CPU 核心里对数据的**操作顺序**，必须在其他核心看起来顺序是一样的，这需要对Cache数据更新时要加**锁**。

##### 4.3.1、总线嗅探

某个CPU核心修改了Cache中的变量后，通过总线广播通知所有核心。每个核心都会监听总线的广播事件，检查自己的Cache是否有相同的数据，有就更新。总线嗅探有两个缺点：

- 只能保证其他CPU核心直到数据发生更改，但是不能保证事务串行化
- CPU需要时刻监听总线上的活动，并且不管别的核心是否缓存了相同数据，都会发广播事件，加重了总线负担。

##### 4.3.2、MESI协议

是基于总线嗅探的协议，标记Cache Line（注意，不是数据）的四个状态：Modified已修改、Exclusive独占、Shared共享、Invalidated无效。

- 已修改：「独占」、「共享」状态修改后就会变成已修改状态，表示这个Cache Block的数据已被修改，表示数据失效，不可读取。对于「已修改」的数据，可以直接修改，因为修改之前，其他核心的这个数据改成了「无效」。

  「已修改」的Cache Line被替换时，会在替换前将数据写入内存。

- 独占：数据可读，并且只有一个CPU核心所有，**可以直接修改，不用通知其他CPU**。但是其他核心一旦读取相同数据，就会收到其他核心的广播信息，变成共享状态。

- 共享：数据可读，但是多个CPU共有，**不能直接修改，需要请求其他核心将这个数据改成「无效」状态**，才能更新。

- 无效：对于共享数据，其中一个CPU要修改，其他CPU就会把这个数据改成无效状态。

对于**已修改、独占的数据**，修改**不需要广播通知其他CPU**，减轻总线压力。

### 5、CPU伪共享

CPU1需要资源A，CPU2需要资源B，但是他们在同一个Cache Line中，这导致两个CPU交替对两个资源修改时，会不断让另一个CPU对这个Cache Line的状态变成无效，需要重新读入，没有起到缓存的作用。

对于多个线程共享的热点数据，即经常会修改的数据，这些数据刚好在同一个Cache Line 中，就会出现为伪共享的问题。

#### 5.1、使用Linux的__cacheline_aligned_in_smp宏定义

该宏定义会让变量在Cache Line是对齐的，采用空间换时间的思想，浪费一部分Cache空间，但是避免了CPU伪共享的问题。

> 举例：对于同一个struct的变量，原本是物理地址连续的，使用这个宏会让变量不放在同一个Cache Line里面。
>
> <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/struct_ab.png" alt="img" style="zoom:50%;" /><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/struct_ab1.png" alt="img" style="zoom:50%;" />

### 6、CPU选择线程

CPU会使用Linux内核中的调度器，在每个CPU都有自己的**运行队列**（不同任务会加入不同队列），按照运行队列优先级和调度策略选择当前运行的线程，也就是调度`task_struct` 结构体。特别的是，只有普通任务使用CFS公平调度策略，可以通过修改nice值修改普通任务优先级。

#### 6.1、task_struct

在 Linux 内核中，**进程和线程都是用 `task_struct` 结构体表示，调度器调度的基本对象也是`task_struct`**。区别在于线程的 task_struct 结构体里部分资源是共享了进程已创建的资源，比如内存地址空间、代码段、文件描述符等，所以说线程是轻量级进程。

#### 6.2、任务优先级

在 Linux 系统中，根据任务的优先级以及响应要求，主要分为两种，其中**优先级的数值越小，优先级越高**：

- 实时任务，对系统的响应时间要求很高，也就是要尽可能快的执行实时任务，优先级在 `0~99` 范围内的就算实时任务；
- 普通任务，响应时间没有很高的要求，优先级在 `100~139` 范围内都是普通任务级别；

##### 6.2.1、调整优先级

设置**普通任务的nice值**：注意只有普通任务才能这样修改，只有它采用CFS公平调度。nice 的值能设置的范围是 `-20～19`， 值越低，表明优先级越高，默认优先级是 0。

优先级计算方式：priority(new) = priority(old) + nice。priority 的范围是 0~139，值越低，优先级越高，因此**nice值是一个优先级的修正值**。

nice值修正后，任务优先级也只能在100-139中，因此 nice 值调整的是**普通任务**的优先级。

#### 6.3、CPU运行队列

**运行队列**：每个CPU都有自己的运行队列，保存在这个CPU上运行的所有任务。三个队列优先级：**Deadline运行队列 > 实时任务Realtime运行队列 > CFS运行队列。**

Deadline 和 Realtime 运行队列都是应用于实时任务的。因为队列优先级，实时任务总是比普通任务先执行。

#### 6.4、CPU调度器

对应三种运行队列，有三种调度类供队列使用：

Deadline调度类：

- *SCHED_DEADLINE*：是按照 deadline 进行调度的，距离当前时间点最近的 deadline 的任务会被优先调度；

Realtime调度器：

- *SCHED_FIFO*：先来先服务原则，但是高优先级任务可以抢占式调度；
- *SCHED_RR*：时间片轮转调度，可以抢占式调度；

Fair 调度类，应用于普通任务：

- *SCHED_NORMAL*：普通任务使用的调度策略；
- *SCHED_BATCH*：后台任务的调度策略，不和终端进行交互，因此不影响其他需要交互的任务，可以适当降低它的优先级。

#### 6.5、完全公平调度CFS - 普通任务使用

会优先选择虚拟运行时间vruntime 少的任务，以保证每个任务的公平性。

虚拟运行时间vruntime  = 真实运行时间 * nice_0_load / 权重。nice_0_load 是一个常数，因此同样真实时间下，高权重任务，虚拟运行时间越少。

### 7、计算机编码

#### 7.1、为什么数字用补码表示

如果负数不用补码表示，做基本加减法运算时，需要**多一步判断是否是负数**，如果是负数，还需要将运算进行反转。使用补码就会让负数、正数加减法一样。

#### 7.2、计算机中的小数

计算机中使用浮点数保存小数：

- 类似于科学计数法一样，对数字进行规格化，让基数为2，也就是小数点左边一定是一个1，这也起到了节约1位空间的作用（因为这1位不需要尾数来表示）。
- 规格化后的数字分为两部分：小数点后的**尾数、指数**（表示小数点的位置）。
- 使用IEEE标准浮点数表示数字，3个部分：符号位、指数位（影响数据的表达范围）、尾数位（影响数据的精度）。

##### 7.2.1、精度问题

二进制只能精准表达被2除尽的数字，就像十进制只能精准表达被2、5整除的数字（10是2、5的乘积），七进制只能精准表达被7整除的数字。

## 二、存储器

### 1、存储器的层次结构

#### 1.1、寄存器

最接近CPU的控制单元、逻辑计算单元的存储器，访问速度非常快，一般要求在半个CPU时钟周期完成读写，因为CPU处理一条指令不仅要读写寄存器。

#### 1.2、CPU Cache

**需要CPU Cache的原因**：CPU和内存的访问性能差距越来越大，需要在中间加入一个高速缓存，存储频繁访问的数据和指令，提高CPU的访问速度。CPU访问数据或指令时，先查找Cache，Cache中没有缓存才到内存中读取。

##### 1.2.1、CPU Cache架构

CPU Cache用SRAM（静态随机存储器）芯片（断电数据丢失，通常用6个晶体管，访问速度非常快），分为L1、L2、L3三级高速缓存。

- L1高速缓存：每个CPU核心只有一块。2-4个时钟周期，几十KB-几百KB。**L1 Cache 通常会分为「数据缓存」和「指令缓存」。**index0是数据缓存，index1是指令缓存。

- L2高速缓存：每个CPU核心独有。10-20个时钟周期，几百KB-几MB。

- L3高速缓存：多个CPU核心共用。20-60个时钟周期，几MB-几十MB。


```shell
$ cat /sys/devices/system/cpu/cpu0/cache/index0/size L1 Cache数据缓存
$ cat /sys/devices/system/cpu/cpu0/cache/index1/size L1 Cache指令缓存
$ cat /sys/devices/system/cpu/cpu0/cache/index2/size L2 Cache
$ cat /sys/devices/system/cpu/cpu0/cache/index3/size L3 Cache
```

##### 1.2.2、Cache Line 缓存块

CPU Cache Line是CPU从内存读取数据的基本单位，读取进入Cache都是一块一块，因此需要对地址进行索引编号。

**内存访问地址**分为3个部分：组标记（高位地址作为组号）、索引（中间地址作为块的编号）、偏移量（低位地址作为块内偏移量，用于具体定位）。

**CPU Cache Line信息**分为4个部分：组标记、索引、有效位（如果有效位是0，无论Cache中是否有数据，CPU会直接访问内存，重新加载数据）、数据块。

##### 1.2.3、CPU Cache 映射

**直接映射**：每个主存地址只能映射到唯一Cache行。实现简单，会出现比较多的映射冲突。

**全相联映射**：任何一个主存地址都可以映射到任何一个Cache行，因此需要额外的标记确定在Cache的位置。虽然解决了冲突问题，但实现复杂，访问速度慢。

**组相联映射**：Cache分为多组，主存地址被映射到唯一组、任意的组内行，是直接映射和组相联映射的折中。

##### 1.2.4、CPU Cache 性能

- 提高命中率：访问过程中，所访问数据、指令在Cache中的比例，命中率越高，CPU访问速度越快。
- 采用预读技术，根据局部性原理，访问一个数据，预读相邻的数据。

#### 1.3、内存

使用用DRAM（动态随机存储器）芯片，使用1个晶体管和1个电容。电容会漏电，需要定时刷新内容。

#### 1.4、SSD/HDD硬盘

SDD（solid state disk）固态硬盘，HDD（hard disk drive）机械硬盘。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E5%B1%82%E6%AC%A1%E5%85%B3%E7%B3%BB%E5%9B%BE.png" alt="img" style="zoom:50%;" />

每个存储器只和相邻的一层存储器设备打交道，并且存储设备为了追求更快的速度，所需的材料成本必然也是更高。所以 CPU 内部的寄存器、L1\L2\L3 Cache 只好用较小的容量，相反内存、硬盘则可用更大的容量，这就**存储器层次结构**。

存储器的层次结构也形成了**缓存体系**：CPU先找寄存器，没有再找L1 Cache……最终找内存。



## 三、中断

### 1、中断

中断是一种**异步**的事件处理机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求，可以提高系统的**并发**处理能力。

**中断处理程序**：有**程序执行太长、中断丢失**两个问题。中断处理过程中还可能会临时关闭中断，导致中断丢失，其他中断都无法响应。

### 2、硬中断、软中断

Linux系统为了解决中断处理程序执行太长、中断丢失的问题，将中断分成两部分。

- 上半部分：硬中断，直接处理硬件请求，**快速处理**中断，一般会要求暂时关闭中断请求。硬中断会直接打断CPU正在执行的任务，立即执行中断处理程序。
- 下半部分：软中断，**延迟处理**上半部分未完成的工作，一般以内核线程方式运行。

### 3、网卡接收包的例子

网卡收到网络包后，通过DMA将数据直接写入内存，通过**硬件中断**通知内核有数据到了，内核会调用中断处理程序处理。

上半部分禁止网卡中断，避免频繁硬中断影响内核工作效率；下半部分触发软中断，处理剩下耗时的任务：从内存中找到网络数据，按照协议栈逐层解析最终交给程序。

#### 3.1、网卡中的异常中断

如果CPU中有大量软中断，可能是网卡接受了太多包，可以通过分析包的来源，检测是否是正常的数据包。

